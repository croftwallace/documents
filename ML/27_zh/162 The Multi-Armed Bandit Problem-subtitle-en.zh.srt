1
00:00:01,780 --> 00:00:05,340
您好，欢迎回到机器学习课程。

2
00:00:05,440 --> 00:00:08,760
今天，我们谈论的是多武装匪徒问题。

3
00:00:08,800 --> 00:00:14,560
您不只是喜欢这些名称，它们就为机器学习算法和

4
00:00:14,560 --> 00:00:15,880
问题。

5
00:00:15,880 --> 00:00:23,740
今天，我们确实在谈论这个问题，这就是我们将要使用的示例

6
00:00:23,740 --> 00:00:25,850
在关于强化学习的整个章节中。

7
00:00:25,840 --> 00:00:31,420
我们将寻找解决多武装匪徒问题的不同方法，并进行比较

8
00:00:31,420 --> 00:00:32,370
结果。

9
00:00:32,680 --> 00:00:37,960
但是在我们向您提供帮助之前，我只想提到Malte臂章。

10
00:00:38,440 --> 00:00:43,330
强化学习可以解决的问题强化学习实际上是真的

11
00:00:43,330 --> 00:00:49,250
例如，很酷的强化学习用于训练机器狗走路。

12
00:00:49,270 --> 00:00:55,660
我会给你一个简单的例子，例如，一旦创建了机器狗，就可以实现

13
00:00:55,660 --> 00:01:00,080
机器狗内部的算法，可以告诉它如何走路。

14
00:01:00,220 --> 00:01:00,460
好吧。

15
00:01:00,460 --> 00:01:05,740
先移动右前脚，然后再移动左后脚，然后再移动左前脚和右后脚

16
00:01:05,740 --> 00:01:10,090
依此类推，您实际上可以给出需要完成的一系列操作

17
00:01:10,090 --> 00:01:11,580
正在行走的任务。

18
00:01:11,740 --> 00:01:19,690
或者，您可以实施arean Forsman学习算法，该算法将训练狗在非常非常快的时间内行走

19
00:01:19,780 --> 00:01:20,500
有趣的方式。

20
00:01:20,500 --> 00:01:25,490
所以基本上它将要做的是，他们会说“嘿狗”是您可以执行的所有操作。

21
00:01:25,930 --> 00:01:29,100
你可以这样移动你的腿，你可以那样移动你的腿。

22
00:01:29,110 --> 00:01:32,850
您的目标是向前迈出一步。

23
00:01:32,860 --> 00:01:39,670
每次前进，都会得到奖励，每次跌倒都会受到惩罚

24
00:01:39,700 --> 00:01:45,790
奖励基本上就是手臂上的奖励，您实际上不必给它胡萝卜或您知道一些东西

25
00:01:46,390 --> 00:01:46,910
去吃。

26
00:01:46,930 --> 00:01:50,850
您只需在算法中给它加1，惩罚为零。

27
00:01:50,950 --> 00:01:55,870
基本上，每次他向前迈进时，它都知道会得到奖励，这就是

28
00:01:55,870 --> 00:01:56,320
很好。

29
00:01:56,320 --> 00:02:03,100
因此，基本上，您将尝试所有这些随机操作，并查看每次操作会导致什么

30
00:02:03,100 --> 00:02:03,670
向前迈进了一步。

31
00:02:03,670 --> 00:02:09,340
请记住，这些都是好行为，并且会尝试越来越多地重复它们，实际上狗喜欢

32
00:02:09,340 --> 00:02:11,780
可以学习走路。

33
00:02:11,860 --> 00:02:17,740
因此，您不必在其中编写实际的行走算法，就可以找出需要执行的步骤

34
00:02:17,740 --> 00:02:18,870
自己承担。

35
00:02:18,910 --> 00:02:27,040
我认为这确实令人振奋，也很酷，但不幸的是，这更多是一个话题。

36
00:02:27,310 --> 00:02:31,050
在人工智能方面，而不仅仅是机器学习。

37
00:02:31,180 --> 00:02:35,020
那就是您知道可以单独完成整个课程。

38
00:02:35,020 --> 00:02:40,930
我们不会钻研训练机器狗来在本部分的本部分中行走。

39
00:02:40,960 --> 00:02:46,450
我们将要讨论的是多武装匪徒问题，这是一个不同的应用

40
00:02:46,810 --> 00:02:51,790
强化学习的机器学习分支。

41
00:02:52,100 --> 00:02:56,810
加上当然还有强化学习的其他许多其他应用。

42
00:02:56,950 --> 00:03:00,880
因此，继续讨论我们的多武装匪徒问题。

43
00:03:00,880 --> 00:03:05,810
因此，首先是多武装匪徒的权利。

44
00:03:05,820 --> 00:03:11,970
因此，想到的第一件事就像是强盗进入银行，等等，或者有人

45
00:03:11,980 --> 00:03:19,830
枪，但实际上是土匪或一个武装的乐队，这种事情让我们简化了。

46
00:03:20,000 --> 00:03:23,890
一个武装匪徒是一台老虎机。

47
00:03:23,890 --> 00:03:24,160
对。

48
00:03:24,160 --> 00:03:25,130
这就是其中之一。

49
00:03:25,180 --> 00:03:28,120
为何将其称为温暖的一只手臂土匪。

50
00:03:28,120 --> 00:03:30,560
嗯，那里有一段历史。

51
00:03:30,760 --> 00:03:35,490
过去，他们曾经在右边设置了此手柄，您仍然可以看到他们的电影和

52
00:03:35,490 --> 00:03:41,050
也许在某些地方您仍然可以找到这些老虎机，而实际上您必须拉动手柄

53
00:03:41,050 --> 00:03:46,480
因为现在它们都是电子设备，您只需按一下那里的按钮即可。

54
00:03:46,780 --> 00:03:57,120
而回到那儿，您必须拉动操纵杆才能使它像启动游戏一样起作用。

55
00:03:57,250 --> 00:04:00,020
因此，手臂。

56
00:04:00,040 --> 00:04:01,090
但是为什么称它为强盗。

57
00:04:01,090 --> 00:04:09,310
好吧，因为这些机器他们实际上会知道，这是最快的方法之一

58
00:04:09,310 --> 00:04:12,750
在赌场赔钱。

59
00:04:12,820 --> 00:04:14,430
他们会的。

60
00:04:14,890 --> 00:04:21,550
我认为他们有一天有50％的机会收回您的钱，所以他们

61
00:04:21,550 --> 00:04:25,950
当然，您的收入会比您的少。

62
00:04:26,170 --> 00:04:27,640
您实际上是赢家。

63
00:04:27,640 --> 00:04:34,750
这是关于您是否有50/50的机会，无论您是否真正赢得了胜利或获得了胜利，还是

64
00:04:34,750 --> 00:04:37,940
赔钱，但后来他们放了一个虫子。

65
00:04:38,020 --> 00:04:42,580
他们可以在线阅读一些内容，并在其中发现一个错误，即正在玩这些游戏的人是

66
00:04:42,580 --> 00:04:46,210
流失速度甚至超过了50％。

67
00:04:46,210 --> 00:04:50,380
所以说是强盗，因为它基本上是在抢你的钱。

68
00:04:50,530 --> 00:04:56,800
而且您知道最快的方法之一来输钱，这就是所谓的

69
00:04:56,800 --> 00:04:58,440
一名武装匪徒。

70
00:04:58,870 --> 00:05:00,580
还有几个小时的强盗。

71
00:05:00,580 --> 00:05:09,100
好吧，多武装匪徒问题是一个人来时面临的挑战

72
00:05:09,100 --> 00:05:15,870
当他没有一个机器时，最多要有五台或十个小时的编程时间

73
00:05:15,900 --> 00:05:21,650
示例将有一个10的示例，但是我们当然不会专门讨论这些机器

74
00:05:21,650 --> 00:05:28,870
这是历史性的问题，您现在将看到，我们将看到还有许多其他应用程序

75
00:05:29,770 --> 00:05:37,060
即使它被称为多重问题，它实际上也用于解决许多其他问题，例如

76
00:05:37,060 --> 00:05:38,080
好。

77
00:05:38,080 --> 00:05:42,590
因此，基本上，您在这里面临的挑战是您正确配置了其中五台计算机。

78
00:05:42,610 --> 00:05:52,150
以及您如何实际玩游戏，以最大程度地从实际游戏数量中获得回报

79
00:05:52,150 --> 00:05:52,330
玩。

80
00:05:52,330 --> 00:05:57,460
所以你知道你决定要玩一百或一千遍，

81
00:05:57,460 --> 00:05:58,810
您想最大化回报。

82
00:05:58,810 --> 00:06:04,090
您如何找出他们中的哪些人才能发挥最大的回报。

83
00:06:04,090 --> 00:06:12,040
那么要更详细地描述问题的问题，我们不得不提到的是这里的假设

84
00:06:12,040 --> 00:06:20,200
是每台机器的背后都有分布，所以有数字分布

85
00:06:20,330 --> 00:06:24,780
机器从哪个或哪个结果中挑选正确的结果。

86
00:06:24,790 --> 00:06:31,260
就像H1-Bs机器拥有自己的分布并挑选出结果一样。

87
00:06:31,270 --> 00:06:36,250
您可以拉动触发器，它只是随机地从其分布中挑选出结果

88
00:06:36,250 --> 00:06:39,010
您知道他们是赢还是输，赢了多少。

89
00:06:39,040 --> 00:06:43,660
您投入硬币后会损失多少使用量或可能会损失相同的钱。

90
00:06:43,810 --> 00:06:49,970
但是从根本上讲，它会根据计算机内置的分布情况告诉您是输还是输。

91
00:06:49,990 --> 00:06:53,760
但是这里的问题是您不知道这些分发权。

92
00:06:53,770 --> 00:06:59,110
您事先不知道什么是分布，并且假定它们是不同的

93
00:06:59,110 --> 00:06:59,820
机器。

94
00:06:59,830 --> 00:07:05,080
有时在某些计算机中它可能相似或相同，但默认情况下它们是不同的

95
00:07:06,130 --> 00:07:14,470
而您的目标是找出哪种分布最适合您，所以让我们

96
00:07:14,470 --> 00:07:14,650
看。

97
00:07:14,650 --> 00:07:16,660
所以有这些，这应该是对的。

98
00:07:16,660 --> 00:07:22,870
因此，例如，我们为这五台机器提供了五个发行版，您可以立即看到

99
00:07:22,870 --> 00:07:25,920
马上看这是最好的机器。

100
00:07:26,140 --> 00:07:28,160
显然是右边的那个。

101
00:07:28,210 --> 00:07:32,180
橙色的是最好的机器，因为它拥有最好的机器。

102
00:07:32,470 --> 00:07:36,970
您知道这是最偏左的提示，因为尾巴在左边。

103
00:07:36,970 --> 00:07:39,070
因此它得到了最有利的结果。

104
00:07:39,080 --> 00:07:41,320
获得了最高的平均中位数和众数。

105
00:07:41,410 --> 00:07:48,280
而且，如果您知道这些分布，并且您显然会去到第五台机器，

106
00:07:48,280 --> 00:07:53,800
您会一直在机器上押注机器，因为它是最好的

107
00:07:53,800 --> 00:07:54,520
发行权。

108
00:07:54,520 --> 00:07:58,980
因此，平均而言，您将获得最佳结果，但您不知道自己并不事先知道。

109
00:07:58,990 --> 00:08:05,330
而您的目标是弄清楚您是否知道这就像一场心灵游戏。

110
00:08:05,350 --> 00:08:12,240
您知道有很多关于机器学习的电影，并且确实使所有很棒的数学都很棒

111
00:08:12,250 --> 00:08:14,400
他们的使用方式很酷。

112
00:08:14,440 --> 00:08:23,410
真正好的电影是关于艾伦·图灵（Alan Turing）以及他以及他如何解决谜题的模仿游戏

113
00:08:23,410 --> 00:08:29,050
等等，但是类似的概念，您不知道其中哪一个是最好的

114
00:08:29,050 --> 00:08:29,570
想办法。

115
00:08:29,590 --> 00:08:33,810
但是同时，您已经在花钱做这件事了。

116
00:08:33,820 --> 00:08:39,310
您只需要知道花费更长的时间就可以得出权衡。

117
00:08:39,310 --> 00:08:46,770
您花费越长的时间弄清楚它，您可能会花在错误的钱上的钱就越多。

118
00:08:46,990 --> 00:08:49,310
因此，您必须很快找出答案。

119
00:08:49,540 --> 00:08:53,170
因此，有两个因素正在发挥作用。

120
00:08:53,200 --> 00:08:58,890
因此，您需要探索机器，以找出其中哪一台是最好的。

121
00:08:58,990 --> 00:09:05,740
同时，您需要尽快开始利用这些机器

122
00:09:05,740 --> 00:09:09,340
利用您的发现获得最大的回报。

123
00:09:09,340 --> 00:09:15,280
所以基本上，还有另一个方法上的缺点。 我们终于有了所有这一切，称为后悔和

124
00:09:15,370 --> 00:09:17,920
遗憾的是它是数学定义的。

125
00:09:17,920 --> 00:09:21,220
而且，如果您可以阅读更多有关此的内容，那么目标就是一个非常好的白皮书。

126
00:09:21,220 --> 00:09:27,170
这被称为使用置信界来进行权衡的开发和探索。

127
00:09:27,250 --> 00:09:37,720
皮拉（Pyrrha）是奥地利格拉茨科技大学的律师或PR

128
00:09:37,720 --> 00:09:43,600
纸上有很多细节，就像我没读完整的书，而是前几章

129
00:09:43,600 --> 00:09:44,490
很好

130
00:09:44,620 --> 00:09:53,060
如果您想详细介绍但基本上感到遗憾的是，当您使用非替代方法时会遭受痛苦

131
00:09:53,370 --> 00:09:54,580
不是最佳方法。

132
00:09:54,580 --> 00:09:54,810
对。

133
00:09:54,810 --> 00:10:01,720
因此，每当使用

134
00:10:01,720 --> 00:10:09,040
非选择机器，您会感到遗憾，可以将其量化为

135
00:10:09,040 --> 00:10:16,120
最好的结果和最好的结果，您就知道自己投入的所有这些钱

136
00:10:16,120 --> 00:10:20,840
您实际探索其他机器的机会成本。

137
00:10:20,850 --> 00:10:25,520
因此，您探索其他非最佳机器的时间越长，后悔就越高。

138
00:10:25,540 --> 00:10:29,710
但是同时如果您没有进行足够长时间的探索，那是正确的。

139
00:10:29,740 --> 00:10:36,020
如果您探索的时间不够长或不够长，那么您和次优的机器可能

140
00:10:36,020 --> 00:10:38,350
或可能显示为最佳机器。

141
00:10:38,350 --> 00:10:44,530
因此，例如，这台机器或此处写道：如果我们探索探索探索但我们花费的不足

142
00:10:44,530 --> 00:10:49,300
长时间探索时，我们可能会认为这是最好的机器，因为它获得了不错的回报

143
00:10:49,300 --> 00:10:53,710
接近这一目标，我们可能会在其余时间开始利用这一目标。

144
00:10:53,800 --> 00:10:56,440
但实际上，这是最好的一个。

145
00:10:56,440 --> 00:11:05,650
因此，目标是找到最好的，并开发最好的，但花费最少的时间进行探索

146
00:11:05,680 --> 00:11:06,540
他们全部。

147
00:11:06,610 --> 00:11:10,770
而且，当您进行探索时，您仍在赚钱，但不是从相对的机器上赚钱。

148
00:11:10,810 --> 00:11:12,150
这就是目标。

149
00:11:12,190 --> 00:11:18,040
这就是整个练习的重点，重要的是要了解这里有最好的

150
00:11:18,040 --> 00:11:18,320
一。

151
00:11:18,340 --> 00:11:25,920
因此，即使您知道这些机器有时也会像大奖一样，在那儿。

152
00:11:25,930 --> 00:11:28,640
但是我们假设只是那样。

153
00:11:28,690 --> 00:11:33,010
这些分布在那里是有限的。

154
00:11:33,040 --> 00:11:38,760
您正在寻找的最好的是强调或整个假设

155
00:11:38,760 --> 00:11:43,770
如果存在此问题的更复杂的选项和版本，则此问题。

156
00:11:43,780 --> 00:11:49,680
然后再次查看有关该主题的其他阅读材料。

157
00:11:49,690 --> 00:11:51,690
那就是更高级了。

158
00:11:51,700 --> 00:11:54,760
但是我们将使用它的目的就足够了。

159
00:11:54,790 --> 00:11:56,630
以及为什么对我们来说足够了。

160
00:11:56,770 --> 00:12:03,430
因为我们可以想到的最常见的现代应用就是我们要去的那个

161
00:12:03,430 --> 00:12:07,150
要探索的是广告瞧。

162
00:12:07,160 --> 00:12:09,850
因此，让我们看一些有趣的广告。

163
00:12:09,920 --> 00:12:15,050
所以只是免责声明，这与可口可乐没有任何联系，示例仅用于教育

164
00:12:15,050 --> 00:12:15,950
目的。

165
00:12:15,950 --> 00:12:16,300
好吧。

166
00:12:16,300 --> 00:12:17,640
让我们来看一下。

167
00:12:17,930 --> 00:12:25,940
我们假设可口可乐或某家公司想要开展一项广告系列，这将被称为“欢迎”

168
00:12:25,940 --> 00:12:28,180
参加可口可乐生活运动。

169
00:12:28,280 --> 00:12:33,140
如果您在线搜索该广告系列，您会发现他们知道数百种不同的广告，

170
00:12:33,260 --> 00:12:35,360
他们想出了这个运动。

171
00:12:35,520 --> 00:12:37,750
这是他们的一个例子。

172
00:12:37,790 --> 00:12:42,650
这些只是我从Google提取的一些图像，也许这些图像甚至是人们绘制的，但是我们要

173
00:12:42,650 --> 00:12:48,500
假设这些是我们也要加入广告系列的合法广告

174
00:12:48,500 --> 00:12:51,350
找出最合适的广告。

175
00:12:51,350 --> 00:12:52,220
所以我们有选择。

176
00:12:52,220 --> 00:12:53,250
第一。

177
00:12:53,270 --> 00:12:57,360
第二三，之前和第五。

178
00:12:57,560 --> 00:13:03,800
因此，现在我们的目标是找出可以发挥最大作用的广告。

179
00:13:03,800 --> 00:13:05,940
但是目前我们还不知道哪种方法最合适。

180
00:13:05,960 --> 00:13:13,640
因此，它背后没有任何分布，但该分布只有在成千上万的情况下才能为人所知

181
00:13:13,640 --> 00:13:15,780
和成千上万的人。

182
00:13:15,860 --> 00:13:20,120
查看这些广告，然后单击或不单击这些广告，这实际上将非常相似

183
00:13:20,120 --> 00:13:21,920
到我们将要看的示例。

184
00:13:21,920 --> 00:13:26,780
带有LUN的示例将在该示例的编程教程中逐步引导您

185
00:13:26,780 --> 00:13:27,900
实际有10个广告。

186
00:13:27,900 --> 00:13:29,050
甚至更多。

187
00:13:29,220 --> 00:13:31,220
因此，您在这里可以做什么。

188
00:13:31,220 --> 00:13:34,540
解决问题的一种方法就是运行AB测试驱动器。

189
00:13:34,550 --> 00:13:44,780
因此，以您的5或50或500个广告为例，运行包含多个AB测试的巨大AB测试，然后等到您获得

190
00:13:44,780 --> 00:13:53,300
足够大的样本中足够的样本，然后有把握地得出结论，这是最好的权利。

191
00:13:53,300 --> 00:13:59,780
但是，这样做的问题是您将花费大量的时间和金钱来正确地做到这一点。

192
00:13:59,780 --> 00:14:02,830
因此，AB测试是纯粹的探索权。

193
00:14:02,840 --> 00:14:08,260
您没有在利用最佳选择，而是在利用最佳选择

194
00:14:08,270 --> 00:14:10,460
利用非最佳选择权。

195
00:14:10,460 --> 00:14:16,220
因此，如果我们按照以前的分布进行分析，如果您只想进行AB测试，那么这是最好的分布，那么

196
00:14:16,520 --> 00:14:23,570
您统一分配或您统一使用这5个选项，因此与使用此选项一样多

197
00:14:23,580 --> 00:14:24,830
一个您正在使用所有四个。

198
00:14:24,830 --> 00:14:27,530
所有这四个基本上都是五个。

199
00:14:27,530 --> 00:14:35,210
所以基本上您是在利用它，但是在不知不觉中，您是以随机的方式到达的，因此

200
00:14:35,420 --> 00:14:38,460
AB测试仅用于探索。

201
00:14:38,460 --> 00:14:46,130
因此，挑战在于找出最好的方法，但要在探索时做到。

202
00:14:46,170 --> 00:14:53,000
虽然您在探索时不会利用最好的，但它会变干，所以找出其中的哪一个

203
00:14:53,000 --> 00:14:57,240
是过程中最好的。

204
00:14:57,920 --> 00:14:59,520
着火。

205
00:14:59,540 --> 00:15:03,190
在实际的启动活动中找出最合适的一种。

206
00:15:03,200 --> 00:15:04,960
所以不要没有两个阶段。

207
00:15:04,970 --> 00:15:07,130
您进行AB测试，然后最常使用它们。

208
00:15:07,130 --> 00:15:13,280
最好的，但实际上以最快的方式找出最好的，并开始加以利用

209
00:15:13,310 --> 00:15:14,270
一路上。

210
00:15:14,270 --> 00:15:17,690
这就是这里的挑战，这就是我们将要解决的问题。

211
00:15:17,930 --> 00:15:22,590
这就是多武装匪徒问题的现代应用。

212
00:15:22,790 --> 00:15:24,560
因此，希望您对此感到兴奋。

213
00:15:24,560 --> 00:15:27,620
我们提出了两种出色的算法。

214
00:15:27,620 --> 00:15:29,160
等不及要开始了。

215
00:15:29,210 --> 00:15:31,020
我在下一个教程中寻找。

216
00:15:31,070 --> 00:15:33,310
在此之前，请享受机器学习。

