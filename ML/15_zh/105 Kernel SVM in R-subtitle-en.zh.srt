1
00:00:00,270 --> 00:00:02,920
您好，欢迎来到本美术教程。

2
00:00:03,090 --> 00:00:08,180
以前，我们使用Python将内核实现为VM，而现在我们将在我们的内核上实现它。

3
00:00:08,490 --> 00:00:12,960
因此，对于那些尚未阅读Python教程和Colonel SVM的人，我迫不及待地向您展示

4
00:00:12,960 --> 00:00:14,130
结果。

5
00:00:14,160 --> 00:00:18,870
您肯定会看到内核作为类，您将如何变得强大

6
00:00:18,870 --> 00:00:24,150
分类器，尤其是在数据集不可线性分离的情况下。

7
00:00:24,150 --> 00:00:30,540
在这里，您将看到如何克服非线性不可分离性并对其进行分类

8
00:00:30,540 --> 00:00:33,630
正确使用我们的社交网络用户。

9
00:00:33,630 --> 00:00:39,140
因此，让我们现在对该内核SVM进行分类，并快速查看结果。

10
00:00:39,150 --> 00:00:42,680
因此，像往常一样，我们将从设置工作目录开始。

11
00:00:42,840 --> 00:00:46,960
所以现在我在桌面上，然后转到我的机械文件夹。

12
00:00:47,280 --> 00:00:50,820
第3部分分类部分将内核作为VM。

13
00:00:50,850 --> 00:00:56,730
在这里，我们确保您拥有社交网络，然后找到您的文件夹，如果那是

14
00:00:56,730 --> 00:01:02,310
如果您准备单击此处的更多按钮，则将文件夹设置为工作目录。

15
00:01:02,790 --> 00:01:04,360
这一切都很好。

16
00:01:04,800 --> 00:01:06,920
现在让我们开始制作模型。

17
00:01:07,230 --> 00:01:12,380
因此，我们在逻辑回归部分中制作了一个很棒的分类模板。

18
00:01:12,390 --> 00:01:14,400
因此，我们将使用它。

19
00:01:14,460 --> 00:01:18,670
所以在这里，我们将从头到尾处理一切。

20
00:01:18,720 --> 00:01:24,290
复制此文件，只需将其粘贴到内核中即可。

21
00:01:24,720 --> 00:01:31,440
现在我们只需要在此处创建或分类，因为模板是在

22
00:01:31,440 --> 00:01:35,560
使您的机器学习体验尽可能高效的方法。

23
00:01:35,790 --> 00:01:37,920
因此，我们将不会创建它。

24
00:01:37,920 --> 00:01:44,280
现在首先我们要知道选择所有数据预处理的第一步来预处理数据

25
00:01:44,280 --> 00:01:44,480
。

26
00:01:44,520 --> 00:01:50,130
因此，我们将按命令和控制并执行，一切都很好，您可以看到执行的代码

27
00:01:50,130 --> 00:01:51,240
正确地。

28
00:01:51,270 --> 00:01:55,820
现在我们可以快速查看训练集和测试集的数据集。

29
00:01:56,010 --> 00:02:02,400
因此，我们可以看到在300个数据集中有400个观测值被选择进行训练

30
00:02:02,400 --> 00:02:05,630
设置并选择100个参加测试。

31
00:02:05,670 --> 00:02:09,800
那是因为我们这里的0.75分配比率。

32
00:02:10,320 --> 00:02:16,530
快速提醒一下，该数据集是关于一个社交网络的，该社交网络包含有关

33
00:02:16,530 --> 00:02:17,580
社交网络。

34
00:02:17,580 --> 00:02:21,430
因此，我们有他们的年龄估算工资，最后一栏说明。

35
00:02:21,430 --> 00:02:28,410
如果是或否，则用户购买了社交网络业务类型的产品，即汽车公司

36
00:02:28,420 --> 00:02:28,600
。

37
00:02:28,800 --> 00:02:35,340
因此，这家汽车公司在社交网络上投放了广告，并且社交网络收集了这些信息

38
00:02:35,340 --> 00:02:37,520
看看用户的反应。

39
00:02:37,660 --> 00:02:43,940
因此，零表示用户未购买SUV，此处零表示用户购买了SUV。

40
00:02:43,940 --> 00:02:44,610
SUV。

41
00:02:44,850 --> 00:02:51,150
现在我们的目标是创建一个将这些用户分为两类的分类器

42
00:02:51,210 --> 00:02:55,760
未购买SUV的用户和购买SUV的用户类别。

43
00:02:55,830 --> 00:02:58,980
因此，让我们使用上校SVM来做到这一点。

44
00:02:59,010 --> 00:03:02,390
因此，现在我们需要创建分类器。

45
00:03:02,820 --> 00:03:06,610
和往常一样，它将非常直观和简单。

46
00:03:06,640 --> 00:03:08,440
我们将为此使用最佳的库。

47
00:03:08,520 --> 00:03:14,940
此外，如果您观看了SVM教程，还会发现我们使用的是相同的库，并且

48
00:03:14,940 --> 00:03:18,660
同样的功能，我们都只需要更改一些参数。

49
00:03:18,660 --> 00:03:19,410
因此，让我们这样做。

50
00:03:19,410 --> 00:03:25,710
对于那些不遵循SVM教程的人，您需要安装该软件包，然后执行此操作

51
00:03:25,800 --> 00:03:33,740
输入以下命令安装软件包，并在括号和引号中将其设为71岁。

52
00:03:33,900 --> 00:03:36,910
因此，这是作为EMS最受欢迎的软件包。

53
00:03:36,960 --> 00:03:39,410
另一个非常受欢迎的软件包是当前的实验室。

54
00:03:39,540 --> 00:03:41,640
您可以玩耍并查看。

55
00:03:41,670 --> 00:03:45,840
实际上非常简单，只是具有稍微不同的参数而具有相同的功能

56
00:03:45,840 --> 00:03:46,550
输入。

57
00:03:46,640 --> 00:03:48,900
对于VAMC来说，它也是一个很好的软件包。

58
00:03:48,900 --> 00:03:52,580
但是这里我们将在最受欢迎的软件包之一71中使用它。

59
00:03:52,770 --> 00:04:01,470
所以这是给你们的人，如果您去这里的包裹清单以及去10 71

60
00:04:02,070 --> 00:04:07,640
您会看到我的背上已经安装了此软件包，可能无法使用。

61
00:04:07,660 --> 00:04:12,060
这就是为什么我在此处添加此行的原因，以防万一您没有在软件包中安装软件包并且

62
00:04:12,100 --> 00:04:12,530
是。

63
00:04:12,750 --> 00:04:18,300
所以我现在就不执行此操作，您只需要选择此行并执行，它将安装软件包

64
00:04:18,300 --> 00:04:19,440
很快

65
00:04:19,440 --> 00:04:23,030
因此，我只想对此发表评论。

66
00:04:23,430 --> 00:04:29,400
我只按了命令转换策略，现在我们需要对该库做另外一件重要的事情

67
00:04:29,750 --> 00:04:36,450
您知道类型是在库中输入的，还是在括号中是名称，而不是在库的引号中

68
00:04:36,540 --> 00:04:36,750
。

69
00:04:36,820 --> 00:04:38,430
转到71。

70
00:04:38,750 --> 00:04:39,670
好。

71
00:04:39,690 --> 00:04:41,730
而且我们需要添加这一行是非常重要的情况。

72
00:04:41,730 --> 00:04:47,520
我们拥有一些自动化脚本，您知道这些脚本在当今道德中已成为核心。

73
00:04:47,550 --> 00:04:53,010
因此，假设您有一个工作流程，并且想要将内核作为VM模型包括在内，并且此工作流程很好

74
00:04:53,010 --> 00:04:54,920
您将需要一些自动化脚本。

75
00:04:54,990 --> 00:05:00,300
因此，添加此时间很重要，因为这会自动选择您的媒体库，因为

76
00:05:00,300 --> 00:05:04,140
可以看到此处未选中它意味着它没有以某种方式导入。

77
00:05:04,200 --> 00:05:08,130
因此，您需要此行，它将自动选择此软件包。

78
00:05:08,490 --> 00:05:09,170
好。

79
00:05:09,470 --> 00:05:11,920
现在，我们准备创建分类器。

80
00:05:12,210 --> 00:05:18,450
因此它将与SVM相同，它实际上是具有Linux内核的不错的VM，在这里

81
00:05:18,450 --> 00:05:23,350
不打算使用或让我们知道，我们将使用其他将是Galchen内核的东西。

82
00:05:23,580 --> 00:05:24,330
因此，让我们这样做。

83
00:05:24,330 --> 00:05:29,940
我们将把我们的分类器称为普通气化器，它等于。

84
00:05:29,940 --> 00:05:37,080
然后在这里我们将使用V.M. 任何一个库的事件的功能，现在我们需要

85
00:05:37,080 --> 00:05:38,670
导入气压计。

86
00:05:38,730 --> 00:05:40,920
和往常一样，让我们​​看一下。

87
00:05:41,190 --> 00:05:42,190
这里是。

88
00:05:42,280 --> 00:05:44,040
现在点击这个。

89
00:05:44,340 --> 00:05:48,830
这里是SVM ETN 71的文档。

90
00:05:49,200 --> 00:05:51,330
好的，让我们看一下参数。

91
00:05:51,450 --> 00:05:53,220
第一个参数是公式。

92
00:05:53,220 --> 00:05:59,710
因此，就您而言，它将一直购买到最后一个点，该点代表所有

93
00:05:59,700 --> 00:06:00,920
自变量。

94
00:06:01,140 --> 00:06:03,560
这样我们就知道了数据。

95
00:06:03,720 --> 00:06:08,910
好的，所以是的，您需要指定数据，因为您要指定要在其上进行数据设置

96
00:06:08,910 --> 00:06:11,860
将您的内核训练为VM模型。

97
00:06:11,910 --> 00:06:17,260
因此，我们需要指定等于训练集的数据，因为我们正在训练集中训练模型，然后

98
00:06:17,280 --> 00:06:19,940
X Y和比例在这里并不重要。

99
00:06:20,070 --> 00:06:24,330
真正重要的是类型和内核。

100
00:06:24,330 --> 00:06:29,850
所以类型是您是否要建立一个回归模型，如V.M. 对于回归

101
00:06:29,850 --> 00:06:36,540
我们是在回归部分看到的，还是在推断分类时看到的，

102
00:06:36,540 --> 00:06:37,330
作为V。

103
00:06:37,650 --> 00:06:44,370
因此，您需要指定C分类类型，这是分类的默认类型

104
00:06:44,380 --> 00:06:45,190
支持向量机

105
00:06:45,250 --> 00:06:52,780
请记住，我们选择了EPM回归，它是SVM回归的默认类型。

106
00:06:52,870 --> 00:06:58,030
但是这里我们是分类人员，他们将选择此分类类型，然后选择最重要的分类

107
00:06:58,020 --> 00:06:58,880
是内核。

108
00:06:58,990 --> 00:07:00,730
在这里，我们跳到了更高的层次。

109
00:07:00,780 --> 00:07:06,390
我们正在制作比上一部分中的SBM更复杂的SVM，这是线性的

110
00:07:06,390 --> 00:07:08,380
我们的内核为V.M.

111
00:07:08,550 --> 00:07:15,600
但是现在我们想成为专业人士，我们选择Galchen作为V.M.。 您会看到这是一项了不起的工作

112
00:07:15,920 --> 00:07:21,960
在对社交网络中的新用户进行分类时，因为记住内核为VM，那么他们就是

113
00:07:21,960 --> 00:07:28,330
使我们的SVM模型成为线性分类器，因此将两个类别的分隔符分开

114
00:07:28,320 --> 00:07:33,030
用户在这里是一条直线，因此无法在这里吸引用户。

115
00:07:33,030 --> 00:07:35,760
这使我们的数据集非线性可分离。

116
00:07:36,150 --> 00:07:41,540
因此，在这里我们将选择气刨核，它将是径向基础核。

117
00:07:41,550 --> 00:07:44,870
实际上，我们不会写径向基础，而只是写无线电。

118
00:07:44,880 --> 00:07:45,950
这就是它的工作方式。

119
00:07:46,000 --> 00:07:48,600
但是Galchen内核是无线电。

120
00:07:48,610 --> 00:07:50,300
实际上，您可以在此处看到公式。

121
00:07:50,520 --> 00:07:54,390
Carroll给了您缓存内核的公式，就在这里。

122
00:07:54,390 --> 00:08:00,680
好的，现在让我们回到我们的代码并实现它。

123
00:08:00,790 --> 00:08:08,910
我想我记得第一个参数是公式，然后在这里我们首先要考虑

124
00:08:08,910 --> 00:08:10,940
购买变量。

125
00:08:10,990 --> 00:08:17,190
不，如果您返回到她的数据集，则这是因变量，需要先购买此变量，然后再购买

126
00:08:17,190 --> 00:08:23,530
是连续出现，然后是一个点，以接受所有自变量的训练集。

127
00:08:23,820 --> 00:08:27,670
那是我们正在变老，估计很抱歉。

128
00:08:28,530 --> 00:08:34,730
然后可以走到下一个参数Enter，然后是第二个参数。

129
00:08:34,750 --> 00:08:41,880
所以我记得的第二个参数是数据再次等于训练集，然后是下一个参数

130
00:08:41,880 --> 00:08:50,250
是类型类型等于C分类，实际上我们并不需要在这里输入类型，因为

131
00:08:50,250 --> 00:08:51,550
这是默认类型。

132
00:08:51,960 --> 00:08:58,990
但是让我们指定它来区分V.M. 作为我们的回归和作为VM的回归

133
00:08:58,990 --> 00:09:01,530
分类内核是V.M. 这里。

134
00:09:01,870 --> 00:09:08,070
然后我们当然会为该部分内核VM添加必要的参数，这当然是

135
00:09:08,350 --> 00:09:16,710
内核，这就是我们选择更复杂的内核的地方，这就是高斯内核。

136
00:09:16,910 --> 00:09:18,270
无线电。

137
00:09:18,820 --> 00:09:19,420
好吧。

138
00:09:19,430 --> 00:09:28,200
现在我们的分类器已经准备就绪，让我们立即选择它并完善我们的分类器分类器

139
00:09:28,200 --> 00:09:29,120
现在建成。

140
00:09:29,350 --> 00:09:34,380
因此，现在让我们用它来预测我们要选择的测试结果。

141
00:09:34,380 --> 00:09:38,160
该行只需按命令和控制按回车即可执行。

142
00:09:38,460 --> 00:09:39,750
这是我们的白色印刷机。

143
00:09:39,750 --> 00:09:40,980
我们来看一下。

144
00:09:40,990 --> 00:09:45,400
为什么弗雷德（Fred）我们在控制台中直接在这里输入，请按Enter。

145
00:09:45,660 --> 00:09:49,760
这就是测试集的所有预测。

146
00:09:49,770 --> 00:09:52,890
所以有100个预测，让我们看一下第一个。

147
00:09:53,130 --> 00:09:59,200
因此，我们需要对此进行比较，为什么prend是预测的向量，而预测的真实结果却是这样。

148
00:09:59,190 --> 00:10:01,410
观察是否有真实结果。

149
00:10:01,460 --> 00:10:02,460
但是，是或否。

150
00:10:02,460 --> 00:10:06,600
SUV，为此，我们需要在此处进行测试以进行检查。

151
00:10:06,850 --> 00:10:12,370
因此，让我们看到一两个三四个和五个用户没有购买SUV。

152
00:10:12,370 --> 00:10:19,220
实际上，根据我们的预测，我们预测这五个用户不会购买SUV。

153
00:10:19,330 --> 00:10:20,750
因此，这是一些正确的预测。

154
00:10:20,790 --> 00:10:22,210
这是一个很好的开始。

155
00:10:22,520 --> 00:10:27,720
如果我们看下一个观察，我们这里有一个，这里有一个，这里有一个。

156
00:10:27,750 --> 00:10:30,810
因此，这使八个第一预测成为正确的预测。

157
00:10:30,820 --> 00:10:38,150
这是我们的第一个错误，第一个错误的预测，因为对于22号用户

158
00:10:38,160 --> 00:10:41,660
类别价值预测该用户不会购买SUV。

159
00:10:41,860 --> 00:10:43,940
实际上，确实如此。

160
00:10:43,950 --> 00:10:48,810
如果您查看数字22，我们可以看到这里有一个数字，表示该用户购买了

161
00:10:48,820 --> 00:10:49,940
SUV。

162
00:10:50,120 --> 00:10:55,430
可以，但是查看这些预测的最佳方法是使用混淆矩阵。

163
00:10:55,430 --> 00:10:56,540
因此，让我们这样做。

164
00:10:56,540 --> 00:10:59,960
该部分已经在这里，我们无需更改任何内容。

165
00:10:59,960 --> 00:11:02,740
该模板可简化所有工作。

166
00:11:02,960 --> 00:11:07,390
因此，让我们喜欢命令和控制的设计，然后按Enter键即可执行。

167
00:11:07,460 --> 00:11:09,560
在这里，我们有了矩阵。

168
00:11:09,710 --> 00:11:14,620
因此，我们将在控制台中对其进行查看，以便查看“我在这里输入”。

169
00:11:14,810 --> 00:11:16,390
这是矩阵。

170
00:11:16,730 --> 00:11:17,140
好。

171
00:11:17,150 --> 00:11:27,200
所以我们这里有58加32等于90正确的预测，四加6等于10不正确的预测

172
00:11:27,200 --> 00:11:28,170
预测。

173
00:11:28,520 --> 00:11:29,590
因此，这还不错。

174
00:11:29,840 --> 00:11:34,970
但是现在最激动人心的部分就要来了，因为我们将要可视化训练集的结果

175
00:11:35,710 --> 00:11:41,090
实际上，我们现在无需更改任何东西，除了标题分类器，然后

176
00:11:41,090 --> 00:11:47,590
在这里，您需要在测试集中将内核指定为VM，将内核指定为VM。

177
00:11:47,630 --> 00:11:51,560
上校和我们一样。

178
00:11:52,490 --> 00:11:52,820
好吧。

179
00:11:52,820 --> 00:11:57,610
现在我们可以喝杯咖啡，然后执行一下并观察结果。

180
00:11:57,640 --> 00:11:59,300
因此，我们将执行此操作。

181
00:11:59,510 --> 00:12:05,660
我们将首先在这里查看结果并将其按入控制器并执行

182
00:12:10,190 --> 00:12:13,770
哇，这些是上校SVM的美丽结果。

183
00:12:14,090 --> 00:12:16,900
我们可以在这里看到如何绘制此曲线以进行分类。

184
00:12:16,880 --> 00:12:22,340
那么这里的大多数用户和社交网络都是如此，因为我们这里有一个二维空间来存储数据

185
00:12:22,350 --> 00:12:27,280
设置意味着数据被映射到三维空间。

186
00:12:27,530 --> 00:12:33,350
然后在这个维空间上设法使数据线性可分离，以便可以找到

187
00:12:33,440 --> 00:12:40,340
线性或超平面，以更好的方式将两个类别分开，然后投影回

188
00:12:40,340 --> 00:12:47,660
这个二维空间最终可以在这里获得更好地分离的曲线

189
00:12:47,660 --> 00:12:51,490
而不是线性类两个类，或者您可以在此处使用直线。

190
00:12:51,640 --> 00:12:55,960
正如我们看到的逻辑回归或SVM一样，我们以线性核结束。

191
00:12:56,120 --> 00:13:00,920
那就是事实，那是内核女同志在幕后所做的出色工作

192
00:13:00,950 --> 00:13:03,040
所以我们可以说矛盾。

193
00:13:03,140 --> 00:13:08,480
因此，对于那些第一次看到此内容的人，我会迅速提醒您要点是什么

194
00:13:08,480 --> 00:13:10,840
这是真实的观察结果。

195
00:13:10,850 --> 00:13:16,700
因此，红点是实际未购买SUV的用户，绿点是用户

196
00:13:16,700 --> 00:13:21,190
谁购买了SUV，然后我们在这里看到的区域就是预测区域。

197
00:13:21,200 --> 00:13:26,810
因此，红色区域是我们的模型预测用户不购买SUV的区域，绿色区域

198
00:13:26,810 --> 00:13:30,520
区域是我们的模型预测使用偏差的区域。

199
00:13:30,680 --> 00:13:36,950
因此，例如，这意味着对于该特定用户，绿色区域中的红点

200
00:13:36,950 --> 00:13:41,840
做出错误的预测，因为事实是用户昨天没有购买。

201
00:13:41,990 --> 00:13:47,150
但是由于该用户位于绿色区域，这意味着该模型预测该用户购买了

202
00:13:47,380 --> 00:13:50,180
SUV，即使那不是现实生活中发生的事情。

203
00:13:50,360 --> 00:13:52,090
因此，这就是图形有关的原因。

204
00:13:52,370 --> 00:13:57,370
这是内核作为VM算法的非线性分隔符。

205
00:13:57,440 --> 00:14:04,220
而且由于有了这个非线性的分隔符，我们作为VM的内核可以正确地对此处的那些用户进行分类

206
00:14:04,220 --> 00:14:09,380
线性sequitur并非如此，因为既然我们有了直线，就无法捕捉到这些直线

207
00:14:09,410 --> 00:14:10,980
用户在正确的Kagami中。

208
00:14:11,030 --> 00:14:15,740
这是绿色类别，因为这些用户实际上是在现实生活中购买了SUV，因此他们应该

209
00:14:15,740 --> 00:14:16,730
在绿色区域。

210
00:14:16,760 --> 00:14:21,380
线性分隔符不是这种情况，内核作为VM分隔符是这种情况

211
00:14:21,620 --> 00:14:23,630
因为它是非线性分类器。

212
00:14:24,020 --> 00:14:24,470
完善。

213
00:14:24,470 --> 00:14:30,440
现在让我们看一下测试结果，看看我们的模型在新观察结果上的表现如何

214
00:14:30,440 --> 00:14:34,400
它仍然可以分类和预测新观测的结果。

215
00:14:34,730 --> 00:14:42,210
因此，我们将要执行此操作，只需要选择此按下命令来控制我们并执行即可。

216
00:14:43,460 --> 00:14:45,610
这是测试结果。

217
00:14:45,620 --> 00:14:45,980
好。

218
00:14:46,010 --> 00:14:47,750
看起来也很棒。

219
00:14:47,750 --> 00:14:52,790
首先要了解的重要一点是，我们在这里看到的试剂与

220
00:14:52,790 --> 00:14:54,030
我们在数据集中看到了。

221
00:14:54,230 --> 00:14:59,240
如果您回到火车上，然后回到下降，您会发现这里的区域没有

222
00:14:59,240 --> 00:15:04,600
仅更改观察点会更改，因为这些当然是新的观察点。

223
00:15:04,670 --> 00:15:10,400
因此，在这里我们可以看到您所说的上校在对新观察结果进行分类方面做得非常出色

224
00:15:10,390 --> 00:15:16,130
因为所有这些测试的观察结果在这里都是其他用户，因为这些点是

225
00:15:16,120 --> 00:15:21,260
红色，并且它们位于红色区域中，在该区域中，分类预测用户不会

226
00:15:21,260 --> 00:15:22,340
买SUV。

227
00:15:22,370 --> 00:15:24,200
因此，这是正确的预测。

228
00:15:24,220 --> 00:15:28,660
对于这些家伙来说，这里所有落入绿色区域的绿点都一样。

229
00:15:28,880 --> 00:15:34,970
当然，我们还有那些不正确的预测，例如，这个绿色用户

230
00:15:35,240 --> 00:15:36,860
在红色区域也是如此。

231
00:15:36,860 --> 00:15:39,040
这两个绿色是那三个。

232
00:15:39,080 --> 00:15:41,420
然后我们有红色用户这个这个这个。

233
00:15:41,570 --> 00:15:48,890
所以四五六七七八九，实际上是10，我们可以看到这里有一点绿点

234
00:15:48,950 --> 00:15:51,110
躲在红点后面。

235
00:15:51,550 --> 00:15:51,900
好。

236
00:15:51,910 --> 00:15:53,750
因此，这绝对是一个很好的工作。

237
00:15:53,780 --> 00:15:59,570
您将看到下一个分类器将如何对分隔进行不同的分类。

238
00:15:59,650 --> 00:16:01,300
您将看到不会有曲线。

239
00:16:01,310 --> 00:16:04,880
这将是另外一回事，我将让您找出惊喜。

240
00:16:05,300 --> 00:16:11,090
但是当您的数据无法线性分离时，作为VM的内核绝对是一个很好的分类器，我们

241
00:16:11,090 --> 00:16:15,950
可以看到它如何绝对改善了我们在物流中看到的线性转移的结果

242
00:16:15,950 --> 00:16:17,260
回归也是如此。

243
00:16:17,600 --> 00:16:21,770
好的，谢谢您观看有关Colonel SVM的教程。

244
00:16:21,770 --> 00:16:23,220
我希望你喜欢它。

245
00:16:23,240 --> 00:16:27,370
正如我告诉你的那样，下一位客人将有更多惊喜，因此您将看到

246
00:16:27,380 --> 00:16:28,910
结果会很有趣。

247
00:16:29,120 --> 00:16:34,010
因此，我期待在下一节中与您见面，并告诉他们喜欢机器学习

