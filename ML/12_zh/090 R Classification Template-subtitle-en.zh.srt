1
00:00:00,240 --> 00:00:02,470
您好，欢迎来到这是辛苦的艺术。

2
00:00:02,700 --> 00:00:07,680
所以这个故事不会像通常的那样，因为基本上我们要做的只是

3
00:00:07,740 --> 00:00:13,650
制作模板以更有效地构建我们未来的分类模型，因为事实上

4
00:00:13,650 --> 00:00:18,900
已经建立了我们的第一个分类模型，即逻辑回归模型，然后是未来

5
00:00:18,900 --> 00:00:24,640
部分，我们将建立新的分类道德，例如VM支持向量机内核

6
00:00:24,740 --> 00:00:30,430
SVM海军基础决策树分类以及Ranum第一分类。

7
00:00:30,660 --> 00:00:35,900
因此，您知道我们将在与数据集相同的社交网络数据集中构建这些模型。

8
00:00:36,000 --> 00:00:40,560
因此，我们将为将来的所有分类模型制作一个模板。

9
00:00:40,710 --> 00:00:43,720
现在，让我们制作分类模板。

10
00:00:43,920 --> 00:00:48,690
也许您已经注意到，我们将非常轻松地制作此模板，因为唯一

11
00:00:48,690 --> 00:00:55,470
我们削减逻辑回归特定内容的代码部分仅在此部分中，因为

12
00:00:55,920 --> 00:00:59,960
我们使用GNN函数创建逻辑回归分类器。

13
00:01:00,150 --> 00:01:03,840
但是，在其他部分中，所有内容都是纯归纳的。

14
00:01:03,870 --> 00:01:09,480
您知道我们在这里使用我们的分类变量，它确实是逻辑回归所产生的Disko

15
00:01:09,510 --> 00:01:11,050
在下一部分中。

16
00:01:11,060 --> 00:01:15,990
该分类器将是其他东西，在本节中相同，这里我们不编写任何代码

17
00:01:15,990 --> 00:01:18,620
与逻辑回归特别相关。

18
00:01:18,630 --> 00:01:22,230
在此部分中，有关结果可视化的内容也相同。

19
00:01:22,230 --> 00:01:25,110
我们使用的唯一变量是分类器。

20
00:01:25,440 --> 00:01:30,600
因此，没有任何与逻辑回归直接相关的内容，此处与本节相同。

21
00:01:30,600 --> 00:01:33,100
我们使用的唯一变量是分类器。

22
00:01:33,180 --> 00:01:39,510
因此，如果我们在此处给出另一个定义进行分类，则此处的代码将完全适用

23
00:01:39,690 --> 00:01:43,070
我将在以后的部分中介绍这个新课程。

24
00:01:43,140 --> 00:01:48,510
这就是为什么它是如此简单的原因，因此值得这样做，因为接下来的模型将被创建

25
00:01:48,510 --> 00:01:49,080
。

26
00:01:49,110 --> 00:01:53,160
因此，我将把所有事情都从这里开始。

27
00:01:53,160 --> 00:02:00,270
将其复制并粘贴到我将来的分类模板中，现在我们的分类模板为

28
00:02:00,270 --> 00:02:01,380
快好了。

29
00:02:01,380 --> 00:02:07,800
我们只需要删除此部分，因为这与逻辑回归直接相关，因为

30
00:02:07,800 --> 00:02:12,830
在这里，我们使用GNN函数，该函数仅用于构建逻辑回归模型。

31
00:02:12,990 --> 00:02:16,890
但是您会在下一节中了解我们将要进行的下一个分类器。

32
00:02:17,070 --> 00:02:22,920
好吧，我们将在这里拥有这个分类变量，它将作为我们未来分类的分类器

33
00:02:22,920 --> 00:02:23,590
楷模。

34
00:02:23,670 --> 00:02:29,160
然后在这里您知道我们将使用构建此分类模型所需的正确函数，然后

35
00:02:29,250 --> 00:02:30,990
其余的都准备好了。

36
00:02:31,080 --> 00:02:36,630
然后我们将在这里定义新的分类器，因为我们在这里有了Caspari并可以很好地预测函数

37
00:02:36,630 --> 00:02:41,850
我们不会在这里进行任何更改，这里也变得更简单，因为唯一的变量

38
00:02:41,850 --> 00:02:43,820
我们使用的是分类器。

39
00:02:43,890 --> 00:02:48,290
它将被定义为新分类模型的分类器。

40
00:02:48,540 --> 00:02:53,370
因此，请记住这一点，并让您知道来提醒我们我们需要做的事情。

41
00:02:53,580 --> 00:03:01,650
我将在此处添加一个说法，这是我们在此处创建分类器的部分。

42
00:03:01,650 --> 00:03:02,220
好吧。

43
00:03:02,250 --> 00:03:04,960
这就是创建分类器的部分。

44
00:03:04,980 --> 00:03:10,110
顺便说一下，您可以在数据集和业务问题中完全使用相同的位置，

45
00:03:10,110 --> 00:03:14,820
只需更改数据集的名称并选择感兴趣的列，然后更改

46
00:03:14,820 --> 00:03:18,080
此处和此处的depan变量的名称也是如此。

47
00:03:18,690 --> 00:03:23,730
但是，您只需要做的就是在此处创建分类器，以便您选择分类

48
00:03:23,760 --> 00:03:26,700
您想要，然后一切都准备就绪。

49
00:03:26,850 --> 00:03:31,890
您将可以预测，因此您将在这里注意索引并确定条件

50
00:03:31,890 --> 00:03:38,370
矩阵化并可视化您的训练集和测试结果，因此您也可以完全使用此模板

51
00:03:38,370 --> 00:03:39,500
为您的数据集。

52
00:03:39,570 --> 00:03:45,270
无疑，此模板已准备好构建我们将在此构建的未来分类道德

53
00:03:45,270 --> 00:03:45,820
部分。

54
00:03:45,960 --> 00:03:47,300
所以我们开始。

55
00:03:47,350 --> 00:03:48,290
准备好模板。

56
00:03:48,360 --> 00:03:54,100
好吧，我们仍然可以通过用分类器代替此处的逻辑回归来进一步推广它。

57
00:03:54,480 --> 00:04:02,670
同样，我们也可以在这里通过分类器来代替逻辑回归。

58
00:04:04,450 --> 00:04:08,210
现在，该模板已完全准备好并已全面推广。

59
00:04:08,400 --> 00:04:12,800
因此，您将看到在构建将来的分类模型时它将多么有效。

60
00:04:12,810 --> 00:04:14,980
我期待与您一起创建这些模型。

61
00:04:15,090 --> 00:04:16,860
在那之前享受机器学习

