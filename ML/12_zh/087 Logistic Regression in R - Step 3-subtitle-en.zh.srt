1
00:00:00,150 --> 00:00:02,590
您好，欢迎来到本美术教程。

2
00:00:02,670 --> 00:00:07,650
所以现在我们将逻辑回归拟合到训练集，我们将进行预测性检验

3
00:00:07,660 --> 00:00:12,120
使用我们在上一教程中构建的分类器的结果。

4
00:00:12,420 --> 00:00:17,790
因此，通常我们可以一步完成此操作，但是对于逻辑回归，我们将分两步完成

5
00:00:17,880 --> 00:00:23,790
而且我们对具有0和1预测而不是概率更感兴趣。

6
00:00:23,790 --> 00:00:25,870
所以首先让我们考虑一下概率。

7
00:00:25,860 --> 00:00:32,790
因此，我们在哪里称它们为问题先驱，即周期的向量

8
00:00:32,790 --> 00:00:38,390
分类器对我们的测试集观测值的预测概率的向量。

9
00:00:38,670 --> 00:00:41,930
因此，财产等于预测。

10
00:00:41,940 --> 00:00:48,180
因此，我们将使用这个漂亮的函数根据我们的Jhelum分类器来预测概率

11
00:00:48,190 --> 00:00:48,520
。

12
00:00:48,840 --> 00:00:55,170
说到分类器，这是我们漂亮函数中的第一个参数，因此在这里我们可以将分类器

13
00:00:56,670 --> 00:01:05,430
然后出现下一个参数是类型，对于逻辑回归，我们应该选择响应类型

14
00:01:05,940 --> 00:01:09,580
因为这将为我们提供单个向量中列出的概率。

15
00:01:09,840 --> 00:01:11,320
这就是我们想要的。

16
00:01:12,030 --> 00:01:16,520
然后，我们必须指定我们要预测的新观测值。

17
00:01:16,800 --> 00:01:22,000
因此，在我们的案例中，这些新观察值就是测试集观察值。

18
00:01:22,380 --> 00:01:32,130
因此，新数据等于测试集，我们将删除测试的最后一列，因为

19
00:01:32,430 --> 00:01:36,090
最后一列是因变量，这就是我们要预测的。

20
00:01:36,090 --> 00:01:38,190
因此，我们只会在负3时进行测试。

21
00:01:38,190 --> 00:01:42,860
那就是测试集的年龄和薪水这两个独立变量。

22
00:01:42,870 --> 00:01:45,440
好的，让我们总结一下这一行。

23
00:01:45,510 --> 00:01:53,190
我们正在使用分类器（即逻辑回归分类器）预测测试集的观察结果

24
00:01:53,200 --> 00:01:53,830
。

25
00:01:54,390 --> 00:01:54,700
好吧。

26
00:01:54,700 --> 00:02:01,110
这返回了概率，因为如您所见，如果我选择此行并在这里键入，则在此处执行

27
00:02:01,110 --> 00:02:09,370
控制台中的问题pred我将得到，如您所见，我将获得每个测试的概率

28
00:02:09,370 --> 00:02:10,800
设定观察。

29
00:02:11,190 --> 00:02:12,610
因此，例如。

30
00:02:12,990 --> 00:02:14,510
让我们去测试集。

31
00:02:14,700 --> 00:02:19,920
第一个观测值已索引到实际结果为零。

32
00:02:19,920 --> 00:02:24,140
这意味着第二个用户没有购买SUV。

33
00:02:24,160 --> 00:02:31,280
现在，如果我们返回逻辑回归，则可以看到该用户的两个proc预定项

34
00:02:31,360 --> 00:02:33,080
0.06 10。

35
00:02:33,240 --> 00:02:38,820
那么，这个概率究竟是什么呢，那个概率就是因变量的概率

36
00:02:38,820 --> 00:02:39,940
等于一。

37
00:02:40,050 --> 00:02:44,430
那就是用户购买SUV的概率。

38
00:02:44,430 --> 00:02:47,750
因此，由于它很小，因此此处为0 16。

39
00:02:47,760 --> 00:02:53,640
这意味着分类器预测因变量相等的可能性非常低

40
00:02:53,640 --> 00:02:54,410
到1。

41
00:02:54,420 --> 00:03:00,510
这意味着它可以预测第二位用户购买SUV的机会非常低。

42
00:03:01,110 --> 00:03:09,390
因此总之，归还用户购买SUV的预测概率

43
00:03:09,480 --> 00:03:13,500
我们真的不希望我们宁愿得到零和一的结果。

44
00:03:13,650 --> 00:03:18,630
为此，这很简单，我们将要做某种转换。

45
00:03:19,140 --> 00:03:27,420
因此，我们将创建一个预测结果向量，我们将其称为y pred equals，然后

46
00:03:27,420 --> 00:03:33,950
我们将仅使用if来将这些概率转换为零和一个结果。

47
00:03:33,960 --> 00:03:36,920
所以他要写其他的话。

48
00:03:37,020 --> 00:03:43,120
因此，if else的第一个参数是条件，而该条件将成为问题。

49
00:03:43,990 --> 00:03:55,590
Pred大于0.5，因为如果pred大于0.5，则意味着用户有更多机会购买

50
00:03:55,590 --> 00:03:56,870
SUV。

51
00:03:56,880 --> 00:03:59,780
因此，在那种情况下，这意味着我们想要预测一个。

52
00:03:59,930 --> 00:04:05,640
实际上，if else函数的第二个参数是您要在这种情况下获取的结果

53
00:04:05,640 --> 00:04:06,410
是真的。

54
00:04:06,600 --> 00:04:09,960
因此，在这里我们将正确放置一个。

55
00:04:10,080 --> 00:04:14,850
最后一个参数是如果此条件为false则要返回的结果。

56
00:04:15,030 --> 00:04:20,690
如果此条件为假，则意味着预测概率低于0.5。

57
00:04:20,700 --> 00:04:26,880
这意味着用户购买SUV的机会更少，因此它将为零。

58
00:04:27,570 --> 00:04:28,440
就是这样。

59
00:04:28,440 --> 00:04:33,190
现在，您将看到我是否选择了这一行并执行。

60
00:04:33,420 --> 00:04:39,840
好吧，现在让我们看看白面包。

61
00:04:40,080 --> 00:04:42,230
我只有零或一。

62
00:04:42,300 --> 00:04:48,960
我不再有这些概率，并且记得使用的实际结果是两个。

63
00:04:48,960 --> 00:04:52,010
这就是现实中发生的事情。

64
00:04:53,070 --> 00:04:55,700
这是分类的预测变量0。

65
00:04:55,740 --> 00:04:57,820
因此，这是一个正确的预测。

66
00:04:57,870 --> 00:05:01,630
那是因为记住之前的概率非常低。

67
00:05:01,740 --> 00:05:06,380
因此它低于0.5，因此返回零。

68
00:05:06,930 --> 00:05:07,310
好吧。

69
00:05:07,320 --> 00:05:09,430
因此，我们预测了测试结果。

70
00:05:09,690 --> 00:05:10,320
这是一件好事。

71
00:05:10,320 --> 00:05:18,000
现在，由于要构建的混淆矩阵，我们将评估此预测

72
00:05:18,090 --> 00:05:19,460
在下一个教程中。

73
00:05:19,560 --> 00:05:21,180
因此，我期待与您相会。

74
00:05:21,360 --> 00:05:23,190
在此之前，请享受机器学习。

