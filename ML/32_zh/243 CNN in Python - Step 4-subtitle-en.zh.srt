1
00:00:00,490 --> 00:00:02,870
您好，欢迎来到本Python教程。

2
00:00:02,950 --> 00:00:09,030
因此，我们只是使用顺序类将卷积网络初始化为一系列图层。

3
00:00:09,160 --> 00:00:13,060
现在我们要添加CNN的第一层。

4
00:00:13,180 --> 00:00:17,710
但是，在我们添加第一层之前，让我们快速提醒一下构建过程。

5
00:00:17,710 --> 00:00:21,120
卷积神经网络就在幻灯片上。

6
00:00:21,310 --> 00:00:25,000
因此，CNN的构建过程需要四个步骤。

7
00:00:25,000 --> 00:00:32,360
步骤1卷积步骤2最大假脱机步骤3展平和步骤4完全连接

8
00:00:32,380 --> 00:00:35,760
这马桶将照顾第一步卷积。

9
00:00:35,920 --> 00:00:40,830
因此，让我们也快速提醒一下该卷积步骤的含义。

10
00:00:40,840 --> 00:00:43,370
因此，我们有一个输入图像。

11
00:00:43,570 --> 00:00:47,290
在我们的例子中，输入图像将是猫或狗的图像。

12
00:00:47,530 --> 00:00:51,730
但是，在此幻灯片的示例中，这是笑脸的输入图像。

13
00:00:51,790 --> 00:00:55,490
我们将此笑脸图像转换为带有像素值的表格。

14
00:00:55,600 --> 00:00:58,810
这就是我们使用所有1和0像素得到的结果。

15
00:00:58,810 --> 00:01:04,210
因此，该卷积步骤包括在此输入图像上应用几个特征检测器。

16
00:01:04,210 --> 00:01:09,240
因此，在幻灯片上，特征检测器就是微笑嘴巴左侧纹理的特征。

17
00:01:09,350 --> 00:01:14,560
好吧，当我们看着人的时候，左侧是右侧，对于我们使用的每个特征检测器，

18
00:01:14,560 --> 00:01:20,860
将其全部滑动到输入图像上，并且当特征检测器经过那

19
00:01:20,920 --> 00:01:26,980
包含微笑着的嘴巴的左侧嗯，我们在这张桌子上的数字很高

20
00:01:26,980 --> 00:01:29,720
右边，此表是特征图。

21
00:01:29,740 --> 00:01:36,130
因此，对于我们应用于输入图像的每个特征检测器，我们都会得到一个包含特征图的特征图

22
00:01:36,130 --> 00:01:42,040
特征图的一些数字和最高数字是特征检测器可以检测到

23
00:01:42,040 --> 00:01:44,820
输入图像中的特定功能。

24
00:01:45,280 --> 00:01:45,630
好吧。

25
00:01:45,640 --> 00:01:51,400
这就是输入图像和特征检测器之间的卷积运算

26
00:01:51,790 --> 00:01:55,930
卷积运算会产生未来的地图。

27
00:01:56,130 --> 00:01:58,600
因此，我们使用许多特征检测器来执行此操作。

28
00:01:58,600 --> 00:02:04,570
我们将在第一步卷积步骤中选择我们创建的特征检测器的数量，因此

29
00:02:04,570 --> 00:02:10,660
特征图的数量，因为我们得到的特征图与用于检测的特征检测器一样多

30
00:02:10,750 --> 00:02:16,480
输入图像中的一些特定特征，因此最终我们得到了第一步卷积

31
00:02:16,600 --> 00:02:22,540
一旦创建了许多将构成我们的卷积层的特征图，便完成了

32
00:02:22,540 --> 00:02:24,100
正是我们要在这里建造的。

33
00:02:24,100 --> 00:02:27,690
由所有这些特征图组成的卷积层。

34
00:02:27,820 --> 00:02:28,870
因此，让我们开始吧。

35
00:02:28,900 --> 00:02:34,120
实际上只需要一行，因为我们已经导入了要使用的数据包

36
00:02:34,120 --> 00:02:35,840
添加该卷积层。

37
00:02:35,890 --> 00:02:42,160
所以这将占用一行，而我们将通过采用一个分类器来开始这一行，因为

38
00:02:42,250 --> 00:02:48,870
当然这是一个对象，我们将在该对象上应用方法

39
00:02:48,880 --> 00:02:52,530
以及我们已经用来添加图层的方法。

40
00:02:52,540 --> 00:02:57,400
但这不是卷积错误，而是由多个节点组成的经典层。

41
00:02:57,460 --> 00:03:00,390
这就是我们在构建DNN的农产品部门所做的。

42
00:03:00,550 --> 00:03:02,820
但是，这里有些事情当然会改变。

43
00:03:03,040 --> 00:03:04,800
因此，让我们一起上课吧。

44
00:03:05,110 --> 00:03:09,030
在这里，我们先粘贴然后再用Dudd来介绍该方法。

45
00:03:09,190 --> 00:03:10,060
现在我们开始。

46
00:03:10,060 --> 00:03:13,000
那就是我们要使用添加按回车的方法。

47
00:03:13,150 --> 00:03:20,260
现在，男爵夫人和这些括号中，我们将在那里添加卷积的参数。

48
00:03:20,410 --> 00:03:26,110
所以现在请记住，当我们在链条和区域中添加经典层时，我们在此处使用的是

49
00:03:26,110 --> 00:03:31,320
函数，但此密集函数用于添加一个完全连接的层，例如在末端。

50
00:03:31,450 --> 00:03:34,070
因此，这不是我们将在此处使用的功能。

51
00:03:34,150 --> 00:03:41,860
我们将要使用的功能可以猜测它是卷积2D，我们可以使用这些功能

52
00:03:41,860 --> 00:03:45,610
今天，这里要进行卷积。

53
00:03:45,880 --> 00:03:48,100
好的，现在是新的括号。

54
00:03:48,280 --> 00:03:53,740
让我们看看我们在此卷积到函数中需要在这里输入什么。

55
00:03:53,740 --> 00:03:56,220
好的，我要按这里。

56
00:03:56,830 --> 00:03:59,980
我需要获得有关此卷积函数的一些信息。

57
00:04:00,250 --> 00:04:01,690
现在我们开始。

58
00:04:01,930 --> 00:04:07,040
因此，我们有几个参数，如您在此处看到的64 3:03板模式输入形状。

59
00:04:07,210 --> 00:04:09,560
让我们看看它们在哪里。

60
00:04:09,600 --> 00:04:09,870
好吧。

61
00:04:09,880 --> 00:04:11,730
所以第一个论点是。

62
00:04:11,800 --> 00:04:14,890
并且我们过滤了过滤器的数量。

63
00:04:14,890 --> 00:04:20,470
因此，这正是我们要在输入图像上获取的特征检测器的数量

64
00:04:20,620 --> 00:04:22,810
相同数量的要素图。

65
00:04:22,840 --> 00:04:28,060
因此，我们在此处选择的过滤器数量就是我们要创建为的特征图的数量

66
00:04:28,060 --> 00:04:33,050
很好，因为将为每个使用的过滤器创建一个特征图。

67
00:04:33,060 --> 00:04:33,640
好吧。

68
00:04:33,640 --> 00:04:37,720
因此，我们需要选择这种数量的特征纹理，但这并不是我们唯一需要做的事情。

69
00:04:37,720 --> 00:04:38,470
在这里选择。

70
00:04:38,530 --> 00:04:45,760
如您所见，OK表示，我们过滤了一些过滤器，但也表示了卷积中的行数

71
00:04:45,760 --> 00:04:46,470
核心。

72
00:04:46,540 --> 00:04:51,700
因此，卷积核只是特征检测器或过滤器的别称，但无论如何，我们都有

73
00:04:51,820 --> 00:04:57,040
特征检测器的行数以及特征检测器的列数。

74
00:04:57,250 --> 00:05:00,140
因此，如果我们回到幻灯片上，将会了解它是什么。

75
00:05:00,310 --> 00:05:04,960
行数就是您在中间看到的此功能检测器表的行数

76
00:05:04,960 --> 00:05:10,420
的幻灯片和与该特征检测器表的列数相同的列数

77
00:05:10,420 --> 00:05:12,240
您会在幻灯片中间看到。

78
00:05:12,310 --> 00:05:18,820
所以基本上，如果我们回到蜘蛛，那么您在卷积参数中看到的数字

79
00:05:18,820 --> 00:05:19,810
功能。

80
00:05:19,920 --> 00:05:24,170
那么这里的64是您要使用的过滤器的数量。

81
00:05:24,190 --> 00:05:27,730
三是每个过滤器的行数。

82
00:05:27,970 --> 00:05:32,540
这另外三个是我们未来检测器的列数。

83
00:05:32,830 --> 00:05:39,430
因此，基本上，如果我们选择64个3和3，则意味着将创建64个特征检测器

84
00:05:39,430 --> 00:05:46,180
将具有三乘三的尺寸，并将通过输入图像来创建64个特征

85
00:05:46,180 --> 00:05:46,900
地图。

86
00:05:46,900 --> 00:05:50,020
所以现在我们要在这里为我们的功能选择什么。

87
00:05:50,170 --> 00:05:55,570
好吧，我们不会选择64，因为首先，如果您查看大多数CNN架构

88
00:05:55,840 --> 00:05:58,840
您会看到一种常见的做法是从32开始。

89
00:05:58,960 --> 00:06:04,090
您知道我们从第一个卷积层中的32个特征检测器开始，然后再添加其他卷积层

90
00:06:04,090 --> 00:06:11,890
层具有更多特征检测器，例如64位，然后是128位，然后是256位，这是第二个

91
00:06:11,890 --> 00:06:14,060
我们从事C.P.的原因 您。

92
00:06:14,070 --> 00:06:19,350
好吧，也许你们中有些人正在努力，这很棒，但是如果您按照安装说明进行操作

93
00:06:19,480 --> 00:06:20,930
我们正在研究锡比乌。

94
00:06:21,070 --> 00:06:26,270
因此，我们希望开始缓慢，但不要担心，我们将获得一些非常好的结果。

95
00:06:26,410 --> 00:06:32,290
首先，我们会得到一些正确的结果，然后我们将改善CNN并获得更好的结果。

96
00:06:32,290 --> 00:06:38,020
好的，所以我们不在这里选择，我们将从32个特征检测器开始，然后

97
00:06:38,020 --> 00:06:41,860
我们将为未来的探测器选择这三个维度。

98
00:06:41,860 --> 00:06:46,570
因此，您在此处添加三个和三个。

99
00:06:46,570 --> 00:06:47,130
好吧。

100
00:06:47,350 --> 00:06:53,800
因此，这意味着我们创建了32个三乘三维的特征检测器，因此我们进行了卷积

101
00:06:53,800 --> 00:06:57,280
将由32个特征图组成。

102
00:06:57,310 --> 00:06:59,020
好吧，然后下一个论点。

103
00:06:59,020 --> 00:07:00,580
下一个论点是什么。

104
00:07:00,580 --> 00:07:02,200
这更偏僻。

105
00:07:02,350 --> 00:07:04,810
因此，这不是最重要的。

106
00:07:04,810 --> 00:07:09,190
这仅是为了指定特征检测器将如何处理输入图像的边界。

107
00:07:09,280 --> 00:07:11,710
但是大多数时候我们在这里选择相同。

108
00:07:11,710 --> 00:07:13,090
这是默认值。

109
00:07:13,180 --> 00:07:17,560
这就是我们要在此处选择的内容，因此我们无需放置它，因为它将自动

110
00:07:17,560 --> 00:07:22,920
采用默认值，然后采用非常重要的参数输入形状。

111
00:07:23,140 --> 00:07:29,410
因此，形状良好的状态就是您要在其上应用功能的输入图像的形状

112
00:07:29,410 --> 00:07:31,950
检测器通过卷积运算。

113
00:07:32,260 --> 00:07:36,900
这是一个非常重要的论据，因为我们所有图像的大小都不相同。

114
00:07:36,910 --> 00:07:42,870
它们没有相同的格式，因此我们需要以某种方式强制它们具有相同的格式。

115
00:07:42,970 --> 00:07:50,320
这意味着我们将所有图像转换为相同的单一格式，因此将转换为固定大小

116
00:07:50,470 --> 00:07:55,660
图像，我们将在构建图像后立即在图像处理部分进行此转换

117
00:07:55,660 --> 00:07:56,140
CNN。

118
00:07:56,140 --> 00:08:03,250
在将RCN放入图像之前，因此在放置形状参数时，我们需要指定

119
00:08:03,250 --> 00:08:06,890
输入图像的预期格式是什么？

120
00:08:06,970 --> 00:08:12,540
那就是我们的图像将被转换成我们将在这里选择的格式的格式。

121
00:08:12,760 --> 00:08:18,160
好吧，首先让我们回到幻灯片，以快速提醒我们输入图像已转换为

122
00:08:18,160 --> 00:08:19,260
3D阵列。

123
00:08:19,360 --> 00:08:24,430
如果图像是彩色图像，则为2D数组，如果图像是黑白图像。

124
00:08:24,540 --> 00:08:30,110
所以在这里，因为您正在使用彩色图像，所以我们的图像将被转换为3D数组

125
00:08:30,200 --> 00:08:32,070
图像处理部分。

126
00:08:32,100 --> 00:08:34,210
那么3D阵列基本上是什么。

127
00:08:34,270 --> 00:08:36,620
好吧，它由三个渠道组成。

128
00:08:36,640 --> 00:08:40,780
每个通道对应一种颜色，蓝色，绿色或红色。

129
00:08:41,140 --> 00:08:47,560
每个通道对包含我们图像像素的数组的响应，因此如果

130
00:08:47,560 --> 00:08:54,420
回到蜘蛛，我们可以看到输入形状具有三个参数3 256 256。

131
00:08:54,580 --> 00:08:57,650
因此，您可能已经猜到三个是通道数。

132
00:08:57,790 --> 00:09:02,290
因此，如果我们要处理黑白图像，则只会是一个；如果我们要处理图像，则只会是三个。

133
00:09:02,290 --> 00:09:10,610
彩色图像，然后数组的256和256其他尺寸具有通道，因此这里

134
00:09:10,630 --> 00:09:19,360
这意味着我们期望256倍256像素的大学图像很棒，但这不是格式

135
00:09:19,360 --> 00:09:20,680
我们将在这里使用。

136
00:09:20,680 --> 00:09:25,570
我们将使用较小的格式，这与使用CPQ的原因相同，

137
00:09:25,570 --> 00:09:28,940
我们不想在代码完成执行之前等待太多时间。

138
00:09:29,050 --> 00:09:33,940
因此，在这里我们将选择一个较小的格式，这将是三个通道，因为

139
00:09:33,940 --> 00:09:38,950
我们希望保留与来电者相关的信息，因为您知道猫和狗没有

140
00:09:38,950 --> 00:09:44,620
相同的颜色，因此将它们与颜色区分开可能有助于对它们进行分类。

141
00:09:44,650 --> 00:09:47,900
因此，我们将保留颜色，因此在这里选择三种。

142
00:09:48,160 --> 00:09:55,420
但是然后我们将选择64时64格式，因为这将足以获得良好的准确性

143
00:09:55,420 --> 00:09:56,140
结果。

144
00:09:56,170 --> 00:10:02,110
最后，您将看到，如果您正在使用GP，欢迎选择更大的格式，例如128 by

145
00:10:02,110 --> 00:10:06,060
128甚至256 x 256。

146
00:10:06,220 --> 00:10:11,680
但是，您要么需要使用GP，要么需要在睡眠8个小时之前运行代码。

147
00:10:11,680 --> 00:10:13,250
好的，让我们启用这种格式。

148
00:10:13,300 --> 00:10:16,310
但是，这里还有最后一件事，我们需要小心。

149
00:10:16,360 --> 00:10:19,260
这是此处输入参数的顺序。

150
00:10:19,270 --> 00:10:23,720
如您所见，我们从通道数开始，然后是数组的尺寸。

151
00:10:23,920 --> 00:10:29,860
但是这些导入参数的顺序是CNO Bacchante中使用的顺序，在这里您可以看到

152
00:10:29,860 --> 00:10:36,030
我们使用了数十个流Bacchante，而后端的顺序与

153
00:10:36,040 --> 00:10:42,010
结束或返回，这实际上是相反的顺序，我们需要从两个数组维度开始

154
00:10:42,160 --> 00:10:47,950
然后是通道数，因此我们需要在此处导入输入形状参数

155
00:10:48,190 --> 00:10:52,700
输入，话语形状相等。

156
00:10:52,890 --> 00:11:02,500
然后在括号中，首先是二维数组的维数，因此是64到64，然后是数字

157
00:11:02,500 --> 00:11:08,570
通道3的数量，这是因为我们正在使用张量返送，因此请小心使用它。

158
00:11:08,680 --> 00:11:13,350
确保您正在使用的往往会倒流，如果您正在使用此代码，并且如果您没有使用

159
00:11:13,510 --> 00:11:17,590
后端只需输入3 64和64。

160
00:11:17,590 --> 00:11:18,130
好吧。

161
00:11:18,130 --> 00:11:24,310
现在我们只有最后一个输入参数，即激活函数，就像我们所做的一样

162
00:11:24,310 --> 00:11:29,830
我们在美国建立的人工神经网络中完全连接的层

163
00:11:29,890 --> 00:11:34,660
我们针对老年人使用了不同的功能，我们使用此激活功能来激活

164
00:11:34,660 --> 00:11:36,500
神经网络中的神经元。

165
00:11:36,520 --> 00:11:42,070
在这里，我们使用此激活函数，顺便说一下，它也是整流器激活函数

166
00:11:42,490 --> 00:11:48,250
只是为了确保我们在未来的地图中没有负像素值，具体取决于

167
00:11:48,250 --> 00:11:53,590
我们用于卷积运算的参数将来我们可以从像素中得到一些东西

168
00:11:53,590 --> 00:11:53,990
地图。

169
00:11:54,190 --> 00:11:59,410
并且我们需要去除这些负像素，以便在我们的卷积神经中具有非线性

170
00:11:59,410 --> 00:11:59,820
网络。

171
00:11:59,830 --> 00:12:04,920
由于对某些图像进行分类当然是一个非线性问题，因此我们需要在

172
00:12:04,920 --> 00:12:09,090
已经存在于我们的模型中，这就是为什么我们在这里使用此激活功能。

173
00:12:09,310 --> 00:12:14,160
纠正激活函数以确保我们得到了这种非线性。

174
00:12:14,440 --> 00:12:15,510
因此，让我们添加它。

175
00:12:15,520 --> 00:12:23,020
与我们在此处输入此激活参数然后等于和之前所做的完全相同

176
00:12:23,020 --> 00:12:29,890
然后用引号将rectify函数的名称放进去，这和往常一样非常完美，这就是

177
00:12:29,890 --> 00:12:35,670
完成我们的卷积层准备将其添加到我们的卷积神经网络中。

178
00:12:35,710 --> 00:12:38,420
因此，让我们执行这一行。

179
00:12:38,560 --> 00:12:39,310
开始了。

180
00:12:39,310 --> 00:12:40,020
完善。

181
00:12:40,030 --> 00:12:43,610
我们的第一个卷积层已正确添加。

182
00:12:43,810 --> 00:12:49,360
因此，我们已经准备好进入拉动步骤的第2步，这就是我们在下一个教程中将要做的。

183
00:12:49,360 --> 00:12:50,920
在那之前和机器学习有关。

