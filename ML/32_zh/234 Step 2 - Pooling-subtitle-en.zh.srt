1
00:00:00,630 --> 00:00:04,800
您好，欢迎回到今天的深度学习课程，我们正在谈论最大池化，我们已经

2
00:00:04,800 --> 00:00:07,380
即将发布一些非常令人兴奋的幻灯片。

3
00:00:07,500 --> 00:00:10,930
甚至在本教程的结尾也有一个特别的惊喜。

4
00:00:11,010 --> 00:00:12,440
因此，让我们开始吧。

5
00:00:12,450 --> 00:00:15,860
第一个问题是什么是池化，为什么我们需要池化。

6
00:00:16,050 --> 00:00:19,650
好回答这个问题，让我们在这些图像上看一下这些图像。

7
00:00:19,650 --> 00:00:20,780
我们有猎豹。

8
00:00:20,790 --> 00:00:23,680
实际上，这与第一张图片上的猎豹完全一样。

9
00:00:23,680 --> 00:00:29,640
该图像放置正确，并且她在第二张图像上正直看着您。

10
00:00:29,640 --> 00:00:30,660
它有点旋转。

11
00:00:30,660 --> 00:00:32,710
第三张图像被压扁了。

12
00:00:32,790 --> 00:00:40,020
这里的事情是我们希望神经网络能够识别每一个猎豹

13
00:00:40,020 --> 00:00:41,450
这些图像之一。

14
00:00:41,460 --> 00:00:43,230
实际上，这只是一只猎豹。

15
00:00:43,230 --> 00:00:45,070
如果我们有很多不同的射手怎么办？

16
00:00:45,090 --> 00:00:46,120
这是猎豹。

17
00:00:46,180 --> 00:00:47,250
他是猎豹。

18
00:00:47,400 --> 00:00:53,130
这是另一只猎豹，他的阿希拉（Ashira），他的石田（Eshida）猎豹和他是一只猎豹，我们想要神经网络

19
00:00:53,130 --> 00:01:01,110
认识到所有这些射击者都是作弊者，如果他们看起来都不一样，怎么办呢？

20
00:01:01,110 --> 00:01:06,300
方向都在图像的不同部分，就像他们的脸位于不同的位置

21
00:01:06,300 --> 00:01:10,080
图像的某些部分有人在右手某人在左角或某人在

22
00:01:10,080 --> 00:01:10,700
中间。

23
00:01:11,010 --> 00:01:14,280
它们都有些不同，质地也有些不同。

24
00:01:14,280 --> 00:01:16,200
照明有点不同。

25
00:01:16,200 --> 00:01:21,600
差异很小，因此如果神经网络正好寻找某个特征

26
00:01:21,810 --> 00:01:29,700
例如，猎豹的一个显着特征是其脸上的眼泪从眼睛

27
00:01:29,700 --> 00:01:35,310
或看起来像阴影的纯粹阴影会撕裂从其开始的图案的纹理

28
00:01:35,310 --> 00:01:40,890
眼睛向下看时，它在鼻子的侧面，看起来像眼泪，这是猎豹的一个独特特征。

29
00:01:40,890 --> 00:01:48,660
但是，如果它正在寻找从特定猎豹那里确切地学到的功能，或者

30
00:01:48,660 --> 00:01:53,370
确切的形状，形式或纹理，它将永远找不到其他射手。

31
00:01:53,460 --> 00:02:01,410
因此，我们必须确保我们的神经网络具有称为空间不变性的属性，这意味着

32
00:02:01,440 --> 00:02:10,170
不在乎这些功能在哪里，也不会像图像的哪一部分那样刺痒，因为

33
00:02:10,520 --> 00:02:16,460
我们在地图上已经考虑到我们在那儿的卷积很差

34
00:02:16,800 --> 00:02:23,400
但不必担心功能是否有些倾斜，如果功能在

35
00:02:23,400 --> 00:02:29,940
如果特征相对于特征而言较近或相对远一点

36
00:02:29,940 --> 00:02:30,210
彼此。

37
00:02:30,210 --> 00:02:37,230
因此，如果特征本身有些失真，我们的神经网络就必须具有一定程度的灵活性

38
00:02:37,410 --> 00:02:39,930
才能找到该功能。

39
00:02:40,050 --> 00:02:42,690
这就是池化的全部内容。

40
00:02:42,690 --> 00:02:45,140
因此，让我们看一下池是如何工作的。

41
00:02:45,180 --> 00:02:51,090
这是我们的特征图，所以我们已经完成了卷积，我们已经完成了那部分，现在我们

42
00:02:51,090 --> 00:02:52,680
与那里的卷积一起工作。

43
00:02:52,680 --> 00:02:53,880
现在我们将应用池化。

44
00:02:53,880 --> 00:02:54,690
那么它是怎样工作的。

45
00:02:54,690 --> 00:02:56,420
我们将应用回池。

46
00:02:56,670 --> 00:03:01,640
有几种不同类型的比赛符合要求，即池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池池评论

47
00:03:01,710 --> 00:03:03,440
在故事快要结束的时候。

48
00:03:03,540 --> 00:03:11,040
但是现在我们只是应用Max池，所以我们像这样一遍又一遍地将一个2 x 2像素的框

49
00:03:11,040 --> 00:03:15,020
不一定要两分之二，您可以选择任意大小的盒子，然后再次对它进行评论

50
00:03:15,030 --> 00:03:21,900
是Tauriel，将其放在左上角，然后在该框中找到最大值

51
00:03:21,900 --> 00:03:26,310
然后您只记录该值，而忽略其他三个。

52
00:03:26,310 --> 00:03:30,600
因此，在您的框中，您有四个值，而忽略三个，则只保留一个最大值，即

53
00:03:30,600 --> 00:03:31,830
在这种情况下一个。

54
00:03:31,830 --> 00:03:36,210
然后，通过大步向右移动框，再次选择大步。

55
00:03:36,210 --> 00:03:41,850
所以在这里，我们将步幅滑至两个，这就是您通常会感到困惑的，就像

56
00:03:41,850 --> 00:03:42,880
您可以选择一个。

57
00:03:42,990 --> 00:03:47,940
因此，有重叠的框，您可以选择任意三种喜欢的罢工

58
00:03:48,770 --> 00:03:52,440
但是我们在这里选择两个大步，这就是常用的步调。

59
00:03:52,470 --> 00:03:57,660
然后，如果重复但不重复，则重复此过程，在此处记录该格言的过程

60
00:03:57,660 --> 00:04:00,080
不管你只是继续做自己在做的事。

61
00:04:00,090 --> 00:04:05,690
因此，您仍在此处记录最大值0，此处最大值为4。

62
00:04:05,700 --> 00:04:11,380
这里是最大值，这里最大值是1 0 1或2然后是1。

63
00:04:11,400 --> 00:04:13,970
如您所见，发生了一些事情。

64
00:04:13,980 --> 00:04:18,890
首先，我们仍然能够正确保留这些功能。

65
00:04:19,080 --> 00:04:23,730
它们代表的最大值是因为我们知道Lehre的结论是如何工作的。

66
00:04:23,730 --> 00:04:28,650
我们知道，要素图中的最大值或最大值代表实际位置

67
00:04:28,650 --> 00:04:31,480
找到与特征最相似的地方。

68
00:04:31,650 --> 00:04:38,250
但是通过合并这些功能，我们首先摆脱了75％的信息

69
00:04:38,250 --> 00:04:46,110
这不是功能，也不是我们要寻找的重要内容，因为

70
00:04:46,220 --> 00:04:49,410
实际上，我们只有四分之三的像素。

71
00:04:49,710 --> 00:04:51,510
所以我们只得到25％。

72
00:04:51,510 --> 00:05:00,260
然后又因为我们要取最大的像素或我们拥有的值

73
00:05:00,770 --> 00:05:04,160
因此，我们要考虑任何失真。

74
00:05:04,160 --> 00:05:12,810
因此，例如有两幅图像，其中，作弊者在眼睛上的眼泪在一张图像中

75
00:05:12,830 --> 00:05:16,550
往左一点或向左旋转一点，再往左一点。

76
00:05:16,580 --> 00:05:22,100
以及它们应该是怎样的，或者如果您以一个为基础，另一个以那里为基础，我们会如何？

77
00:05:22,100 --> 00:05:23,800
位向左旋转。

78
00:05:24,060 --> 00:05:26,570
组合功能将完全相同。

79
00:05:26,570 --> 00:05:32,900
因此，您可以在这里看到是否我们在谈论作弊者的眼泪，那么我们说这是四个

80
00:05:32,900 --> 00:05:36,050
如果这里有点旋转，那就是这里。

81
00:05:36,050 --> 00:05:38,270
例如，这四个人就在这里结束。

82
00:05:38,390 --> 00:05:44,180
然后，当我们进行池化时，我们仍将获得相同的池特征图，这是一种

83
00:05:44,180 --> 00:05:46,270
背后的原理。

84
00:05:46,430 --> 00:05:52,340
这又是一个非常粗糙的解释，还是直观的解释，但这就是我们要集中的地方。

85
00:05:52,340 --> 00:06:00,290
仍然能够保留这些要素，并且还要考虑其可能的空间或纹理

86
00:06:00,290 --> 00:06:02,330
或其他类型的扭曲。

87
00:06:02,420 --> 00:06:07,370
除此之外，我们还在减小尺寸，因此还有另一个好处。

88
00:06:07,370 --> 00:06:13,520
因此，我们必须保留要引入空间不变性的特征，并要减小尺寸

89
00:06:13,520 --> 00:06:19,700
减少了75％，这在处理方面确实可以为我们提供帮助。

90
00:06:19,870 --> 00:06:25,970
而且，池化的另一个好处是我们减少了参数数量，因此我们减少了

91
00:06:26,690 --> 00:06:31,370
再减少75％或减少将要进入我们最终

92
00:06:31,370 --> 00:06:35,270
神经网络，因此我们防止过拟合。

93
00:06:35,300 --> 00:06:42,580
池化的一个非常重要的好处就是我们删除了信息，这是一件好事。

94
00:06:42,590 --> 00:06:50,660
这是一件好事，因为那样一来我们的模型将无法适应该信息，因为

95
00:06:50,690 --> 00:06:54,500
尤其是因为这些信息不太好，并且记得我们刚开始谈论时

96
00:06:54,950 --> 00:07:00,650
即使对于像人类一样的人，重要的是要准确地看到其特征而不是其他所有杂音

97
00:07:00,650 --> 00:07:02,520
进入我们的眼睛。

98
00:07:02,780 --> 00:07:09,070
对于神经网络来说，它们同样是通过忽略不必要的非重要形式

99
00:07:09,080 --> 00:07:12,470
帮助防止过度拟合。

100
00:07:12,500 --> 00:07:14,590
因此，我们要做的就是池化。

101
00:07:14,600 --> 00:07:21,500
而且这里的问题当然是为什么WiMax池存在许多不同类型的池

102
00:07:21,710 --> 00:07:26,780
而且所有这些东西的宽度跨度过大（两乘两个像素）。

103
00:07:26,780 --> 00:07:33,980
关于这一点，我想向您介绍这份可爱的研究论文，称为“池的评估”。

104
00:07:33,980 --> 00:07:40,250
大学的Dominic Sc​​herrer在卷积架构中进行对象识别的运算

105
00:07:40,250 --> 00:07:41,100
波恩

106
00:07:41,180 --> 00:07:47,540
有链接，这篇文章的美在于它非常非常简单非常直接

107
00:07:47,550 --> 00:07:51,530
因此，如果您从未尝试过研究论文，就可以尝试一下。

108
00:07:51,530 --> 00:07:54,440
这是一个很好的起点，它很短。

109
00:07:54,440 --> 00:07:55,400
仅10页。

110
00:07:55,400 --> 00:07:56,810
非常容易阅读。

111
00:07:57,080 --> 00:08:03,170
而且，额外的好处是，现在我们已经讨论了卷积和池化，您将完全

112
00:08:03,170 --> 00:08:07,040
对您在本文中谈论的所有内容都感到满意。

113
00:08:07,100 --> 00:08:11,880
这是实际加强的一种好方法，我也强烈建议您检查这篇论文。

114
00:08:11,930 --> 00:08:18,050
我将花20分钟阅读它，甚至感觉到您甚至可以跳过第2部分（称为相关工作）

115
00:08:18,050 --> 00:08:19,880
有点牵强或疏远。

116
00:08:19,880 --> 00:08:21,230
只是不要阅读该部分。

117
00:08:21,290 --> 00:08:23,950
直接从第1部分转到第3部分。

118
00:08:24,020 --> 00:08:29,600
您确实需要了解本文的一件事，他们谈论的是所谓的子采样概念

119
00:08:30,360 --> 00:08:33,230
二次采样基本上是平均池化。

120
00:08:33,230 --> 00:08:36,260
因此，请记住我们在这里采取的方式。

121
00:08:36,280 --> 00:08:37,400
我们正在努力。

122
00:08:37,400 --> 00:08:43,250
所以在我们的平方器中，取最大值就是一个概念，叫做均值池

123
00:08:43,250 --> 00:08:48,590
当您仅将其中一些值拉到平均池中或平均池中时，便取平均值

124
00:08:48,650 --> 00:08:53,890
在所有这些中，子采样有点像是对人员汇集的概括。

125
00:08:53,900 --> 00:09:00,840
这是获取这些值的平均值的一种更通用的方法。

126
00:09:00,860 --> 00:09:05,480
您可以阅读本文的更多内容，否则可以将其视为平均池

127
00:09:05,480 --> 00:09:06,620
你正在读论文。

128
00:09:06,920 --> 00:09:11,180
因此，在这里您可以获取有关此主题的其他信息，现在让我们来回顾一下

129
00:09:11,210 --> 00:09:12,310
我们到哪里去了。

130
00:09:12,320 --> 00:09:14,440
所以有我们的输入图像。

131
00:09:14,870 --> 00:09:18,960
然后我们应用了卷积运算，并得出了结论。

132
00:09:19,070 --> 00:09:24,230
现在，对于我们得到的每个特征图，我们都应用了Pullinger。

133
00:09:24,260 --> 00:09:30,590
因此，我们已经完成了演化和池化这两个步骤，现在我们将要做一些非常重要的事情。

134
00:09:30,590 --> 00:09:32,160
有趣的事情令人兴奋。

135
00:09:32,220 --> 00:09:40,340
我们将对此进行实验，因此这是我从Adam Harley创建的工具中截取的屏幕截图

136
00:09:40,340 --> 00:09:48,140
从他在瑞尔森大学计算机科学系毕业到现在在卡内基梅隆大学

137
00:09:48,320 --> 00:09:49,750
我想做他的页面。

138
00:09:50,060 --> 00:09:53,150
还有一个很棒的工具，让我们开放一下吧。

139
00:09:53,270 --> 00:09:55,780
因此，您可以找到它，实际上可以通过Google找到它。

140
00:09:55,780 --> 00:09:57,500
你必须知道你的角色。

141
00:09:57,500 --> 00:10:03,790
就像通过Google很难找到它一样，因为这里没有文本，就像我们今年一样。

142
00:10:03,930 --> 00:10:08,350
我将看到开始的Reierson档案和这些资料。

143
00:10:08,510 --> 00:10:14,820
基本上这就是我们正在做的但要可视化，所以在这里您需要画一个数字

144
00:10:14,820 --> 00:10:21,330
我画了四号，这个工具将把四号放在这里。

145
00:10:21,340 --> 00:10:22,960
那是你的形象。

146
00:10:22,960 --> 00:10:26,620
在我们的第一步中，这就是卷积步骤。

147
00:10:26,800 --> 00:10:27,100
对。

148
00:10:27,100 --> 00:10:30,390
这是合并步骤，顺便说一下合并也称为下采样。

149
00:10:30,390 --> 00:10:33,770
因此，拉采样和下采样是相同的。

150
00:10:33,930 --> 00:10:39,190
因此，您可以看到它是应用卷积，然后是应用池化，并且可以看到它是如何工作的。

151
00:10:39,190 --> 00:10:44,290
您可以看到已应用了哪种卷积或已应用了哪种过滤器

152
00:10:44,290 --> 00:10:45,020
他们看着像是。

153
00:10:45,130 --> 00:10:47,630
寻找什么功能。

154
00:10:47,830 --> 00:10:53,340
然后将其应用池化，从而减小了大小，您可以在此处看到这很重要。

155
00:10:53,380 --> 00:11:01,090
因此，您可以看到这是卷积图像，这是混合图像，您仍然可以看到

156
00:11:01,090 --> 00:11:05,830
相同的功能只是较少的信息，而相同的功能则保留了正确的功能。

157
00:11:05,830 --> 00:11:08,110
那是重要的部分。

158
00:11:08,350 --> 00:11:14,170
而且，如果您知道所有四个部分是否都有点像旋转到一边，它仍然会

159
00:11:14,170 --> 00:11:16,960
能够拿起非常相似的泳池

160
00:11:17,050 --> 00:11:19,810
在那之后，有更多的信件，我们还没有谈论过。

161
00:11:19,810 --> 00:11:26,840
因此，他在这里得到了另一个我们实际上不会拥有的卷积窝。

162
00:11:27,130 --> 00:11:30,730
然后他有另一个可怜的巢穴，但他基本上只是在重复相同的过程。

163
00:11:31,000 --> 00:11:34,880
然后，这就是我们接下来将要讲的内容。

164
00:11:34,910 --> 00:11:37,610
他得到了完全联系的Lares，依此类推。

165
00:11:38,080 --> 00:11:39,880
但是您绝对可以解决这个问题。

166
00:11:39,880 --> 00:11:47,890
因此，如果我删除您喜欢的东西，如果我画了7，您将看到它实际上告诉您猜测是

167
00:11:47,890 --> 00:11:49,410
猜测是这是7。

168
00:11:49,570 --> 00:11:52,850
第二个猜测的第二个可能性是3。

169
00:11:53,050 --> 00:11:56,440
因此，您可以绘制一些具有挑战性的东西，看看它是否可以拾取它们。

170
00:11:56,440 --> 00:12:02,680
因此，假设我画了一个看起来像0的东西，但它不是完成的0，它会把它捡起来吗

171
00:12:02,770 --> 00:12:03,730
时间还没到。

172
00:12:03,730 --> 00:12:06,190
看起来像9。

173
00:12:06,190 --> 00:12:08,550
如果我喜欢那样完成该怎么办。

174
00:12:08,560 --> 00:12:14,430
因此，现在它认为它是0或9，您可以在那看到点亮0的内容。

175
00:12:14,460 --> 00:12:16,600
但是，我们将对此部分进行怀疑。

176
00:12:16,720 --> 00:12:20,030
再说一遍就像8。

177
00:12:20,260 --> 00:12:23,780
我认为现在拿起8很难。

178
00:12:23,800 --> 00:12:29,590
因此，您可以看到它变成了8，然后像这样，它停止了识别，停止了

179
00:12:29,590 --> 00:12:31,570
对我们人类有意义。

180
00:12:31,570 --> 00:12:32,150
对。

181
00:12:32,170 --> 00:12:34,390
它正在使用的这些功能。

182
00:12:34,570 --> 00:12:38,710
但与此同时，它正确地认识到它是8。

183
00:12:39,100 --> 00:12:42,540
所以一定要玩一下，才能画个笑脸。

184
00:12:42,550 --> 00:12:43,460
那会发生什么。

185
00:12:44,310 --> 00:12:50,070
这个工具看起来像三分，因为该工具显然只接受了来自

186
00:12:50,070 --> 00:12:50,950
0到9。

187
00:12:51,120 --> 00:12:58,530
因此，它必须识别出某些东西，并识别出生活中的三个东西，当您

188
00:12:58,530 --> 00:13:05,700
您会看到像从未见过的某种水果，例如释迦或类似的东西

189
00:13:06,120 --> 00:13:12,570
而且您认为这就像是一只梨，因为您从未真正见过一个梨

190
00:13:12,570 --> 00:13:18,210
知道在这里将其归类为同一事物的原因，因此实际上并没有经过笑脸训练，这就是

191
00:13:18,210 --> 00:13:20,480
为什么以为是一棵树。

192
00:13:20,490 --> 00:13:25,770
因此，您可以使用它，它是一个非常强大的功能强大的工具，可以帮助您实际使用它

193
00:13:26,130 --> 00:13:29,430
当您将鼠标放在要显示的像素上时。

194
00:13:29,430 --> 00:13:36,930
它显示了特征检测器将拾取像素的位置，因此您可以看到这些像素的位置

195
00:13:36,930 --> 00:13:43,170
是从那里来的，所以您可以看到滤镜有点像通过图像

196
00:13:43,170 --> 00:13:47,910
我们谈论的方式，当然，在这里您可以看到可以看到的池，可以看到

197
00:13:47,910 --> 00:13:58,140
拉动是通过拉动完成的，其平方大小为2乘2，您可以看到

198
00:13:58,200 --> 00:14:03,730
正如我们在本教程中讨论的那样，这是两个步骤。

199
00:14:03,960 --> 00:14:09,240
因此，您可以去玩或玩一玩，我希望您喜欢今天的会议。

200
00:14:09,240 --> 00:14:10,610
期待下次见到您。

201
00:14:10,620 --> 00:14:12,470
在此之前，请享受深度学习。

