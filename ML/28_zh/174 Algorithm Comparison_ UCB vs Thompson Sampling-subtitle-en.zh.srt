1
00:00:01,380 --> 00:00:06,240
您好，欢迎回到机器学习课程，希望您喜欢之前的教程，并且

2
00:00:06,270 --> 00:00:12,030
现在您对置信范围和Tompson采样算法或至少

3
00:00:12,030 --> 00:00:13,490
他们背后的直觉。

4
00:00:13,530 --> 00:00:18,120
今天，我们将快速比较两者，因为它们确实解决了解决相同问题的方法。

5
00:00:18,120 --> 00:00:24,990
多武装匪徒的问题，让我们看一下每种武装的利弊

6
00:00:24,990 --> 00:00:25,710
算法。

7
00:00:25,860 --> 00:00:31,590
因此，当然存在很多不同的先进性和劣势，

8
00:00:31,590 --> 00:00:34,630
两个，但我们仅突出显示主要的两个。

9
00:00:34,650 --> 00:00:36,500
所以在这里，我们在左侧有两个算法。

10
00:00:36,510 --> 00:00:43,170
我们已经从直觉教程中获得了ECB和图像，这将有助于我们记住它的含义。

11
00:00:43,230 --> 00:00:43,790
它是关于什么的。

12
00:00:43,800 --> 00:00:47,760
汤普森（Tompson）采样算法与其后的图像相同。

13
00:00:47,760 --> 00:00:55,590
因此，第一个特点可能是与众不同的是UCB是确定性算法

14
00:00:55,650 --> 00:01:03,950
实际上，这些算法有很多不同之处。

15
00:01:03,960 --> 00:01:08,460
您可以在网上找到它们，关于它们如何使用该算法的白皮书很多。

16
00:01:08,460 --> 00:01:17,370
进行了修改以改进它并使其在某一方面或其他方面变得更好，因为一项优势使它成为

17
00:01:17,370 --> 00:01:22,580
结果会更好一些，但可能会增加强度，反之亦然。

18
00:01:22,590 --> 00:01:29,160
因此，所有这些算法全部属于UCB Algren的Opper自信的Bollen系列

19
00:01:29,190 --> 00:01:34,620
都是确定性的算法，基本上这意味着它非常简单。

20
00:01:34,620 --> 00:01:44,890
是的，因此一旦您进行了特定的回合，将会非常简单。

21
00:01:44,940 --> 00:01:48,870
您只要看一下真主党的右上角，就可以看到其中一个最高的那个

22
00:01:48,870 --> 00:01:50,050
挑。

23
00:01:50,130 --> 00:01:55,800
拉算法是或拉杠杆是然后从中获得随机值

24
00:01:55,800 --> 00:01:56,450
机器。

25
00:01:56,520 --> 00:02:01,340
但这就是机器的侧面。

26
00:02:01,350 --> 00:02:06,240
因此，这就是机器侧面的随机性，然后是任意值

27
00:02:06,240 --> 00:02:08,900
得到它是非常确定的。

28
00:02:08,910 --> 00:02:12,700
这个值将要做什么是非常确定的。

29
00:02:13,050 --> 00:02:18,310
因此，美国实际上采取的所有步骤都是确定性的。

30
00:02:18,990 --> 00:02:21,330
算法本身没有随机性。

31
00:02:21,600 --> 00:02:26,790
另一方面，Tomsen采样算法是一种概率算法，因为

32
00:02:26,820 --> 00:02:33,390
算法本身具有这些分布，它们代表了我们对世界的认知以及在哪里

33
00:02:33,390 --> 00:02:39,620
我们认为这些机器中的每台机器的实际预期收益可能都在。

34
00:02:39,690 --> 00:02:49,230
因此，每次我们在时间采样算法中实现或迭代时，我们实际上

35
00:02:49,230 --> 00:02:52,270
从这些分布中生成随机值。

36
00:02:52,290 --> 00:03:00,300
因此，如果您从UCB算法中重新运行，仅在收到来自

37
00:03:00,600 --> 00:03:04,430
机器上的先前值，然后重新运行该回合。

38
00:03:04,440 --> 00:03:05,950
总是会得到相同的结果。

39
00:03:06,210 --> 00:03:11,070
而在从机器上收到先前值并重新运行后，在采样Algren中

40
00:03:11,070 --> 00:03:12,740
本轮比赛。

41
00:03:13,130 --> 00:03:21,450
因此，总会有所不同，因为您总是从分布特征中进行采样

42
00:03:21,450 --> 00:03:27,290
您对世界的感知，这是一种完全不同的算法。

43
00:03:27,290 --> 00:03:28,860
它是一种概率算法。

44
00:03:29,150 --> 00:03:35,720
而这两件事实际上具有不同的含义。

45
00:03:35,730 --> 00:03:35,970
对。

46
00:03:35,970 --> 00:03:42,630
例如，一个重要的方面是UCB在每一轮都需要更新。

47
00:03:42,630 --> 00:03:48,010
基本上，正确的价值是您从使用机器中获得的回报。

48
00:03:48,020 --> 00:03:52,640
因此，一旦您拉动杠杆，并且从那台机器上获得了价值，就必须将其纳入其中

49
00:03:52,640 --> 00:03:57,930
为了继续进行下一轮，您必须先进行下一步，才能继续进行下一轮

50
00:03:59,670 --> 00:04:06,840
合并该值，直到您基于该值对算法进行调整为止，因为

51
00:04:06,840 --> 00:04:11,150
如果您不进行调整，则没有任何变化，您将被卡住。

52
00:04:11,400 --> 00:04:16,130
而在汤普森采样中，它可以容纳延迟的反馈，这一点非常重要。

53
00:04:16,290 --> 00:04:22,410
这基本上意味着，如果您拉动操纵杆，您只会得到结果，您只会知道

54
00:04:22,410 --> 00:04:26,570
拉杆500的结果使轨道变圆。

55
00:04:26,580 --> 00:04:26,820
对。

56
00:04:26,820 --> 00:04:31,010
并非马上，您只会在以后了解所有500发子弹。

57
00:04:31,080 --> 00:04:32,830
汤普森采样算法仍将起作用。

58
00:04:32,820 --> 00:04:39,600
为什么会起作用，因为如果您现在运行算法，甚至不更新对世界的感知

59
00:04:39,600 --> 00:04:46,440
您仍将获得一组新的假想土匪。

60
00:04:46,440 --> 00:04:51,930
正确的是，您将产生一个新的东西，并且您期望每个人都能得到回报，因为您正在产生

61
00:04:51,930 --> 00:04:53,910
他们以概率的方式。

62
00:04:53,910 --> 00:04:59,010
理解这一点非常重要，因为这使汤普森采样具有以下优势：

63
00:04:59,010 --> 00:05:02,790
您不必每次都用结果更新算法。

64
00:05:02,790 --> 00:05:09,290
当然，就方巾而言，这并不重要，因为如果您

65
00:05:09,300 --> 00:05:14,430
在赌场里玩，如果某个假想的人在赌场里玩而他们看不见

66
00:05:14,430 --> 00:05:17,160
拉动这些杠杆，他们马上就能得到结果。

67
00:05:17,160 --> 00:05:18,450
这样他们就可以更新Algor。

68
00:05:18,690 --> 00:05:23,210
但是，对于网站和广告而言，这很重要。

69
00:05:23,220 --> 00:05:32,430
因此，甚至不只是在网站上展示广告，还是可以将其用于AB测试

70
00:05:32,430 --> 00:05:38,540
而不是AB来测试您网站的不同布局。

71
00:05:38,550 --> 00:05:46,560
您可以使用汤普森采样算法在开发探索之间取得平衡

72
00:05:46,560 --> 00:05:47,170
马上。

73
00:05:47,280 --> 00:05:54,720
因此，基本上，您在Thomson采样上在网络上所做的任何事情，或者像解决多武装匪徒一样

74
00:05:54,720 --> 00:06:00,020
您的业​​务或网络业务的问题。

75
00:06:00,610 --> 00:06:04,430
您将获得所有成千上万的点击。

76
00:06:04,440 --> 00:06:12,120
并立即更新算法，这在计算上将是非常昂贵的

77
00:06:12,750 --> 00:06:19,230
否则可能需要额外的资源和复杂的流程，而如果您是

78
00:06:19,230 --> 00:06:24,680
算法允许您做的是批量更新数据集或信息算法

79
00:06:24,690 --> 00:06:28,800
因此，您等待直到获得500次点击，或者等待直到获得5000次点击。

80
00:06:28,890 --> 00:06:32,850
您更新算法，然后让它运行，然后运行它，然后又得到另一个

81
00:06:32,850 --> 00:06:39,410
单击5000次，然后再次更新算法，它将仍然有效，这非常重要

82
00:06:39,440 --> 00:06:44,960
汤普森采样算法创造的灵活性。

83
00:06:44,990 --> 00:06:52,700
最后，我们不会在正反两面介绍太多细节，而是对汤普森采样

84
00:06:52,700 --> 00:06:57,060
实际上，该算法具有比以往更好的经验证据。

85
00:06:57,140 --> 00:07:06,380
他们发现这个词组是更好的经验证据，这是因为直到最近

86
00:07:06,380 --> 00:07:12,290
汤普森采样算法背后的理论，或者您知道整个研究还不是很完整，

87
00:07:12,290 --> 00:07:19,040
只是在几年前才进行了非常详细的研究，现在您知道了

88
00:07:19,040 --> 00:07:25,160
可以在Thompson采样算法上找到很多信息，以前人们只是从

89
00:07:25,640 --> 00:07:30,010
实验证明，汤普森采样算法的效果比这些更好。

90
00:07:30,050 --> 00:07:33,190
这正是我们将要看到的。

91
00:07:33,200 --> 00:07:34,110
扰流板警报。

92
00:07:34,140 --> 00:07:39,830
这正是您将在本节的实用教程中看到的。

93
00:07:39,830 --> 00:07:46,400
所以我们现在要编码或吃午餐，我们将带您完成相同练习的编码

94
00:07:46,400 --> 00:07:49,130
我们以前遇到的问题不是。

95
00:07:49,340 --> 00:07:55,430
您是否打算使用一些汤普森采样算法来解决它，您实际上会看到一些

96
00:07:55,430 --> 00:07:56,550
有趣的结果。

97
00:07:56,610 --> 00:08:02,600
我们就这样解决了，希望您喜欢这些直觉教程，然后继续实际操作。

98
00:08:02,600 --> 00:08:04,880
方面可以等待您入门。

99
00:08:04,880 --> 00:08:09,040
吃过午饭我们会带你到处看看，下次我会再见到你。

100
00:08:09,050 --> 00:08:10,760
在那之前在德国学习。

