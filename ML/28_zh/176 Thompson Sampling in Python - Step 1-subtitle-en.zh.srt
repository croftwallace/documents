1
00:00:00,210 --> 00:00:02,510
您好，欢迎来到本Python教程。

2
00:00:02,700 --> 00:00:08,400
因此，在美国，我们为此引入了一项多武装福利计划，并优化了点击率

3
00:00:08,400 --> 00:00:09,130
问题。

4
00:00:09,330 --> 00:00:16,230
而且我们已经尝试过使用算法，第一个算法是简单的随机选择算法，

5
00:00:16,230 --> 00:00:21,200
包括纯随机选择和每轮AD。

6
00:00:21,330 --> 00:00:27,990
这个算法平均给我们提供了1200个病房，因为您知道存在这个随机因素

7
00:00:28,150 --> 00:00:31,550
平均而言，我们可以获得1200的总奖励。

8
00:00:31,650 --> 00:00:37,520
当然，当我们绘制直方图时，每个广告的选择次数几乎相同。

9
00:00:37,740 --> 00:00:45,300
然后我们尝试了另一种算法，它是在上面找到的上限，在那里我们得到了更好的结果

10
00:00:45,480 --> 00:00:52,840
因为我们不仅获得了几乎两倍的总奖励，还获得了我们想要的2170

11
00:00:52,890 --> 00:00:53,410
8。

12
00:00:53,520 --> 00:01:00,030
因此，几乎是我们从随机选择中获得的收益的两倍，更妙的是，我们设法

13
00:01:00,030 --> 00:01:06,780
找出哪个版本最能向用户显示哪个广告的最高

14
00:01:06,900 --> 00:01:13,430
最高城市的转化率是最高的点击率，现在在本节中

15
00:01:13,430 --> 00:01:17,940
将尝试一种称为Thomsons采样的新算法。

16
00:01:17,940 --> 00:01:20,900
因此，在本节中，我们将看两件事。

17
00:01:20,910 --> 00:01:27,450
首先是肯·汤普森（Ken Thompson）超越了说服力的上限，肯·汤普森（Ken Thompson）只是给了我们

18
00:01:27,660 --> 00:01:31,830
甚至比2170高的工具病房8。

19
00:01:31,920 --> 00:01:35,280
您知道我们几乎将随机选择的总奖励提高了一倍。

20
00:01:35,310 --> 00:01:37,670
让我们看看是否可以再次击败它。

21
00:01:37,770 --> 00:01:40,690
就像是两倍甚至三倍以上。

22
00:01:40,710 --> 00:01:41,130
我不知道。

23
00:01:41,130 --> 00:01:41,790
让我们来看看。

24
00:01:41,910 --> 00:01:47,340
我们要看的第二件事是，如果我们获得最高的广告

25
00:01:47,340 --> 00:01:48,230
兑换率。

26
00:01:48,300 --> 00:01:54,270
让我们看看是否获得广告五，该广告是通过算法的最高可信度找到的

27
00:01:54,270 --> 00:01:55,990
发现广告排名第五。

28
00:01:56,010 --> 00:01:59,550
因此，希望我们也能获得第五版。

29
00:01:59,550 --> 00:02:05,290
从逻辑上讲，如果我们设法在总回报上击败了较高的置信度，那就应该是这样。

30
00:02:05,340 --> 00:02:08,930
因此，让我们执行此操作，让我们在本节中实现Tomson采样。

31
00:02:09,030 --> 00:02:14,940
实际上，我们将一步一步地做到这一点，因为当您考虑它时，我们只需进行更改

32
00:02:15,060 --> 00:02:21,030
在这四个策略中，循环执行，然后保持相同以实施Thompson，因为

33
00:02:21,030 --> 00:02:24,810
您知道我们将在此处保留这些参数，即此轮数。

34
00:02:24,870 --> 00:02:30,980
此数字会将“选择时”添加到包含每个回合中选择的所有不同广告的向量中。

35
00:02:30,990 --> 00:02:35,720
这将需要更改，因为这些是Opera对算法的信心的参数

36
00:02:35,770 --> 00:02:37,000
因此我们需要进行更改。

37
00:02:37,170 --> 00:02:43,440
当然，我们将保留此总奖励，因为我们希望获得通过累积的总奖励

38
00:02:43,440 --> 00:02:47,060
汤普森采样算法的执行。

39
00:02:47,070 --> 00:02:55,560
所以我们现在要做的就是简单地将所有内容从这里复制到这里，然后粘贴到这里

40
00:02:55,650 --> 00:02:58,110
我们只会改变我们需要改变的东西。

41
00:02:58,110 --> 00:03:02,340
这是汤普森采样算法运行标杆的权利。

42
00:03:02,640 --> 00:03:04,260
好吧，让我们开始吧。

43
00:03:04,260 --> 00:03:14,400
我们已经可以在此处用Thomson采样代替UCAP，现在让我们在改变策略之前

44
00:03:14,400 --> 00:03:21,000
别忘了去这里进行全面探索，为我们设置合适的工作目录，以便轻松加固机器

45
00:03:21,000 --> 00:03:21,810
学习。

46
00:03:21,840 --> 00:03:26,840
汤普森抽样，然后确保您将其作为城市进行了优化。

47
00:03:26,880 --> 00:03:32,580
是的，父神当然与我们在置信度上限内的档案相同。

48
00:03:32,760 --> 00:03:38,400
因此，在这种情况下，您准备单击此处的此小按钮以将该文件夹设置为工作状态

49
00:03:38,400 --> 00:03:39,300
目录。

50
00:03:39,660 --> 00:03:42,480
好的，现在让我们实现我们的。

51
00:03:42,480 --> 00:03:44,070
汤普森采样算法。

52
00:03:44,160 --> 00:03:49,270
因此，让我们直接跳到汤普森某种算法的幻灯片上。

53
00:03:49,400 --> 00:03:51,380
好的，所以我们在这里看到什么。

54
00:03:51,380 --> 00:03:54,230
汤普森某种算法需要三个步骤。

55
00:03:54,230 --> 00:04:01,160
第一步是，每轮我们需要考虑两个数字，每个第一个数字是

56
00:04:01,160 --> 00:04:07,540
我得到的ADD次数是一次，第二次是

57
00:04:07,670 --> 00:04:09,740
我知道我们到零为止。

58
00:04:09,760 --> 00:04:13,160
这就是我们在这里要做的第一件事。

59
00:04:13,220 --> 00:04:20,150
我们将考虑这些参数并声明与这些参数对应的变量，然后

60
00:04:20,150 --> 00:04:25,630
可以注意到，如果我们将此汤普森算法与UCB算法进行比较。

61
00:04:25,820 --> 00:04:32,000
好吧，这是具有不同参数的同一第一步，因为您在第一步中会注意到

62
00:04:32,000 --> 00:04:37,880
关于算法的最高可信度，我们还考虑了两个数字，这两个数字是

63
00:04:37,880 --> 00:04:44,190
和我被选出的次数到四舍五入，和我的单词的总和到大约。

64
00:04:44,190 --> 00:04:50,180
因此，如果我们在这里查看此代码部分，则为上方来自咒语的代码部分

65
00:04:50,250 --> 00:04:51,070
对数。

66
00:04:51,200 --> 00:04:58,280
好，我们可以看到这两个参数在这里，而这些参数不再是参数

67
00:04:58,280 --> 00:05:04,430
对于汤普森采样，我们在UCB算法的第1步中考虑的这两个参数实际上是

68
00:05:04,430 --> 00:05:09,080
在Tomsen采样算法中被两个新参数取代。

69
00:05:09,080 --> 00:05:14,820
所以我们现在要做的只是删除这两个参数

70
00:05:14,820 --> 00:05:21,080
在使用算法的步骤1中，将其替换为我们需要的这两个新参数

71
00:05:21,080 --> 00:05:23,400
考虑使用汤普森采样算法。

72
00:05:23,420 --> 00:05:25,370
因此，让我们立即更换它们。

73
00:05:25,490 --> 00:05:28,480
因此，我们声明两个新变量。

74
00:05:28,550 --> 00:05:31,910
因此，首先我获得的ADD次数越长。

75
00:05:31,910 --> 00:05:33,600
我们是周围的两个人之一。

76
00:05:33,830 --> 00:05:42,730
因此，我们将此数字称为我们想要的数字，然后加下划线并指定一个数字

77
00:05:42,730 --> 00:05:44,300
广告获得的次数。

78
00:05:44,310 --> 00:05:45,040
我们想要一个。

79
00:05:45,310 --> 00:05:52,630
然后第二个数字是我得到的广告达到0的次数，因此我们

80
00:05:52,630 --> 00:05:56,800
将创建无效数量的奖励零。

81
00:05:56,850 --> 00:05:59,230
现在我们将要成为这两个变量。

82
00:05:59,230 --> 00:06:04,810
这些就是汤普森采样的参数，这是我们将要采取的未来策略的本质

83
00:06:04,810 --> 00:06:05,850
在这里。

84
00:06:05,860 --> 00:06:12,000
因此，这两个变量将成为具有10个元素的元素的某些向量。

85
00:06:12,160 --> 00:06:18,050
正如您可能已经猜到的那样，每增加一个，它们就会包含我们想要的次数

86
00:06:18,050 --> 00:06:20,950
直到周围，零到周围。

87
00:06:20,950 --> 00:06:27,170
因此，我们将采用与歌剧置信度相同的方式初始化这些向量

88
00:06:27,170 --> 00:06:30,970
我们将把这个零放在方括号中乘以深。

89
00:06:31,120 --> 00:06:36,060
这将创建元素的向量，并且那些元素为零。

90
00:06:36,070 --> 00:06:44,200
因此，这就是我们将如何通过10个零的向量初始化这两个变量的方式。

91
00:06:44,200 --> 00:06:45,880
好吧，这里也一样。

92
00:06:45,880 --> 00:06:47,800
等于零乘以t。

93
00:06:47,860 --> 00:06:53,090
因为当然在开始时，每个加法的单词数当然为零。

94
00:06:53,260 --> 00:06:55,600
因为只是没有选择每个添加项。

95
00:06:55,900 --> 00:06:56,280
好吧。

96
00:06:56,290 --> 00:06:58,360
因此，我们有两个论点。

97
00:06:58,360 --> 00:07:01,650
这意味着步骤1已经完成，我们可以继续进行步骤2。

98
00:07:01,810 --> 00:07:04,160
因此，第二步是每个步骤。

99
00:07:04,190 --> 00:07:10,210
我将从这个分布中随机抽取一个值，以下是beta分布。

100
00:07:10,330 --> 00:07:11,230
为什么是这样。

101
00:07:11,250 --> 00:07:15,960
这是因为我们这里有两个与患者推论有关的重要假设。

102
00:07:16,240 --> 00:07:22,310
因此，第一个假设是这里的第一行，我们假设每个我想我们都会从新

103
00:07:22,510 --> 00:07:27,270
参数Theta I的分布，即成功的概率。

104
00:07:27,340 --> 00:07:32,830
通过向大量用户展示广告，您可以想象这种成功的可能性

105
00:07:32,830 --> 00:07:38,640
百万用户和Thida I可以解释为结果是

106
00:07:38,650 --> 00:07:44,140
成功次数除以我们选择ADD的总次数（即一百万）。

107
00:07:44,140 --> 00:07:49,840
所以基本上，眼睛是成功的概率，就是我们成为1的概率

108
00:07:49,840 --> 00:07:51,170
我们选择添加。

109
00:07:51,190 --> 00:07:58,010
因此，假设我从伯努利分布的

110
00:07:58,120 --> 00:08:04,260
参数Theta I是成功的概率，然后第二个假设的强度较小

111
00:08:04,260 --> 00:08:08,890
比第一个假设最强的假设，我们有第二个假设

112
00:08:08,890 --> 00:08:14,530
这是第二行，这就是我们假设AI的分布均匀

113
00:08:14,530 --> 00:08:20,600
先验分布，然后我们使用贝叶斯规则得出后验分布，即P-T

114
00:08:20,620 --> 00:08:23,420
给予我们圆满的回报。

115
00:08:23,470 --> 00:08:29,670
因此，通过使用贝叶斯规则，这就是我们到此处的最佳方式。

116
00:08:29,710 --> 00:08:33,820
因此，通过采取趋势，可以随意抽取这些beta分布。

117
00:08:34,030 --> 00:08:39,310
好吧，既然这些随机抽奖别无其他，成功的可能性就得到了

118
00:08:39,310 --> 00:08:44,620
这里是从无人机中获取最大的这些，因为这些随机掉落的最大值是

119
00:08:44,620 --> 00:08:48,310
接近成功的最高可能性。

120
00:08:48,430 --> 00:08:54,500
这就是汤普森（Tompson）背后的全部想法，我们正在尝试估算这些参数。

121
00:08:54,620 --> 00:09:00,010
这10个中的每个都有成功的可能性，然后通过随机抽取并

122
00:09:00,010 --> 00:09:05,740
他们当中最高的是我们估计成功的最高概率，而这个最高概率

123
00:09:05,740 --> 00:09:09,540
成功次数对应于每一轮的一次特定增加。

124
00:09:09,700 --> 00:09:13,490
因此，当我们进行随机抽奖时，特定的回合可能是错误的。

125
00:09:13,630 --> 00:09:19,540
但是，当我们进行数千轮随机抽奖时，我们将仅基于概率的本质

126
00:09:19,840 --> 00:09:25,900
我们获得与成功概率最高的广告对应的所有theta。

127
00:09:25,990 --> 00:09:28,690
那就是获得奖励的最高概率等于1。

128
00:09:28,960 --> 00:09:31,160
这就是汤普森采样背后的想法。

129
00:09:31,240 --> 00:09:36,280
顺便说一下，这些随机抽取的最大值就是这些估计的最大值

130
00:09:36,280 --> 00:09:38,520
获得奖励的概率等于1。

131
00:09:38,680 --> 00:09:41,100
好吧，这只是第三步。

132
00:09:41,230 --> 00:09:47,770
所以现在我们要做的是实施由第二步和第三步组成的策略

133
00:09:47,770 --> 00:09:52,500
此处的代码部分替换了获得较高信任度的旧策略。

134
00:09:52,880 --> 00:09:58,900
好，让我们高效地进行操作让我们将逻辑保留在此代码节的后面，不要删除所有内容

135
00:09:58,900 --> 00:09:59,680
太快了。

136
00:09:59,800 --> 00:10:03,250
您知道，因为我们将在每个回合中对每个添加项进行不同的随机抽奖。

137
00:10:03,430 --> 00:10:09,250
并且由于我们需要很好地进行这个最高随机抽取，因此我们应该在这里保持这种编码策略，

138
00:10:09,580 --> 00:10:12,370
获得某物的最大值。

139
00:10:12,520 --> 00:10:14,780
因此，我们将替换此Max。

140
00:10:14,780 --> 00:10:22,300
这里的问题是最大随机数，因为您知道在UCB算法中我们需要取最大

141
00:10:22,390 --> 00:10:28,300
康普顿上限，对于汤普森，我们需要进行最大随机抽取，因此我们称

142
00:10:28,300 --> 00:10:31,290
这个最大随机数最大随机数。

143
00:10:31,360 --> 00:10:31,740
好吧。

144
00:10:31,750 --> 00:10:38,390
然后我们当然将其保持为零，因为没有，这仅仅是为了初始化添加的内容

145
00:10:38,990 --> 00:10:44,600
特定人群，因为我们当然需要配合一些东西，我们需要挑选这些东西展示给用户。

146
00:10:44,690 --> 00:10:48,230
因此，我们将这篇文章设为零，这则广告等于我听到的信息。

147
00:10:48,410 --> 00:10:55,970
但是，我们绝对需要在此处更改的是其他情况，因为其他情况是直接特定的

148
00:10:56,090 --> 00:10:58,130
对策略充满信心。

149
00:10:58,190 --> 00:11:03,490
因此，我们将删除它，现在将实施汤普森采样策略。

150
00:11:03,920 --> 00:11:09,990
因此，我们要做的第一件事是生成10个广告中每个广告的随机抽奖。

151
00:11:10,070 --> 00:11:15,110
因此，我们将其保留在0 D范围内，因为我们需要此循环来遍历10个广告。

152
00:11:15,200 --> 00:11:17,300
因此，现在我们需要进行随机抽奖。

153
00:11:17,420 --> 00:11:23,960
因此，我们将在这里声明一个新变量，我们将其称为random和score数据，以及

154
00:11:23,960 --> 00:11:28,430
课程将与不同的跑步次数相对应，因为这些是从

155
00:11:28,520 --> 00:11:30,410
Beta分布。

156
00:11:30,410 --> 00:11:38,650
所以等于，现在我们将使用Python的函数，它是随机点数据变量

157
00:11:38,780 --> 00:11:41,920
功能，将为我们提供所需的功能。

158
00:11:41,930 --> 00:11:47,770
就是说，它将随机抽取我们选择的参数的beta分布，

159
00:11:47,810 --> 00:11:53,120
正如我们在幻灯片上看到的那样，第一个参数是我获得广告的次数

160
00:11:53,120 --> 00:11:59,750
一加一，第二个参数是我得到的加数是0加1的次数。

161
00:11:59,930 --> 00:12:00,950
因此，让我们开始吧。

162
00:12:00,950 --> 00:12:05,110
我们只需要标记两个参数，这两个参数分别是什么。

163
00:12:05,330 --> 00:12:08,080
好吧，只是有一些奖励。

164
00:12:08,240 --> 00:12:12,440
我要在这里讲的是第一个论点。

165
00:12:12,440 --> 00:12:18,650
当然，由于这与特定广告相对应，因此我将在此处添加一些括号并进行广告

166
00:12:18,710 --> 00:12:23,480
idlis这是我们在这个特定时间正在处理的，因为我看起来它只是对应

167
00:12:23,480 --> 00:12:24,910
投放到特定广告。

168
00:12:25,100 --> 00:12:30,530
而且，我们不要忘记这里的加号，然后输入第二个参数。

169
00:12:30,530 --> 00:12:37,430
当然，如果您想要零向量，则第二个参数将是这些数字的索引。

170
00:12:37,460 --> 00:12:43,900
因此，如果我们想在此处添加零，我们将放置这些数字，并在其中添加一些括号，并在其中添加索引。

171
00:12:44,090 --> 00:12:51,260
然后让我们不要忘记这里的加号，这是该beta分布的两个参数

172
00:12:51,260 --> 00:12:53,570
我们正在随机抽奖。

173
00:12:53,590 --> 00:12:55,860
好的，所以我们有需要的一切。

174
00:12:55,990 --> 00:13:01,880
现在，我们当然需要在这里使用if条件来获得最大的随机性

175
00:13:01,880 --> 00:13:02,660
绘制。

176
00:13:02,660 --> 00:13:08,570
因此，对您而言，一个不错的练习是解析此视频，然后尝试在此处完成此代码部分

177
00:13:08,570 --> 00:13:11,120
在这里猜测该代码的最后一个元素。

178
00:13:11,330 --> 00:13:13,090
所以我现在要告诉你。

179
00:13:13,310 --> 00:13:16,430
现在，我们需要最大程度地利用这些随机抽奖。

180
00:13:16,550 --> 00:13:22,660
我们已经在这里声明了Max随机变量，它将是这些随机抽取的最大值。

181
00:13:22,790 --> 00:13:24,620
因此，您猜对了。

182
00:13:24,620 --> 00:13:32,710
现在我们需要用Max random替换这里的Max，当然这里我们需要替换

183
00:13:32,860 --> 00:13:36,220
上限为随机数据。

184
00:13:36,370 --> 00:13:36,970
好。

185
00:13:37,120 --> 00:13:45,280
然后相同的是我们替换了Max，这里用Max random表示，这里取其平均值，用random表示

186
00:13:46,060 --> 00:13:46,780
数据。

187
00:13:47,260 --> 00:13:50,700
最终我们当然将其保持等于I。

188
00:13:50,920 --> 00:13:51,220
好。

189
00:13:51,220 --> 00:13:53,690
因此，让我们快速地重新解释这里发生的事情。

190
00:13:53,800 --> 00:13:56,250
对于这里的每个AM我都在这里循环。

191
00:13:56,470 --> 00:14:00,610
好吧，我们从参量分布的分布中随机抽取。

192
00:14:00,640 --> 00:14:06,070
我们想要1 +1的Akhet的次数，以及我们0 +1所得到的广告的次数

193
00:14:06,070 --> 00:14:09,430
然后每次我们从该分布中随机抽取一个。

194
00:14:09,550 --> 00:14:14,450
好了，我们在这里检查了这个随机抽签是否高于这个最大随机抽签。

195
00:14:14,500 --> 00:14:19,920
所以当然是第一次，因为最大随机数被初始化为零，所以会这样。

196
00:14:20,020 --> 00:14:25,180
因此，此条件适用于第一个广告，因此“最大随机数”将等于第一个广告

197
00:14:25,360 --> 00:14:26,620
在这里随机抽奖。

198
00:14:26,710 --> 00:14:28,420
因此，我们首先将其保留在这里。

199
00:14:28,600 --> 00:14:30,580
然后，当我们继续下一个时。

200
00:14:30,580 --> 00:14:35,950
然后发生的是，我们从这些参数的beta分布中又抽了一次

201
00:14:35,950 --> 00:14:38,640
这里对应于你我。

202
00:14:38,740 --> 00:14:43,870
然后，如果此新随机抽奖高于此最大值，则等于前一次随机抽奖

203
00:14:43,870 --> 00:14:44,380
画。

204
00:14:44,500 --> 00:14:49,750
好吧，这意味着该条件为真，因此“最大随机数”采用该新随机数的值

205
00:14:49,750 --> 00:14:52,950
抽奖，因此我们选择此新广告。

206
00:14:52,990 --> 00:14:57,880
我听说随机抽奖次数最多，而我们忘记了之前选择的广告，因为

207
00:14:57,880 --> 00:15:00,040
只是它的随机抽奖较低。

208
00:15:00,040 --> 00:15:05,290
好的，这就是我们正在实施的Tomsen采样的想法和策略。

209
00:15:05,350 --> 00:15:06,760
每轮。

210
00:15:06,760 --> 00:15:11,700
因此，现在我们可以注意到这里有这个小警告，因此我们必须注意这一点。

211
00:15:11,740 --> 00:15:15,470
这表示我们有Nunda随机找到名字。

212
00:15:15,700 --> 00:15:20,080
因此，这当然是因为我们在这里使用此随机拍子非常有用。

213
00:15:20,200 --> 00:15:25,810
由于此函数来自库，因此我们需要导入包含此函数的库。

214
00:15:25,840 --> 00:15:27,260
这就是我们现在要做的。

215
00:15:27,370 --> 00:15:34,330
实际上，我们可以注意到我们不需要此数学库，因为我们没有使用任何平方根

216
00:15:34,330 --> 00:15:39,820
或锁定功能，因此我们在这里不需要此库，我们可以用该库替换它。

217
00:15:39,820 --> 00:15:47,280
我们需要在每个函数中使用此随机位，并且该库是随机的。

218
00:15:47,350 --> 00:15:47,680
好吧。

219
00:15:47,680 --> 00:15:53,980
因此，导入Ranum，现在此警告消失，我们可以使用此功能。

220
00:15:53,980 --> 00:15:54,660
大。

221
00:15:54,760 --> 00:15:56,800
因此，现在我们几乎拥有了所需的一切。

222
00:15:56,800 --> 00:16:03,580
我们现在需要更新的是这里发生的事情，因为这来自于上层信任

223
00:16:03,580 --> 00:16:04,780
绑定算法。

224
00:16:04,780 --> 00:16:09,370
这就是您知道UCAP算法中步骤1的参数。

225
00:16:09,430 --> 00:16:11,560
因此，我们将需要删除此行。

226
00:16:11,560 --> 00:16:16,850
我们不需要这个，我们必须保留它，因为这是获得真正的回报。

227
00:16:16,990 --> 00:16:22,160
正如我们解释的那样，UCB算法知道这实际上是我们继续获得奖励的方式。

228
00:16:22,210 --> 00:16:28,160
在此模拟数据集中，然后得到的是包含单词和的这一行。

229
00:16:28,180 --> 00:16:33,880
当然，奖励的总和是UCAP算法的一个参数，因此我们需要将其删除

230
00:16:33,880 --> 00:16:34,990
好。

231
00:16:35,080 --> 00:16:40,610
现在，我们已经准备好更新Tomsen某种算法所需的内容。

232
00:16:40,660 --> 00:16:41,110
好吧。

233
00:16:41,110 --> 00:16:45,440
然后我们有了总不存在的总数，我们当然必须保留，因为这是令人兴奋的结果

234
00:16:45,910 --> 00:16:48,660
这是一种绩效评估者。

235
00:16:48,970 --> 00:16:51,350
因此，根据您的需要，我们现在需要什么。

236
00:16:51,490 --> 00:16:55,230
当然，到目前为止，我们需要的是这两个向量。

237
00:16:55,250 --> 00:17:01,660
字数1和我们的数为零，因为您知道在此策略中，我们正在导入

238
00:17:02,080 --> 00:17:03,730
这两个向量的索引。

239
00:17:03,820 --> 00:17:08,470
但是您知道我们需要根据趋势更新它们，否则它们将始终等于零

240
00:17:08,710 --> 00:17:11,170
因为它们被初始化为零。

241
00:17:11,170 --> 00:17:12,460
所以现在我们需要做什么。

242
00:17:12,460 --> 00:17:16,930
获得奖励后，我们需要增加其价值。

243
00:17:16,930 --> 00:17:20,280
因此，让我们看看我们需要为该变量增加多少。

244
00:17:20,280 --> 00:17:21,900
如果我们是一位，这是数字。

245
00:17:21,970 --> 00:17:26,590
好吧，这对应于每个广告在一轮中获得的不同次数。

246
00:17:26,600 --> 00:17:30,570
因此，只有在广告达到1时，我们才需要对其进行递增。

247
00:17:30,790 --> 00:17:32,060
那这个向量呢。

248
00:17:32,170 --> 00:17:36,760
好吧，就是包含每次添加的不同次数的向量

249
00:17:36,760 --> 00:17:38,000
和处为0。

250
00:17:38,150 --> 00:17:43,980
因此，只有在我们选择的成年人达到零时，才需要增加此向量。

251
00:17:44,200 --> 00:17:50,400
因此，由于这取决于我们选择广告时所获得的报酬，因此我们需要一个if条件。

252
00:17:50,620 --> 00:17:57,640
因此，我们将在此处将if条件写为if if，因此条件就是Ward等于

253
00:17:57,640 --> 00:18:00,350
等于1，然后等于科伦。

254
00:18:00,490 --> 00:18:08,050
因此，如果此奖励是在此特定回合中获得的，则当此奖励为1时，我们在此处选择特定奖励

255
00:18:08,200 --> 00:18:14,110
那么我们需要做些什么，我们需要将这个单词的数量增加一个，但是仅针对索引

256
00:18:14,770 --> 00:18:19,300
因为此处的索引对应于所选广告的索引。

257
00:18:19,330 --> 00:18:27,150
因此，让我们来做吧，让我们增加这一奖励数量，让我们复制并在这里面对它，

258
00:18:27,160 --> 00:18:34,290
现在，让我们以广告索引来响应所选广告的索引，然后在此处

259
00:18:34,290 --> 00:18:35,570
我们需要增加它。

260
00:18:35,580 --> 00:18:42,630
因此，我将复制此内容并将其粘贴到此处并添加一个加号。

261
00:18:42,630 --> 00:18:43,120
好吧。

262
00:18:43,170 --> 00:18:48,450
因此，当我们说出一句话是理所当然的事时，我们需要做的就是增加一个加一的次数

263
00:18:48,450 --> 00:18:51,140
这个添加到这里，我们连线了。

264
00:18:51,180 --> 00:18:58,530
好吧，然后我们有了其他，这与我们在这里所说的情况相对应

265
00:18:58,530 --> 00:18:59,550
等于零。

266
00:18:59,580 --> 00:19:05,730
那就是我们选择的广告在特定时间获得零奖励，因此这种情况发生时

267
00:19:05,850 --> 00:19:14,790
这次我们需要增加奖励0的数量，所以我要复制此行并正对它

268
00:19:14,790 --> 00:19:23,130
在这里，然后在此处替换为零，因为我们需要将单词的数量增加为零，但仅

269
00:19:23,130 --> 00:19:26,130
此处对应于此添加索引的值。

270
00:19:26,360 --> 00:19:26,800
好吧。

271
00:19:26,820 --> 00:19:28,020
现在我们完成了。

272
00:19:28,020 --> 00:19:30,740
汤普森实际上已经完全实施了某些措施。

273
00:19:30,900 --> 00:19:31,950
我们拥有所需的一切。

274
00:19:31,950 --> 00:19:33,420
我们在这里有策略。

275
00:19:33,480 --> 00:19:38,710
在这里，我们有了这两个参数的含义，我们就得到了总的回报。

276
00:19:38,860 --> 00:19:42,800
因此，现在该是将结果可视化的激动人心的一步了。

277
00:19:42,900 --> 00:19:44,850
因此，我们将在接下来的两个工作中这样做。

278
00:19:44,880 --> 00:19:46,700
在此之前，请享受机器学习。

