1
00:00:00,390 --> 00:00:02,840
您好，欢迎来到本Python教程。

2
00:00:02,850 --> 00:00:08,580
好吧，现在在此讲义中，我们将自己实现ex-GI boost模型，因此，新代码

3
00:00:08,580 --> 00:00:11,300
这里的部分适合前GI训练集。

4
00:00:11,430 --> 00:00:12,660
因此，让我们开始吧。

5
00:00:12,660 --> 00:00:16,830
因此，正如我在之前的Statoil中所说的那样，我们要做的第一件事是导入正确的类

6
00:00:16,830 --> 00:00:22,240
对于通常称为X G-B分类的工作，它将是相同的。

7
00:00:22,260 --> 00:00:27,000
我们将创建该类的一个对象，该对象将成为我们的分类器，我们将对此进行拟合

8
00:00:27,020 --> 00:00:28,910
反对训练集。

9
00:00:28,920 --> 00:00:30,660
所以，让我们先做。

10
00:00:30,690 --> 00:00:38,100
我们当然要从我们安装的ex-GI boost导入极其分类器类

11
00:00:38,100 --> 00:00:42,130
我们在上一教程中看到的有关此链接的说明。

12
00:00:42,150 --> 00:00:48,890
因此，从实际提升开始，然后导入x G-B分类器。

13
00:00:49,200 --> 00:00:50,030
好了

14
00:00:50,130 --> 00:00:54,810
现在让我们创建这个X G-B分类器类的对象。

15
00:00:54,840 --> 00:00:57,520
因此，正如您所说，此对象是分类器。

16
00:00:57,600 --> 00:01:06,680
因此，我们将像往常一样将此对象分类器称为“对象分类器”，然后将类X作为分类器，

17
00:01:06,720 --> 00:01:07,890
插入语。

18
00:01:08,040 --> 00:01:15,430
现在，如果我按Command，我会收到一些有趣的信息

19
00:01:15,470 --> 00:01:16,690
重新分类。

20
00:01:16,710 --> 00:01:22,200
我们唯一得到的是可以输入的参数列表，我们可以看到我们有一些参数

21
00:01:22,200 --> 00:01:28,620
就像我们在深度学习数估计器中一样的学习率，因为实际上额外的提升

22
00:01:28,620 --> 00:01:30,840
带有树的梯度提升算法。

23
00:01:30,840 --> 00:01:36,390
因此，估算器的数量实际上是树木的数量，然后我们还有其他一些参数，但

24
00:01:36,450 --> 00:01:38,760
我们现在不打算使用这些参数。

25
00:01:38,880 --> 00:01:44,270
这只是这个功能强大的算法的介绍，但是您当然可以找到很多信息

26
00:01:44,310 --> 00:01:45,180
在网上。

27
00:01:45,270 --> 00:01:48,000
请随时问我，我会给您一些参考。

28
00:01:48,000 --> 00:01:54,120
另外，您可以做的第二件事是做一些练习，然后尝试做一些网格搜索参数

29
00:01:54,130 --> 00:02:00,300
例如进行调整以找到某些参数的最佳参数，例如学习率或

30
00:02:00,300 --> 00:02:03,160
您现在知道如何进行估算的数量。

31
00:02:03,240 --> 00:02:09,050
它与上一节中实现网格搜索时所采用的技术完全相同。

32
00:02:09,180 --> 00:02:10,920
好吧，如果您能做到，那就太好了。

33
00:02:10,920 --> 00:02:12,870
那将是极好的实践。

34
00:02:13,050 --> 00:02:19,140
但是现在我们不会输入任何参数，我们将对默认值感到满意

35
00:02:19,140 --> 00:02:22,140
在这个极其机密的课程中

36
00:02:22,140 --> 00:02:27,150
因此，我们将采用迈克典型的三百棵树，其余的很好，因为实际上

37
00:02:27,150 --> 00:02:28,990
我们有一个二进制结果。

38
00:02:29,010 --> 00:02:33,030
因此，目标是二进制后勤，其余部分保留。

39
00:02:33,030 --> 00:02:37,380
您在此处还有另一个伽玛参数，可以尝试通过网格搜索进行调整。

40
00:02:37,410 --> 00:02:42,990
如果您想通过这种额外的提升道德感走得更远，可以随意做任何您想做的事

41
00:02:42,990 --> 00:02:47,310
仅对您有利，如果您需要任何帮助，请随时提出问题。

42
00:02:47,370 --> 00:02:48,400
在这样做的时候。

43
00:02:48,690 --> 00:02:53,300
好的，所以基本上我们从X得到的分类对象应该是分类类。

44
00:02:53,340 --> 00:02:59,700
因此，我们准备继续进行下一行，该行是关于将分类的对象适合训练的

45
00:02:59,700 --> 00:03:00,650
组。

46
00:03:00,660 --> 00:03:08,660
因此，在滚动时，我们将使用分类器对象而不是点，然后使用fit方法进行拟合

47
00:03:08,670 --> 00:03:10,260
方法括号。

48
00:03:10,470 --> 00:03:16,490
在这些括号内，我们可以放入由X火车以及为什么训练组成的训练集。

49
00:03:16,620 --> 00:03:24,840
因此，我们为第一个参数输入X训练，然后为第二个参数训练。

50
00:03:24,930 --> 00:03:30,180
因此，极端是火车集合中的特征矩阵，以及为什么火车在火车中已经是变量向量

51
00:03:30,180 --> 00:03:31,740
相同的训练集。

52
00:03:31,860 --> 00:03:32,580
完善。

53
00:03:32,700 --> 00:03:37,900
实际上就已经准备好额外的boost实现一样简单。

54
00:03:38,190 --> 00:03:43,250
这实际上与我们实现其他分类模型时完全相同。

55
00:03:43,380 --> 00:03:49,050
但是当然，如​​果您认为这太简单了，则可以在此处使用参数并尝试优化

56
00:03:49,050 --> 00:03:50,320
他们的价值观。

57
00:03:50,340 --> 00:03:55,740
所以基本上我们已经准备好了，现在开始执行之前，因为我想这样做很有趣

58
00:03:55,740 --> 00:03:58,830
我想在准备好之后执行整个代码的方式。

59
00:03:58,830 --> 00:04:01,010
因此，我们将再添加三个部分。

60
00:04:01,010 --> 00:04:06,810
您知道一部分可以对测试集进行一些预测，另一部分可以创建计算机矩阵。

61
00:04:06,960 --> 00:04:13,560
最后一项操作是应用仔细的交叉验证以获得相关的准确性或相关的性能

62
00:04:13,560 --> 00:04:17,390
评估我们的Bruce模型的性能的指标。

63
00:04:18,160 --> 00:04:23,420
因此，下一部分将是经过测试的预测，然后是混淆矩阵。

64
00:04:23,440 --> 00:04:28,600
因此，让我们变得高效吧，我们去看看为什么这就是python文件。

65
00:04:28,660 --> 00:04:35,740
让我们继续下去，让我们在这里进行预测和混淆矩阵。

66
00:04:36,160 --> 00:04:41,500
因此，我不仅要提高效率，还要向您展示如何轻松地从

67
00:04:41,500 --> 00:04:43,050
一个玩另一个。

68
00:04:43,060 --> 00:04:47,860
例如，如果您在比赛中使用某种机械，可以轻松拥有多个模板

69
00:04:47,860 --> 00:04:53,040
在您的仪表板上相互跳来跳去，这对您来说很重要。

70
00:04:53,170 --> 00:04:55,250
所以现在这就是我们正在做的。

71
00:04:55,390 --> 00:04:59,100
我们正在使用测试集预测和混淆矩阵代码。

72
00:04:59,140 --> 00:05:05,800
因此，让我们回过头来进行增强，然后面对这一点，我们实际上可以删除此行，因为

73
00:05:06,220 --> 00:05:14,270
我们不会得到的概率将直接获得0和1的预测，并且混淆矩阵还可以。

74
00:05:14,560 --> 00:05:21,190
最后，正如我所说，我们还希望获得Caple交叉验证代码以获取相关的

75
00:05:21,280 --> 00:05:23,510
这个精度极小。

76
00:05:23,620 --> 00:05:30,370
因此，我们也将再次很容易地在这个Caple交叉验证中浏览不同的内容

77
00:05:30,370 --> 00:05:31,110
模板。

78
00:05:31,180 --> 00:05:38,830
这是我们仅需复制的部分，然后返回以进行实际增强，然后粘贴

79
00:05:38,840 --> 00:05:39,530
在这里。

80
00:05:39,700 --> 00:05:42,670
接下来我们准备好我们的代码。

81
00:05:42,880 --> 00:05:49,180
现在，我们只需要做的就是执行它，然后我们就可以喝杯咖啡并观察结果。

82
00:05:49,180 --> 00:05:50,200
因此，让我们开始吧。

83
00:05:50,200 --> 00:05:51,560
我期待向您展示。

84
00:05:51,560 --> 00:05:56,140
我们将在即时执行时间内获得一些惊人的性能。

85
00:05:56,370 --> 00:06:01,190
很快，让我们开始探索我们的父亲机器。

86
00:06:01,300 --> 00:06:08,170
A到Z代表10，而此合唱的最后一部分是49之前的胃肠道。

87
00:06:08,170 --> 00:06:10,630
再次恭喜您在这里。

88
00:06:10,840 --> 00:06:12,020
进去吧

89
00:06:12,100 --> 00:06:13,190
那是为了

90
00:06:13,210 --> 00:06:15,890
确保您具有搅动建模CNC文件。

91
00:06:15,910 --> 00:06:20,170
如果是这种情况，您就可以开始喝咖啡并执行此代码了。

92
00:06:20,440 --> 00:06:21,150
因此，让我们开始吧。

93
00:06:21,160 --> 00:06:22,830
现在，我们在正确的文件夹中。

94
00:06:23,020 --> 00:06:25,810
让我们从执行日常预处理阶段开始。

95
00:06:25,810 --> 00:06:31,780
所以我要选择从这里到顶部的所有内容，然后按Commander Control按Enter

96
00:06:32,110 --> 00:06:33,660
执行。

97
00:06:33,670 --> 00:06:34,210
开始了。

98
00:06:34,220 --> 00:06:35,550
所有执行正确。

99
00:06:35,770 --> 00:06:41,740
因此，如果我们要进行变量探索，请确保我们拥有重要的数据集，而且非常非常快

100
00:06:41,740 --> 00:06:42,680
提醒。

101
00:06:42,730 --> 00:06:46,510
该数据集包含一些银行客户的信息。

102
00:06:46,510 --> 00:06:52,540
我们选择的自变量都是从信用评分到估计的自变量

103
00:06:52,540 --> 00:06:54,650
工资和因变量。

104
00:06:54,640 --> 00:06:57,250
这说明存在的可行性。

105
00:06:57,250 --> 00:06:59,960
如果是或否，则客户已离开银行。

106
00:07:00,160 --> 00:07:05,670
因此，这是六个月的时间，在这六个月中，如果客户离开，我们将得到一个

107
00:07:05,670 --> 00:07:06,960
银行和零。

108
00:07:06,970 --> 00:07:12,400
如果客户没有离开银行，那么我们正在数据集中训练这种额外的提升模型

109
00:07:12,670 --> 00:07:18,640
以便它了解这些信息之间的相关性，例如信用评分，地理位置

110
00:07:18,640 --> 00:07:24,790
性别年龄平衡表（无论客户是否使用信用卡）和估计工资

111
00:07:25,180 --> 00:07:31,810
以及客户决定离开银行的决定，因此这是

112
00:07:31,810 --> 00:07:36,820
我们将客户分为两类：离开的和留下的

113
00:07:37,690 --> 00:07:42,580
然后我们的目标是为未来的客户做出一些预测，并预测他们是否会

114
00:07:42,580 --> 00:07:44,690
离开银行是或否。

115
00:07:45,040 --> 00:07:51,400
因此，让我们按OK（确定），现在让我们继续进行令人兴奋的部分，让我们进一步增加训练量。

116
00:07:51,430 --> 00:08:00,340
因此，我将首先导入要分类的X类，然后再进行额外的分类类

117
00:08:00,400 --> 00:08:03,240
以及从极端分子那里进口的

118
00:08:03,400 --> 00:08:07,720
现在，让我们将分类器对象适合训练集。

119
00:08:07,720 --> 00:08:10,480
因此，我们将在这里选择这两行。

120
00:08:10,720 --> 00:08:12,280
让我们执行。

121
00:08:12,280 --> 00:08:13,250
开始了。

122
00:08:13,370 --> 00:08:20,190
创建分类对象并将其拟合到火车上，并选择所有默认参数。

123
00:08:20,320 --> 00:08:26,290
因此，例如，我们在X中有100棵树来提高等级和士气。

124
00:08:26,290 --> 00:08:26,840
好吧。

125
00:08:26,850 --> 00:08:29,480
现在让我们进行测试集预测。

126
00:08:29,530 --> 00:08:32,580
因此，我将选择此行并执行。

127
00:08:32,590 --> 00:08:33,330
开始了。

128
00:08:33,430 --> 00:08:39,140
因此，这是对客户是否离开银行的决定的预测。

129
00:08:39,290 --> 00:08:40,170
组。

130
00:08:40,180 --> 00:08:41,990
因此，我们在这里得到了预测。

131
00:08:42,190 --> 00:08:44,670
那就是前地理标志提升所做出的预测。

132
00:08:44,680 --> 00:08:50,920
因此，例如，预计第一个客户不会离开银行，而六个客户则预计会离开银行

133
00:08:50,920 --> 00:08:52,370
离开银行。

134
00:08:52,810 --> 00:08:55,110
好的，但这不是最有趣的。

135
00:08:55,120 --> 00:09:00,970
首先有趣的是获取混淆度指标，因为我们将首先了解准确性

136
00:09:01,240 --> 00:09:03,890
但随后我们将获得相关的准确性。

137
00:09:03,910 --> 00:09:10,670
因此，让我们从执行此混淆矩阵的混淆矩阵Rigaud中获取准确性开始

138
00:09:10,660 --> 00:09:19,450
在这里，我们可以看到我们有很多正确的预测我们有1521个客户的正确预测

139
00:09:19,450 --> 00:09:24,900
不会离开银行，而208会纠正，但是离开银行的客户的行为。

140
00:09:25,180 --> 00:09:29,540
然后，我们得到197加74个错误的预测。

141
00:09:29,650 --> 00:09:36,970
因此，由于我们的测试集中有2000个观测值，而且我们有1521个加上208个

142
00:09:37,180 --> 00:09:41,030
等于一千一百二十九。

143
00:09:41,200 --> 00:09:43,470
好吧，让我们快速准确地计算出准确度。

144
00:09:43,630 --> 00:09:46,270
因此，准确度是正确预测的数量。

145
00:09:46,270 --> 00:09:52,430
就像我们刚才所说的1729除以2000。

146
00:09:52,750 --> 00:09:59,140
如果我们去，我们可以获得86％的准确度，但这并不是获得最大收获的最相关准确度

147
00:09:59,140 --> 00:10:02,470
相关的准确性，我们需要进行仔细的交叉验证。

148
00:10:02,470 --> 00:10:08,830
所以这就是我们现在要做的，希望我们能达到86％的良好准确性

149
00:10:09,220 --> 00:10:14,710
作为我们通过仔细考虑不同交易而计算出的几种精度的平均值

150
00:10:14,710 --> 00:10:16,140
故障和测试故障。

151
00:10:16,330 --> 00:10:18,750
因此，让我们现在了解一下。

152
00:10:18,820 --> 00:10:21,310
这是10倍的K4辐射。

153
00:10:21,340 --> 00:10:23,980
因此，这意味着我们将获得10个精度。

154
00:10:24,010 --> 00:10:29,010
正如您所看到的，我们采用这10个精度的平均值以及标准偏差。

155
00:10:29,020 --> 00:10:30,620
您是否了解差异。

156
00:10:30,760 --> 00:10:33,730
因此，这确实更加重要。

157
00:10:33,730 --> 00:10:36,230
好的，让我们执行该部分。

158
00:10:36,250 --> 00:10:37,120
开始了。

159
00:10:37,910 --> 00:10:45,560
花一秒钟或两秒钟执行，最终我们得到1％的标准偏差，

160
00:10:45,560 --> 00:10:51,110
精度，我们需要重新计算蜘蛛只是想将悬念保持到最后一秒，但我们

161
00:10:51,110 --> 00:10:53,830
现在要获取均值，我们只需要执行该操作即可。

162
00:10:53,930 --> 00:10:54,750
现在我们开始。

163
00:10:54,830 --> 00:11:01,280
我们得到的平均值为86％，这显然意味着我们极小的精度大约是

164
00:11:01,310 --> 00:11:10,190
86％，因为不但平均跌幅超过10时达到86％，而且方差仅为1％

165
00:11:10,640 --> 00:11:19,170
因此，在大多数情况下，准确度将在86减去1％之间，即85％，

166
00:11:19,270 --> 00:11:22,790
是6加1％，即87％。

167
00:11:22,790 --> 00:11:25,420
因此很明显，我们获得了非常好的准确性。

168
00:11:25,670 --> 00:11:31,280
而且很难改进它，因为正如我们之前所说的那样，它受到问题的限制

169
00:11:31,280 --> 00:11:31,910
本身。

170
00:11:32,120 --> 00:11:38,450
好吧，您可以尝试通过网格搜索进行一些参数调整，以优化的值

171
00:11:38,450 --> 00:11:44,690
X中要分类的类中的不同参数，但我怀疑您会得到更好的结果

172
00:11:44,690 --> 00:11:46,120
准确性比这高。

173
00:11:46,130 --> 00:11:49,130
6％的人也许会设法提高一点。

174
00:11:49,160 --> 00:11:52,950
好吧，实际上，我非常感兴趣地看看可以通过参数调整获得什么。

175
00:11:53,030 --> 00:11:56,580
因此，不要为了练习而将其作为家庭作业。

176
00:11:56,690 --> 00:12:01,720
此外，您还可以通过它很好地浏览我们学到的许多技术，并进行一些参数化

177
00:12:01,900 --> 00:12:03,050
与网格搜索。

178
00:12:03,110 --> 00:12:04,570
很好的做法。

179
00:12:04,580 --> 00:12:10,220
我强烈建议您这样做，现在是时候说再见了，因为这实际上是

180
00:12:10,220 --> 00:12:12,340
最后一头野牛在这道菜上劳作。

181
00:12:12,470 --> 00:12:16,970
这是一种感觉，因为这是我介绍的机器学习之旅的终点

182
00:12:16,970 --> 00:12:19,340
在本课程的第一个教程中。

183
00:12:19,340 --> 00:12:22,160
是的，那是对的，这就是旅程的终点​​。

184
00:12:22,160 --> 00:12:25,850
但是，我确信这不是最后的机器学习旅程。

185
00:12:26,000 --> 00:12:28,090
这是您的第一次宣教之旅。

186
00:12:28,100 --> 00:12:30,500
我很高兴与您一起进行这次冒险。

187
00:12:30,500 --> 00:12:33,340
我非常喜欢这一旅程，希望您也是如此。

188
00:12:33,440 --> 00:12:38,630
我会很高兴在课程中加入一些新机器，以开始一些新的机器之旅。

189
00:12:38,690 --> 00:12:40,270
所以我希望很快能见到你。

190
00:12:40,340 --> 00:12:42,170
直到那时学习。

