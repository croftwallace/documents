1
00:00:00,690 --> 00:00:03,190
您好，欢迎回到机器学习课程。

2
00:00:03,330 --> 00:00:09,490
在今天的Tauriel中，我将向您展示我对我最后一次向您提出的挑战的解决方案。

3
00:00:09,740 --> 00:00:15,450
因此，在上一个教程中，我们面临着计算某人的后验概率的挑战

4
00:00:15,450 --> 00:00:21,540
成为一个努力工作的人，并且考虑到他们被安置在我们所处的位置

5
00:00:21,630 --> 00:00:24,530
对我们女儿的新观察说。

6
00:00:24,660 --> 00:00:29,830
因此，基本上，进行新观察或提出开车上班的人的可能性是多少

7
00:00:29,840 --> 00:00:30,040
。

8
00:00:30,330 --> 00:00:35,240
我们每个人的计算方式都是使用我们面前的贝叶斯定理。

9
00:00:35,440 --> 00:00:36,710
现在，我们将逐步解决它。

10
00:00:36,800 --> 00:00:41,250
我们将计算概率，然后计算边际可能性，然后

11
00:00:41,250 --> 00:00:45,400
计算可能性，我们可以一路比较。

12
00:00:45,420 --> 00:00:47,250
如果您得到相同的结果。

13
00:00:47,430 --> 00:00:48,770
因此，让我们来看一下。

14
00:00:49,290 --> 00:00:50,500
这就是我们的数据集。

15
00:00:50,520 --> 00:00:55,290
现在让我们向左移动，使MySpace和我们要计算的第一件事是

16
00:00:55,290 --> 00:01:00,150
概率先验概率两种思考方式，第一种思考方式

17
00:01:00,150 --> 00:01:06,050
如果我现在只是从我们的数据集中随机选择一个人的话。

18
00:01:06,270 --> 00:01:11,340
因此，如果不自动包括成绩，那么您可以确定我是否从那里随机选择一个人，

19
00:01:11,340 --> 00:01:14,910
他们成为开车上班的人的可能性。

20
00:01:14,910 --> 00:01:15,360
对。

21
00:01:15,480 --> 00:01:20,190
这就是答案的数量，即绿色的数量或总数

22
00:01:20,190 --> 00:01:20,840
点。

23
00:01:21,150 --> 00:01:27,360
另一种思考的方式是，是否只是将一个新的数据点随机地放入我们的数据集中？

24
00:01:27,360 --> 00:01:33,540
只是随机地，不知道他们的年龄或薪水，然后才知道所有这些

25
00:01:33,540 --> 00:01:38,490
我们有绿点和红点的信息，那个人的可能性是

26
00:01:38,490 --> 00:01:43,050
我们正在增加，或者可能会有一个开车去上班的人。

27
00:01:43,170 --> 00:01:49,200
同样，我们没有非常简单，因为除了计算概率外，我们别无选择

28
00:01:49,200 --> 00:01:54,510
并根据我们所知道的来分配概率，这就是将绿色点20

29
00:01:54,540 --> 00:01:59,130
绿色点除以此处的点总数，并将其分配为概率。

30
00:01:59,130 --> 00:02:03,260
因此，我们没有其他选择，因此它的计算方式就是如此。

31
00:02:03,300 --> 00:02:09,000
因此，某人成为开车上班的人或从我们中选出的随机Daut的可能性

32
00:02:09,000 --> 00:02:15,030
开车上班的人的现有点是司机的数量，该数量除以20除以总数

33
00:02:15,030 --> 00:02:16,310
持续时间是30

34
00:02:16,330 --> 00:02:18,110
所以20或30

35
00:02:18,420 --> 00:02:20,930
这就是我们这样做的先验概率。

36
00:02:20,940 --> 00:02:23,120
下一个是边际可能性。

37
00:02:23,220 --> 00:02:29,070
因此，让我们继续进行计算，您会发现边际可能性实际上正在

38
00:02:29,070 --> 00:02:31,910
与上一教程完全相同。

39
00:02:31,920 --> 00:02:33,410
我们将分别讨论。

40
00:02:33,540 --> 00:02:39,100
因此，我们将再次围绕观察值画一个圆，以删除观察值。

41
00:02:39,100 --> 00:02:40,540
它没有阻碍。

42
00:02:40,780 --> 00:02:42,800
我们将在这个区域遮荫。

43
00:02:42,900 --> 00:02:49,230
所以现在边际可能性就是问题，如果我只是随机选择一个

44
00:02:49,230 --> 00:02:52,330
来自我们数据集中的点。

45
00:02:52,410 --> 00:02:54,710
我有可能从这里选一个。

46
00:02:54,710 --> 00:03:01,860
所以我们将X放在这里的原因是因为我选择观察的可能性是多少

47
00:03:02,010 --> 00:03:08,960
具有与我们要添加到数据集中的那个点相似的特征。

48
00:03:08,970 --> 00:03:12,930
因此，我们要添加的一点是，我们刚刚将其删除了，并且我们同意

49
00:03:12,960 --> 00:03:21,000
圆内的任何点都被认为与该数据相似，或者换句话说，被视为正在展示

50
00:03:21,000 --> 00:03:22,570
类似的功能。

51
00:03:22,650 --> 00:03:28,130
如此的年龄和类似的薪水，这就是我们要计算的。

52
00:03:28,140 --> 00:03:33,060
所以X非常简单，我们只需要计算相似观测值的数量

53
00:03:33,060 --> 00:03:38,460
实际落在这里是四除以观测总数30

54
00:03:38,460 --> 00:03:45,630
将给我们一个新点落在这里的可能性，或者如果我们只是随机选择一个点

55
00:03:45,630 --> 00:03:51,210
现在从我们的数据集中获取点，那么其中超过30个的可能性就很大。

56
00:03:51,230 --> 00:03:51,690
好了

57
00:03:51,780 --> 00:03:53,020
四三点。

58
00:03:53,370 --> 00:03:58,890
好的，这就是我们完成的边际可能性，现在我们将继续讨论可能性

59
00:03:59,280 --> 00:04:05,310
而这次将是某人展示X的特征或相似的可能性

60
00:04:05,310 --> 00:04:11,760
鉴于我们只查看正在开车上班的人，所以我们添加到的数据点

61
00:04:11,780 --> 00:04:12,100
。

62
00:04:12,420 --> 00:04:14,020
因此，让我们看一下。

63
00:04:14,730 --> 00:04:21,000
这是我们的数据集，我们将再次在数据点周围画一个圆，将其取出，然后

64
00:04:21,480 --> 00:04:22,600
添加阴影。

65
00:04:22,620 --> 00:04:28,230
因此，现在的问题是，我们只与开车上班的人打交道，

66
00:04:28,380 --> 00:04:33,100
如果我们选择其中一个，该人将表现出与x相似的特征。

67
00:04:33,420 --> 00:04:38,150
因此，因为我们仅与开车上班的人打交道，所以我们可以忘记红点。

68
00:04:38,180 --> 00:04:42,720
还有其他棚屋消失了，现在我们只处理绿点。

69
00:04:42,720 --> 00:04:48,200
因此提出了一个问题，我们要从所有开车的人中选择一个随机点。

70
00:04:48,210 --> 00:04:53,390
因此，这种垂直杆驱动意味着有人开车去工作。

71
00:04:53,400 --> 00:04:59,130
因此，我们绕着他转圈指出了这些可能性，他们将展现出类似的特征

72
00:04:59,130 --> 00:05:07,080
我们同意的X等于它们落入圆圈内，并且可能性大于

73
00:05:07,080 --> 00:05:08,940
绿点总数。

74
00:05:08,970 --> 00:05:10,260
所以我们走了。

75
00:05:10,260 --> 00:05:15,850
假设他们开车去上班，则x的P是与步行者相似的观察次数。

76
00:05:15,970 --> 00:05:21,690
因此，在里面有一个类似的意思，类似于我们添加并除以的新点

77
00:05:21,690 --> 00:05:25,110
步行者总数为20。

78
00:05:25,110 --> 00:05:29,220
因此，超过20分之一就是我们的可能性。

79
00:05:29,220 --> 00:05:29,880
好了

80
00:05:29,880 --> 00:05:33,980
所以现在我们可以将它们插入公式中，计算后验概率。

81
00:05:34,020 --> 00:05:40,140
因此，在两个小时之前的21:30，它将是30的20倍以上，它是0.25。

82
00:05:40,290 --> 00:05:42,360
所以25％

83
00:05:42,390 --> 00:05:43,090
所以你去了。

84
00:05:43,090 --> 00:05:49,760
那是我们所有朴素基础算法或基础分类器的第二步。

85
00:05:49,830 --> 00:05:55,410
希望你能够摔倒很久，也希望你有机会进行这项运动

86
00:05:55,410 --> 00:06:00,210
靠自己，您得到了类似的结果，就是今天。

87
00:06:00,210 --> 00:06:01,880
期待下次见到您。

88
00:06:01,890 --> 00:06:03,720
直到那时，机器学习

