
****************************关于神经网络、机器学习等的资料收录及自己理解**********************************

-1- 训练神经网络解决现实中的问题时之间的联系
	.达到最终目的前 统计一些影响最终目的先决条件-对应神经网络的特征
	.根据实践得出的结果 作为最终确定的结果，然后网络依据一些先决条件(对应神经元)和中间隐藏层(参数或其他调整)得出的一个关于结果的一个概率值，这个值越大说明此网络作出的判断 越贴近最终确定的结果
	.神经元和隐藏层之间连接(突触)，起思考的作用，影响最终的走向和最终偏离最终确定结果的概率

-2-	.神经网络将得出 0 到 1 之间的概率，与真值 1 对比，表示准确率
	.神经网络通过概率和试错学习方法，渐进式地改进下一次预测的结果

-3- 准确率提高的步骤
    前馈：想象一下 1960 年的 IBM 计算机，大到填满整个房间，穿孔卡片从一端输入，答案从另一端输出。上文提到的神经网络以前三个调查问题的数据作为输入，得出预测结果；

    全局最小值：想象一下桌子上有一个黄色的碗（如上图所示）。桌子表面表示几乎零误差的完美预测结果，那么很显然碗底是最接近完美预测结果的位置，具备最小的误差。与碗整个表面（即「全局表面」（global surface））相比，碗底最接近完美，它具备全局最小误差值。


    反向传播：想象一位杂技表演者，他能向空中抛接 16 个不同大小和重量的保龄球瓶，并使它们同时悬在空中，甚至可以神奇地调整保龄球瓶的大小和重量。网络在执行预测后，会返回到上一次预测的过程中，查看是否可以做一些调整，以便在下一次预测中缩小误差，推动小球向碗底前进。

    梯度下降：想象粉色乒乓球沿着碗侧向碗底滚落，碗底即全局最小值（见上图）。网络就像那个球，碗的表面由网络的每一次预测构成。梯度下降就是球沿着碗侧滚落向碗底（即具备全局最小误差的预测）的过程。



    梯度下降是网络在达到准确预测（即全局最小误差）前的试错过程，就像乒乓球滚落碗底的过程；

    前馈即执行预测。预测就像给定时刻球停留在碗表面某个位置的定格图像；

    全局最小值即预测几乎没有误差的完美位置（碗底）。我们的目标是到达碗底。网络将预测结果与真值进行对比，来衡量球目前位置与碗底的距离（误差）；

    反向传播即返回到上一次预测，找出错误并修正。反向传播衡量球现在位置到其下桌面的距离（即误差），并找出推动球向碗底前进的方法。
















Hopfield 网络是理论神经科学的一个模型，为分布式、内容可寻址的内存存储和检索提供了统一的框架，也启发了 Boltzmann 机的提出以及许多满足弱约束的分布作为 AI 计算模型的想法。


