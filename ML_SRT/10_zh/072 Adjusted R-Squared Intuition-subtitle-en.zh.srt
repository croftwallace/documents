1
00:00:00,570 --> 00:00:03,560
好吧，这是有趣的部分，调整后的r平方。

2
00:00:03,840 --> 00:00:07,120
因此，这里有一个简单的内部。

3
00:00:07,290 --> 00:00:12,330
我们已经谈到了R平方是如何得出这样对我们的秘密公式是它等于

4
00:00:12,330 --> 00:00:19,170
1减去残差的平方和除以总平方和，其中残差的平方和

5
00:00:19,710 --> 00:00:28,470
是从观测值到拟合线的距离的平方和，因此我们看不到它

6
00:00:28,500 --> 00:00:35,880
这是您在回归线上的线性符号，我们适合我们的数据和

7
00:00:35,890 --> 00:00:42,600
全总和，而我们可以在这里看到它，这样就是那些红线的这些广场的总和我们

8
00:00:42,600 --> 00:00:47,640
可以在这里看到这样你的意见和平均伯斯基R平方之间的区别告诉

9
00:00:47,640 --> 00:00:50,220
我们将您的模型拟合到女儿的状况如何。

10
00:00:50,390 --> 00:00:55,620
实际上，这比她可以通过女儿画出的平均线好多少？

11
00:00:55,860 --> 00:00:57,180
非常简单地。

12
00:00:57,180 --> 00:01:02,620
因此，让我们摆脱所有这些，并把我们所有的秘密公式搁置一秒钟。

13
00:01:02,630 --> 00:01:10,170
现在，我们讨论了用于简单线性回归的R平方，而相同的概念适用于多元

14
00:01:10,170 --> 00:01:10,930
在您的回归中。

15
00:01:10,920 --> 00:01:16,590
因此，例如，我们有两个变量R平方将以相同的方式计算。

16
00:01:16,590 --> 00:01:22,920
我们只是现在不打算进行所有这些推导，因为它更容易可视化

17
00:01:22,920 --> 00:01:30,120
这是我们完成的方式，而完全相同的概念也适用于多元线性回归，

18
00:01:30,120 --> 00:01:31,570
仍然。

19
00:01:31,980 --> 00:01:36,080
因此，这意味着将使用所有普通的最小二乘法。

20
00:01:36,090 --> 00:01:43,800
最佳拟合是多元线性回归，即线性平方和最小的

21
00:01:43,940 --> 00:01:47,290
残差因此，您正在尝试最小化残差平方和。

22
00:01:47,290 --> 00:01:50,100
当我很好地提出这一点时，我们将在一秒钟内需要它。

23
00:01:50,310 --> 00:01:56,130
因此，我们要像我们讨论的那样使用R平方作为拟合参数的优度，因此它越大

24
00:01:56,130 --> 00:01:59,070
电流越接近模型越好。

25
00:01:59,140 --> 00:01:59,930
太棒了。

26
00:01:59,940 --> 00:02:06,630
我们可以完全尝试这样做，但是有一个问题，问题是当您开始

27
00:02:06,690 --> 00:02:09,780
向模型添加更多变量。

28
00:02:09,780 --> 00:02:13,410
因此，在这里您可以看到我们的多重集成中有两个变量。

29
00:02:13,560 --> 00:02:17,350
如果在模型中添加第三个变量，将会发生什么。

30
00:02:17,440 --> 00:02:22,470
我们以它为例，让我们来看一个有薪水的例子。

31
00:02:22,470 --> 00:02:30,990
因此，您的薪水等于常数30000加10000年的工作经验再加上例如

32
00:02:31,020 --> 00:02:38,460
B2可以是恒定的小时系数乘以您所拥有的资格的数量。

33
00:02:38,550 --> 00:02:46,260
而且我不知道B-3可能是您去年给公司带来了多少钱，所以

34
00:02:46,350 --> 00:02:51,600
例如，如果您是推销员，那么系数乘以您带来的美元金额

35
00:02:51,600 --> 00:02:53,910
公司在前一年是这样的。

36
00:02:53,970 --> 00:03:01,410
因此，您可以继续添加您认为实际上会影响结果的变量，从而影响结果

37
00:03:01,410 --> 00:03:07,380
因变量，您想适合模型并查看它是否更好。

38
00:03:07,380 --> 00:03:09,270
因此，在这种情况下，我们要添加第三个变量。

39
00:03:09,270 --> 00:03:11,880
我们已经有一个带有两个变量的模型，并且可以正常工作。

40
00:03:12,010 --> 00:03:17,580
现在我们要添加第三个变量，看看是否可以使用第三个变量来拟合模型

41
00:03:17,610 --> 00:03:21,250
甚至更好，因此我们可以使用三个变量创建一个更好的模型。

42
00:03:21,300 --> 00:03:22,730
那么我们如何判断呢。

43
00:03:22,740 --> 00:03:25,450
因此，我们添加了所有可忍受的对象，并运行了模型。

44
00:03:25,500 --> 00:03:28,400
我们可以看一下R平方是否使R平方变好或变差。

45
00:03:28,410 --> 00:03:34,760
因此，实际上R平方增加了还是减少了或保持不变。

46
00:03:34,770 --> 00:03:41,060
因此，这里的问题在于，由于这两个因素的扩散，R平方永远不会减小。

47
00:03:41,100 --> 00:03:43,410
让我们更详细地介绍一下。

48
00:03:43,450 --> 00:03:47,460
我将在这里使用鼠标，因为这是非常重要的部分。

49
00:03:47,460 --> 00:03:54,180
因此，此处的R平方等于1减去残差除以某个平方的平方

50
00:03:54,180 --> 00:03:55,250
总。

51
00:03:55,800 --> 00:04:00,570
因此，一旦您将新变量添加到模型中。

52
00:04:00,690 --> 00:04:06,450
正确，它将以某种方式影响模型的外观。

53
00:04:06,450 --> 00:04:15,090
而我们试图将残差平方和最小化的事实是

54
00:04:15,090 --> 00:04:21,090
这个新变量将有助于最大程度地减少残差的平方

55
00:04:21,090 --> 00:04:27,930
将会找到一种给它一个系数的方法，该系数将有助于最小化平方残差之和。

56
00:04:27,930 --> 00:04:32,920
然后，在那种情况下，R平方将发生在我们平方上。

57
00:04:33,180 --> 00:04:37,310
这将是一减去以前的值。

58
00:04:37,410 --> 00:04:38,110
对。

59
00:04:38,280 --> 00:04:44,550
除以相同的值是因为我们通过添加新变量不会影响我们正在观察的结果

60
00:04:44,550 --> 00:04:47,190
不影响观测平均值的权利。

61
00:04:47,190 --> 00:04:48,580
这不会改变。

62
00:04:48,690 --> 00:04:55,410
因此，通过添加新变量进行此条件下的回归过程，我们一定会尽量减少

63
00:04:55,470 --> 00:04:58,910
此值使其比现在更小。

64
00:04:59,190 --> 00:05:05,400
这样，整个部分将减少而整个部分将增加。

65
00:05:05,400 --> 00:05:11,190
因此，如果发生这种情况，您将增加无论新系数如何添加的新变量

66
00:05:11,220 --> 00:05:17,630
如果不能减小SS残差，则给它一个新系数。

67
00:05:17,640 --> 00:05:17,910
对。

68
00:05:17,930 --> 00:05:18,980
会发生什么。

69
00:05:18,990 --> 00:05:20,610
那么这个系数将变成零。

70
00:05:20,610 --> 00:05:26,470
我很少认为我从未见过像B这样的系数完全为零。

71
00:05:26,570 --> 00:05:28,440
我现在就告诉你为什么。

72
00:05:28,500 --> 00:05:33,390
但是在最坏的情况下，回归过程会说这个变量是您完全知道的

73
00:05:33,870 --> 00:05:38,840
只是使世界模型变得更加糟糕，所以我只用0代替这个系数。

74
00:05:39,060 --> 00:05:39,980
那就算了。

75
00:05:39,990 --> 00:05:43,720
那样的话，这个残差将不会改变，R平方也不会改变。

76
00:05:43,830 --> 00:05:49,160
因此，您只有两个选项，或者R平方会增加，或者根本不会改变。

77
00:05:49,170 --> 00:05:51,010
因此R平方永远不会减小。

78
00:05:51,150 --> 00:05:58,770
如果添加变量，为什么要说B-3永远不等于零，因为它们始终可以是

79
00:05:58,830 --> 00:06:06,840
否则在独立标签和相关标签之间始终至少存在很小的随机相关性

80
00:06:06,840 --> 00:06:07,370
变量。

81
00:06:07,450 --> 00:06:08,860
放什么都没关系。

82
00:06:08,860 --> 00:06:16,290
因此，即使在示例中，当我们查看薪水时，薪水也等于经验的年数加上多少

83
00:06:16,620 --> 00:06:19,230
我的意思是一个人拥有的资格。

84
00:06:19,380 --> 00:06:24,570
然后我们可以添加该人的手机号码定律的最后一位数字。

85
00:06:24,600 --> 00:06:24,940
对。

86
00:06:25,050 --> 00:06:27,940
当然那不会。

87
00:06:27,940 --> 00:06:33,270
它与自变量没有任何关联。

88
00:06:33,270 --> 00:06:37,160
什么样的情况没有致病因素，两者之间没有关联。

89
00:06:37,170 --> 00:06:41,480
您手机号码的丢失对您的工资没有影响。

90
00:06:41,580 --> 00:06:46,870
但是，如果我们添加了它们，它们将随机地成为一个稍微相关的对象，您知道。

91
00:06:46,890 --> 00:06:51,570
这只是一个随机相关，回归过程将把它捡起来，我会尝试一下

92
00:06:51,570 --> 00:06:58,050
效率和R平方可能会减少一点点或增加一点点

93
00:06:58,050 --> 00:06:58,340
。

94
00:06:58,410 --> 00:07:01,400
这就是为什么R平方存在问题。

95
00:07:01,530 --> 00:07:07,170
您可以添加变量，但您将不知道这些变量是否对您的模型有所帮助或

96
00:07:07,170 --> 00:07:12,540
无济于事，因为您是R平方会偏向于基本上总是在增加

97
00:07:12,630 --> 00:07:15,690
实际改进或未经证实的拟合。

98
00:07:15,840 --> 00:07:23,910
因此，我们必须提出不同的参数来衡量拟合优度，并且在此位置进行调整

99
00:07:23,940 --> 00:07:25,170
R平方进来。

100
00:07:25,170 --> 00:07:27,460
这就是R平方的前者。

101
00:07:27,480 --> 00:07:29,640
这是回归数。

102
00:07:29,850 --> 00:07:34,870
因此，自变量的数量和样本大小即为此处的大小。

103
00:07:35,430 --> 00:07:39,230
现在他们说调整后的R平方具有惩罚因子。

104
00:07:39,330 --> 00:07:45,000
如果添加对模型没有帮助的自变量，将对您不利。

105
00:07:45,000 --> 00:07:46,290
再说说吧。

106
00:07:46,290 --> 00:07:50,820
那是关于R平方的重要部分，因此p是许多endpin语言。

107
00:07:50,820 --> 00:07:55,490
让我们看一下分母底部的那一块。

108
00:07:55,590 --> 00:07:58,980
这意味着当PPI增加时，增加自变量的数量。

109
00:07:59,160 --> 00:08:01,800
这整个部分减少。

110
00:08:02,000 --> 00:08:08,070
当整个部分减少时，分母减少，比率增加，并且随着比率增加

111
00:08:08,220 --> 00:08:10,480
整个出价也会提高。

112
00:08:10,520 --> 00:08:14,920
随着整体的增加，负数将减少。

113
00:08:15,030 --> 00:08:22,140
因此，正如您所见，随着添加更多的回归变量，调整后的R平方正在减小

114
00:08:22,140 --> 00:08:23,810
远离1。

115
00:08:24,000 --> 00:08:25,730
这是重要的部分。

116
00:08:25,730 --> 00:08:33,260
您还可以在这里看到当R平方增加而正常R平方增加R平方时会发生什么

117
00:08:33,270 --> 00:08:34,180
增加。

118
00:08:34,260 --> 00:08:37,110
因此，这部分减少了。

119
00:08:37,110 --> 00:08:42,220
一个R平方可能会减少，这意味着整个部分都会增加。

120
00:08:42,360 --> 00:08:48,480
因此，通过添加一个新变量，您一方面在R平方上有一场战斗，您正在增加R平方

121
00:08:49,560 --> 00:08:52,250
因此，您正在增加一个正则的R平方。

122
00:08:52,260 --> 00:08:57,650
但是另一方面，通过增加numable可以增加P，因此您可以减少调整后的R平方。

123
00:08:57,900 --> 00:09:03,100
从这个意义上讲，这是一场公平，就像在这里是一场公平的战斗。

124
00:09:03,300 --> 00:09:10,590
如果变量不好对模型没有帮助，那么调整后的R平方将是微不足道的

125
00:09:10,590 --> 00:09:11,240
增加。

126
00:09:11,460 --> 00:09:17,530
而这种惩罚因素实际上将驱使R平方下降，调整后的R平方下降。

127
00:09:17,790 --> 00:09:23,610
另一方面，如果您添加的新变量有助于建模，那么

128
00:09:23,610 --> 00:09:30,000
R平方将是巨大的，它将压倒这一惩罚因子，因此即使您仍然会

129
00:09:30,000 --> 00:09:36,660
由于添加变量增加模型的收益而受到惩罚，即使

130
00:09:36,660 --> 00:09:39,100
恰到好处的R平方会上升。

131
00:09:39,190 --> 00:09:41,910
调整后的R平方基本上就是这样工作的。

132
00:09:41,910 --> 00:09:47,910
这是一个非常好的指标，它可以帮助您了解是否要向模型或模型中添加良好的变量

133
00:09:47,910 --> 00:09:54,690
否，我们将在整个课程中使用调整后的R平方，以确保我们的模型稳健

134
00:09:54,690 --> 00:09:55,530
当我们建造它们时

