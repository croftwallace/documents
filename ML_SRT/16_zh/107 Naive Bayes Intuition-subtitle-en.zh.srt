1
00:00:00,870 --> 00:00:03,000
您好，欢迎回到机器学习课程。

2
00:00:03,180 --> 00:00:04,740
这是基里尔·埃雷缅科（Kirill Eremenko）。

3
00:00:04,770 --> 00:00:08,570
在今天的Turrell中，我们正在谈论中堂基础分类器。

4
00:00:08,640 --> 00:00:13,740
这是一个非常有趣的机器学习算法，今天我们将在一个非常

5
00:00:13,830 --> 00:00:20,200
直观的水平并符合使复杂化变得简单的超级数据科学使命。

6
00:00:20,220 --> 00:00:26,670
我们将把这个复杂的主题分解成简单的步骤，并咬合信息的大小。

7
00:00:26,840 --> 00:00:29,000
我已经准备了一些非常令人兴奋的幻灯片。

8
00:00:29,100 --> 00:00:31,500
因此，让我们直接研究它。

9
00:00:31,500 --> 00:00:35,570
好的，所以这里有贝叶斯定理，这是我们在新闻教程中讨论的内容

10
00:00:35,580 --> 00:00:41,400
因此，到现在为止，我们应该对如何应用它来创建机器的概念非常满意

11
00:00:41,400 --> 00:00:42,450
学习算法。

12
00:00:42,690 --> 00:00:45,520
好吧，让我们看看这里，我们有一个数据集。

13
00:00:45,510 --> 00:00:47,310
因此它具有两个功能。

14
00:00:47,310 --> 00:00:48,980
它具有x1和x2。

15
00:00:49,020 --> 00:00:53,520
并且有两个类别类别1被评为类别2，该类别为绿色但不能正常工作

16
00:00:53,520 --> 00:00:58,480
使用这些抽象术语，我们将把它们转换为可以更好地理解的东西

17
00:00:58,480 --> 00:01:01,780
或更易于操作或谈论的东西。

18
00:01:01,800 --> 00:01:07,530
因此，我们将Y变量称为额外变量薪水，而x 1变量称为年龄

19
00:01:07,530 --> 00:01:07,560
。

20
00:01:07,560 --> 00:01:13,230
因此，基本上，我们是按照数据集的形式呈现观察结果或人员

21
00:01:13,290 --> 00:01:17,610
您可以看到，年龄和薪水图表上有30个人。

22
00:01:17,910 --> 00:01:20,520
候选人是我们将用步行代替它们。

23
00:01:20,550 --> 00:01:23,800
意思是人走路去上班，格林会干的。

24
00:01:23,820 --> 00:01:25,710
那意味着那个人开车去上班。

25
00:01:26,010 --> 00:01:29,750
因此，现在我们可以解决我们将要解决的机器学习挑战。

26
00:01:29,930 --> 00:01:34,370
如果将新观察值和新数据点添加到集合中会发生什么。

27
00:01:34,470 --> 00:01:37,500
我们如何对该新数据点进行分类。

28
00:01:37,500 --> 00:01:42,870
如您所见，这是一种监督式机器学习算法，因为我们正在对某些事物进行分类

29
00:01:42,870 --> 00:01:45,560
基于先前已知的Klaas。

30
00:01:45,570 --> 00:01:50,070
所以问题是，这个人会被归类为步行上班的人，还是这

31
00:01:50,070 --> 00:01:55,620
将被归类为开车去上班然后离开基础算法的人

32
00:01:55,620 --> 00:01:57,630
帮助我们解决这一挑战。

33
00:01:57,630 --> 00:01:59,580
好吧，那么我们该如何处理呢。

34
00:01:59,580 --> 00:02:02,720
我们需要一个攻击计划，这将是一个非常复杂的方法。

35
00:02:02,730 --> 00:02:06,960
但与此同时，我们将其分解为几步，它们都将非常有意义

36
00:02:06,960 --> 00:02:08,280
容易理解。

37
00:02:08,280 --> 00:02:12,880
因此，我们的攻击计划将采用贝叶斯定理，并且可以对其应用两次。

38
00:02:12,990 --> 00:02:19,740
第一次，我们将应用它来找出给定此人走路的概率

39
00:02:19,740 --> 00:02:26,970
他的特征和此处的X是该数据点的特征或呈现的特征，所以让我们开始吧

40
00:02:26,970 --> 00:02:28,760
回到这里的可视化。

41
00:02:28,770 --> 00:02:34,830
所以在这里您可以看到这是我们的新数据点，该人具有一定的年龄，所以我们说这个年龄

42
00:02:34,830 --> 00:02:37,650
这个人的年龄大概是25岁。

43
00:02:37,920 --> 00:02:41,870
然后他们有薪水，所以说他们的薪水是每年$ 3000。

44
00:02:42,120 --> 00:02:48,240
因此，这些是当前观察结果的特征，为了简化起见，我们仅使用两个变量

45
00:02:48,240 --> 00:02:53,400
为了让我们可以可视化年龄和薪水，但实际上可能还有很多很多其他功能

46
00:02:53,400 --> 00:02:59,400
这可能是他们从事多少行业或受过多少年教育的特征

47
00:02:59,400 --> 00:03:02,470
拥有或已经拥有驾驶执照的时间。

48
00:03:02,550 --> 00:03:06,890
而且我认为他们下班后的工作距离很远，因此可能会有很多变数。

49
00:03:06,900 --> 00:03:11,250
但是同时，您将要处理两个年龄和薪水，无论

50
00:03:11,250 --> 00:03:15,790
您将调用多少个变量，我们将其称为功能。

51
00:03:15,810 --> 00:03:23,970
因此，鉴于x的特征，因此假设其年龄为25岁，工资为$ 30000，我们将详细讨论

52
00:03:23,970 --> 00:03:27,220
恰好就是我们目前所说的功能。

53
00:03:27,240 --> 00:03:33,480
因此，这部分代表该人，我们正在尝试对可能性进行分类

54
00:03:33,540 --> 00:03:36,000
具有这些特征的人。

55
00:03:36,000 --> 00:03:41,390
因此，我们知道我们正在为新数据点中拥有的那些功能而忙碌。

56
00:03:41,390 --> 00:03:44,450
他们走路的可能性是多少，然后您有了正确的一面。

57
00:03:44,450 --> 00:03:48,180
因此，在计算它们时，我们将逐一讨论。

58
00:03:48,180 --> 00:03:51,080
但是现在，让我们给他们命名，从右到左。

59
00:03:51,080 --> 00:03:57,600
因此，这里的这个称为先验概率，我们将首先计算该概率，因为

60
00:03:57,600 --> 00:03:59,040
这是最容易计算的。

61
00:03:59,070 --> 00:04:05,790
下一个是边际可能性，我们将计算第二个是边际可能性

62
00:04:05,880 --> 00:04:06,140
。

63
00:04:06,270 --> 00:04:07,560
那只是他们的名字。

64
00:04:07,590 --> 00:04:09,670
我们将校准该三分之一。

65
00:04:09,780 --> 00:04:13,740
最后，我们要寻找的是所谓的后理论或我们要计算的概率

66
00:04:13,740 --> 00:04:14,790
那股力量。

67
00:04:14,790 --> 00:04:17,330
好的，这就是我们第一步的攻击计划。

68
00:04:17,370 --> 00:04:21,090
这仍然是计算有人行走的概率的第一步。

69
00:04:21,090 --> 00:04:25,090
给定我们在新数据点中看到的那些特征X。

70
00:04:25,500 --> 00:04:29,430
接下来，我们将进行第二步，我们将计算某人驾驶的可能性

71
00:04:29,520 --> 00:04:33,220
给定我们在新数据点中看到的那些特征X。

72
00:04:33,300 --> 00:04:37,770
再一次，这里将具有先计算概率然后再计算边际可能性的概率

73
00:04:37,770 --> 00:04:40,440
可能性，然后您将了解到可能性。

74
00:04:40,530 --> 00:04:44,700
最后，我们将比较某人走给定特征X和的可能性

75
00:04:44,700 --> 00:04:49,650
有人驾驶人类特征X的概率，然后从那里决定要放置哪个子句

76
00:04:49,740 --> 00:04:51,750
新数据指向。

77
00:04:51,750 --> 00:04:57,000
正如您所看到的，因为我们首先计算了的基类是分类的概率类型

78
00:04:57,000 --> 00:05:00,820
概率，然后根据概率我们将其分配为接近。

79
00:05:00,840 --> 00:05:01,110
好吧。

80
00:05:01,110 --> 00:05:08,020
因此，您准备好要形成这些步骤了吗，我们将很轻松，很有趣。

81
00:05:08,020 --> 00:05:10,580
友好而缓慢，以便我们了解所有内容。

82
00:05:10,600 --> 00:05:14,060
并在此事件发生后对海军基地的交战感到非常自在。

83
00:05:14,230 --> 00:05:14,830
第一步。

84
00:05:14,830 --> 00:05:16,610
好的，所以我们在这里进行安装。

85
00:05:16,660 --> 00:05:20,070
让我们将其向左移动一点，以便我们腾出一些空间。

86
00:05:20,080 --> 00:05:24,030
现在，我们将计算贝叶斯定理中的第一个概率。

87
00:05:24,040 --> 00:05:28,900
我们将计算某人正确行走的概率。

88
00:05:28,900 --> 00:05:29,580
这意味着什么。

89
00:05:29,590 --> 00:05:35,250
那是某人战斗的可能性，他们对他们一无所知，所以我们只是说我们在

90
00:05:35,250 --> 00:05:38,630
在这里将新的观测值添加到我们的数据集中。

91
00:05:38,770 --> 00:05:43,330
但是我们不知道他们的年龄，我们也不知道他们的薪水会将其放入我们的数据中

92
00:05:43,330 --> 00:05:44,050
组。

93
00:05:44,050 --> 00:05:48,440
我们要添加到数据库中的这个人走动工作的可能性是多少？

94
00:05:48,460 --> 00:05:51,940
从这里很简单的答案，我们没有太多选择。

95
00:05:51,940 --> 00:05:55,710
我们唯一能做的就是计算已读观测值的数量。

96
00:05:55,720 --> 00:06:00,820
实际行走的人数除以总数，以至于该人行走的人数

97
00:06:00,820 --> 00:06:06,040
与法拉德一起工作的其他知识是步行者的数量和人数或步行者

98
00:06:06,430 --> 00:06:10,660
这些是成年人除以吸收的总数绿色的点是灰色的点不参与

99
00:06:10,660 --> 00:06:12,340
在这些计算中。

100
00:06:12,340 --> 00:06:17,940
因此，如果有人走，这里我们大概是10个10个红点除以50个点。

101
00:06:17,950 --> 00:06:18,250
好吧。

102
00:06:18,250 --> 00:06:19,060
这很容易。

103
00:06:19,060 --> 00:06:23,570
接下来，我们通过计算边际可能性来计算先验概率。

104
00:06:23,680 --> 00:06:26,130
这就是事情变得有趣的地方。

105
00:06:26,140 --> 00:06:28,850
那么我们如何计算似然裕度。

106
00:06:29,350 --> 00:06:30,160
我们来看一下。

107
00:06:30,400 --> 00:06:32,180
再次是我们的数据集。

108
00:06:32,320 --> 00:06:37,990
首先，我们要选择一个半径，然后在周围画一个圆

109
00:06:38,080 --> 00:06:40,410
这样我们的观察。

110
00:06:40,420 --> 00:06:44,960
现在，您需要自行选择此半径，然后需要自己决定。

111
00:06:44,980 --> 00:06:48,490
算法，这就像输入参数或算法，您可以减少选择，因为

112
00:06:48,550 --> 00:06:50,670
像这样，这取决于您。

113
00:06:50,710 --> 00:06:52,020
现在，这个半径是做什么的。

114
00:06:52,060 --> 00:06:57,050
好吧，我们要做的是首先让我们简化事情。

115
00:06:57,050 --> 00:07:01,980
我们现在暂时删除DOT，以免混淆我们。

116
00:07:02,230 --> 00:07:07,930
然后，我们将研究本系列中的所有要点以及我们在这里所说的

117
00:07:07,930 --> 00:07:15,640
是圆内的所有点我们都认为它们在特征上相似

118
00:07:15,640 --> 00:07:17,150
到我们拥有的地步。

119
00:07:17,290 --> 00:07:18,160
我们的观点。

120
00:07:18,160 --> 00:07:22,580
请记住，它的年龄为25岁，年薪为$ 30000。

121
00:07:22,600 --> 00:07:28,720
所以现在我们要在其周围绘制一个半径，假设20至30岁之间的任何人

122
00:07:28,720 --> 00:07:33,380
年薪在$ 25000至$ 35000之间。

123
00:07:33,640 --> 00:07:39,090
再次落入该圆圈的人是不是正方形，而是正方形是一个圆圈。

124
00:07:39,340 --> 00:07:47,410
落在附近某处的任何人都将被视为与新数据相似

125
00:07:47,440 --> 00:07:49,190
指向我们要添加到我们的数据集中。

126
00:07:49,330 --> 00:07:54,550
因此，您可以想象这个半径实际上将对您的算法发挥很大的作用

127
00:07:54,570 --> 00:07:54,740
。

128
00:07:54,880 --> 00:07:58,570
好吧，我们有这个半径，这就是全部播放的方式。

129
00:07:58,570 --> 00:08:01,110
我们有三个红点和一个绿点。

130
00:08:01,360 --> 00:08:01,650
好吧。

131
00:08:01,660 --> 00:08:03,100
所以现在我们该怎么办。

132
00:08:03,100 --> 00:08:07,270
我们如何计算X的概率以及X的概率是多少。

133
00:08:07,390 --> 00:08:15,190
X的概率就是我们添加到数据集中的新点相似的概率

134
00:08:15,190 --> 00:08:19,640
在功能上达到我们实际上要添加的功能。

135
00:08:19,660 --> 00:08:24,520
因此，基本上，这是我们添加或喜欢的任意随机点的可能性

136
00:08:24,520 --> 00:08:31,930
add是任意随机点落入该圆并X的P计算为的概率

137
00:08:31,930 --> 00:08:36,190
相似观察的数量，所以我们已经可以在圆圈中看到的观察的数量

138
00:08:36,250 --> 00:08:40,500
1 2 3 4除以持续时间总数30。

139
00:08:40,660 --> 00:08:42,680
所以X的p是Bethy的前身。

140
00:08:43,030 --> 00:08:49,120
再次重申x的P，它告诉我们任何新的随机变量

141
00:08:49,120 --> 00:08:53,010
我们将这个数据集添加到圆圈内。

142
00:08:53,140 --> 00:08:56,070
它是430，因为我们只有四个。

143
00:08:56,290 --> 00:09:00,960
根据先前的知识，我们可以在这里解决此问题，而第二个问题也可以是30分的四个问题。

144
00:09:01,120 --> 00:09:03,660
好的，这一点也不难。

145
00:09:03,670 --> 00:09:05,380
我们称其为边际可能性。

146
00:09:05,380 --> 00:09:07,790
到目前为止，我们得到了这个，我们得到了这个。

147
00:09:07,860 --> 00:09:12,120
接下来，我们进入可能性，这可能是最复杂的可能性。

148
00:09:12,130 --> 00:09:19,930
我们说话后，走路的人展示X的可能性是多少？

149
00:09:19,930 --> 00:09:24,060
关于边际可能性的计算，可能性将不会那么复杂。

150
00:09:24,070 --> 00:09:25,410
让我们来看一下。

151
00:09:25,420 --> 00:09:27,100
所以有我们的图表。

152
00:09:27,250 --> 00:09:33,570
现在我们要做的是再次绘制相同的圆，然后再一次

153
00:09:33,570 --> 00:09:37,120
现在删除灰色点，我们将为圆形涂色。

154
00:09:37,330 --> 00:09:43,770
因此，落入圆内的任何东西都被视为与我们添加的点相似

155
00:09:43,790 --> 00:09:44,030
。

156
00:09:44,260 --> 00:09:51,070
所以问题是从我们的数据集中随机选择的数据点将有多大的可能性

157
00:09:51,070 --> 00:09:54,070
与我们要添加的数据点相似。

158
00:09:54,070 --> 00:10:00,670
因此，基本上，给定随机数的数据点将从该圆中出现的可能性是多少

159
00:10:00,820 --> 00:10:07,390
这个垂直的管道意味着给定那个人走路，我们知道那个人走路去工作

160
00:10:07,390 --> 00:10:11,990
对此的另一种思考方式是，我们仅与步行上班的人一起工作。

161
00:10:11,990 --> 00:10:15,690
因此，我们只使用代表步行上班的人的红点。

162
00:10:15,690 --> 00:10:17,390
因此，让我们忘记绿点。

163
00:10:17,440 --> 00:10:21,230
他们就像他们现在昏了过去，我们甚至根本不在谈论他们。

164
00:10:21,250 --> 00:10:22,830
我们只在谈论红点。

165
00:10:22,840 --> 00:10:29,590
因此，给出的问题是，我们仅使用红点进行操作，那么随机

166
00:10:29,590 --> 00:10:38,020
从我们女儿那里选出的数据点说，从红点可以看出是具有相似特征的人

167
00:10:38,260 --> 00:10:41,450
到我们加给女儿们的地步。

168
00:10:41,450 --> 00:10:48,160
因此，基本上，随机选择的红点落入该灰色区域的可能性是多少？

169
00:10:48,160 --> 00:10:49,250
圈子。

170
00:10:49,270 --> 00:10:50,840
这就是我们要问的问题。

171
00:10:50,860 --> 00:10:54,390
现在，我们已经知道所有工作原理非常简单。

172
00:10:54,490 --> 00:10:59,440
基本上是那些从事工作的人的民事或观察数，所以红点的数量

173
00:10:59,440 --> 00:11:05,110
实际上落在这个大圆圈的红色圆圈内，该圆圈是三除以

174
00:11:05,170 --> 00:11:10,600
步行者，因此步行上班的人数和总人数为10分之三。

175
00:11:10,600 --> 00:11:11,060
好了

176
00:11:11,070 --> 00:11:17,200
这就是我们P表示某人表现出与该更广泛点相似的特征的可能性

177
00:11:17,200 --> 00:11:21,760
考虑到我们只是在红点中进行选择，我们将要添加的内容。

178
00:11:21,850 --> 00:11:24,280
这就是三分之十。这就是我们的可能性。

179
00:11:24,280 --> 00:11:28,350
所以现在，如果我们将所有这些都插入，那么我们就完成了可能性。

180
00:11:28,360 --> 00:11:29,550
因此，如果您全部插入。

181
00:11:29,560 --> 00:11:31,350
我们将得到后验概率。

182
00:11:31,390 --> 00:11:36,320
因此，三乘十乘以10或30，再除以四或三。

183
00:11:36,400 --> 00:11:39,730
因此，如果我们计算出疾病给我们零分75。

184
00:11:39,730 --> 00:11:46,030
75％是我们将某人放置到放置位置的概率

185
00:11:46,060 --> 00:11:50,680
x应归为步行上班的人。

186
00:11:50,680 --> 00:11:57,020
那是第一步，非常激烈的旅程非常激动，可以计算出该值。

187
00:11:57,030 --> 00:11:59,840
现在，下一步是完成第二步。

188
00:11:59,890 --> 00:12:06,460
下一步，对具有特征X的人进行分类的可能性执行相同的操作

189
00:12:06,610 --> 00:12:09,820
或应归为开车上班的人。

190
00:12:10,180 --> 00:12:17,710
在这里给您一个挑战，我将挑战您发布此视频或倒带以查找答案

191
00:12:17,710 --> 00:12:17,830
。

192
00:12:17,890 --> 00:12:23,770
要让图像摆在您面前，并自己进行这些计算，以实际进行相同的操作

193
00:12:23,770 --> 00:12:25,870
步骤并执行这些计算。

194
00:12:25,870 --> 00:12:32,920
如果您想查看并与我的计算结果进行比较，那么在此之后，我将放另一个视频

195
00:12:32,920 --> 00:12:37,420
一个本课程之后的另一个教程，您可以转到下一个教程并进行比较

196
00:12:37,440 --> 00:12:37,960
。

197
00:12:38,090 --> 00:12:40,200
否则，我现在将向您显示结果。

198
00:12:40,420 --> 00:12:47,630
因此，结果是24种可能性之一，或者这是正确的概率，即20或30裕度电

199
00:12:47,770 --> 00:12:49,490
保持不变。

200
00:12:49,540 --> 00:12:51,980
可能性变为20分之一。

201
00:12:52,000 --> 00:12:58,330
因此，具有特征X的某人开车上班的概率为25％

202
00:12:58,330 --> 00:12:58,810
。

203
00:12:58,870 --> 00:13:00,290
这就是第二步。

204
00:13:00,400 --> 00:13:01,630
现在，我们将执行第三步。

205
00:13:01,660 --> 00:13:08,470
我们将比较具有特征X巴西人的某人成为某人的概率

206
00:13:08,470 --> 00:13:13,010
步行上班与X出现某人特征的可能性驱动。

207
00:13:13,240 --> 00:13:19,420
所以是75％对25％，因此第一个很棒，第二个很棒

208
00:13:19,420 --> 00:13:26,620
具有特征X的人比走路的人更有可能成为走路上班的人

209
00:13:26,620 --> 00:13:27,280
谁开车去上班。

210
00:13:27,280 --> 00:13:31,500
因此仍然有25％的机会是一个开车去工作的人。

211
00:13:31,540 --> 00:13:37,540
是一个会走路的人或出现灰白色的概率为75％，因此我们将对其进行分类

212
00:13:37,810 --> 00:13:41,420
这是一个步行上班的人。

213
00:13:41,500 --> 00:13:42,100
好了

214
00:13:42,100 --> 00:13:47,760
这就是他们如何在机器学习中留下基础算法的方法。

215
00:13:47,770 --> 00:13:49,980
我希望这个Tauriel有用。

216
00:13:49,990 --> 00:13:56,860
我为这些Sly感到非常兴奋和自豪，希望这是一个循序渐进且简单的步骤

217
00:13:56,860 --> 00:13:59,230
一个复杂概念的解释。

218
00:13:59,290 --> 00:14:00,970
我期待着下次见到你。

219
00:14:00,970 --> 00:14:02,720
在此之前，请享受您的机器学习

