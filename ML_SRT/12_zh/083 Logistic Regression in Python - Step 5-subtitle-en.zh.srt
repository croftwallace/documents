1
00:00:00,240 --> 00:00:02,860
您好，欢迎来到本Python教程。

2
00:00:02,940 --> 00:00:03,780
就是这样。

3
00:00:03,780 --> 00:00:09,480
我们建立了模型，将逻辑回归模型拟合到训练集中，然后我们进行了预测

4
00:00:09,480 --> 00:00:10,890
测试结果。

5
00:00:10,950 --> 00:00:17,010
我们使用计算矩阵来评估逻辑回归模型的预测能力。

6
00:00:17,160 --> 00:00:18,730
实际上还不错。

7
00:00:18,810 --> 00:00:23,010
我们发现65加24等于89的正确预测。

8
00:00:23,280 --> 00:00:25,210
而4月3日等于11。

9
00:00:25,290 --> 00:00:26,520
错误的预测。

10
00:00:26,850 --> 00:00:31,180
但这并不是可视化预测能力的有趣方式。

11
00:00:31,440 --> 00:00:35,960
有趣的是，更令人兴奋的是，在图形上查看结果。

12
00:00:36,090 --> 00:00:40,860
这就是我们在本教程中要做的，我们将制作一个图表，在其中清晰可见

13
00:00:40,860 --> 00:00:46,620
我们的逻辑回归模型预测的区域是，用户将要购买产品，并且

14
00:00:46,620 --> 00:00:49,370
没有用户不会购买该产品。

15
00:00:49,380 --> 00:00:51,100
因此，让我们制作这张图。

16
00:00:51,220 --> 00:00:56,740
因此，不幸的是，我们不能仅以一行或两行来制作该图。

17
00:00:56,760 --> 00:01:03,120
我尝试使其尽可能简单，但最终我得到了超过10行

18
00:01:03,120 --> 00:01:04,040
代码。

19
00:01:04,080 --> 00:01:08,310
因此，我现在不打算编写整个代码，因为您可能会睡着

20
00:01:08,310 --> 00:01:09,650
。

21
00:01:09,690 --> 00:01:15,240
所以我要做的是采用我准备用来可视化Trenin发送结果的代码

22
00:01:15,510 --> 00:01:16,860
在我的文本编辑器中。

23
00:01:16,950 --> 00:01:19,270
我要复制并粘贴到这里。

24
00:01:19,440 --> 00:01:22,170
然后，我将选择此代码并执行它。

25
00:01:22,170 --> 00:01:27,570
我们将看一下我们的结果来解释它们，然后为那些对我们如何做出这样的结果感兴趣的人

26
00:01:27,570 --> 00:01:31,740
本教程结尾处的图形，我将解释其如何制作图形。

27
00:01:31,910 --> 00:01:32,200
好。

28
00:01:32,220 --> 00:01:34,590
所以我复制并粘贴。

29
00:01:34,590 --> 00:01:35,780
现在在这里。

30
00:01:35,780 --> 00:01:36,960
这是代码。

31
00:01:36,960 --> 00:01:40,410
如您所见，这就是15行代码。

32
00:01:40,430 --> 00:01:47,430
因此，由于迫不及待想向您展示结果，我们现在选择代码，

33
00:01:47,430 --> 00:01:53,220
按Commander控件并执行Enter，我们将看到逻辑回归背后的全部内容

34
00:01:53,220 --> 00:01:54,000
模型。

35
00:01:54,040 --> 00:01:58,210
我们将看到真实的结果和预测范围。

36
00:01:58,260 --> 00:02:00,870
因此，让我们开始执行或控制我们。

37
00:02:00,900 --> 00:02:02,870
现在我们开始。

38
00:02:02,880 --> 00:02:04,440
那是图。

39
00:02:04,440 --> 00:02:10,680
因此，我将扩大它，现在我将解释要集成的内容。

40
00:02:11,160 --> 00:02:15,060
好的，让我们逐步分析该图。

41
00:02:15,100 --> 00:02:20,910
首先让我们专注于所有要点，我们可以看到我们有一些红点和一些绿点

42
00:02:20,910 --> 00:02:21,510
。

43
00:02:21,510 --> 00:02:28,140
因此，我们在此图中看到的所有这些点都是我们的训练集的观察点，即

44
00:02:28,440 --> 00:02:35,340
这些都是社交网络的所有用户，都被选择去培训站点，每个

45
00:02:35,340 --> 00:02:42,750
这些用户的特点是x轴上的年龄，此处是估算工资

46
00:02:42,750 --> 00:02:44,140
y轴。

47
00:02:44,160 --> 00:02:52,270
现在我们可以看到这里有一些红色的点，这里有一些绿色的点是

48
00:02:52,290 --> 00:02:59,610
购买因变量等于零和绿点的列车观测值

49
00:02:59,700 --> 00:03:05,880
是因变量pre-Chase等于1的训练集观测值。

50
00:03:05,970 --> 00:03:13,110
这意味着此处的红点是未购买SUV的用户，此处的绿点是

51
00:03:13,110 --> 00:03:16,220
实际购买SUV的购买者。

52
00:03:16,230 --> 00:03:23,130
现在，作为分析的第一步，我们来解释一下我们在此用户身上观察到的内容

53
00:03:23,140 --> 00:03:23,400
。

54
00:03:23,640 --> 00:03:23,880
好。

55
00:03:23,880 --> 00:03:30,180
因此，首先我们可以看到用户很年轻，估计薪水很低。

56
00:03:30,180 --> 00:03:36,180
所以这些用户实际上并没有购买SUV，因为这些是真正的观察点

57
00:03:36,180 --> 00:03:36,300
。

58
00:03:36,390 --> 00:03:39,130
他们在此处读取并读取对零的响应。

59
00:03:39,180 --> 00:03:42,880
因此，这意味着此处所有这些点都是昨天未购买的用户。

60
00:03:42,960 --> 00:03:51,390
然后，如果我们查看的是那些年龄较大且估算工资较高的用户，

61
00:03:51,600 --> 00:03:56,460
我们可以看到，这些用户中的大多数实际上是购买了SUV，这实际上是有道理的，因为

62
00:03:56,730 --> 00:04:01,500
他们的SUV更像是家用车，因此对于这些年长的用户来说更有趣。

63
00:04:01,500 --> 00:04:08,160
在这里，除了较高的估计薪水，我们还可以看到有些老年人即使估计的薪水也很低

64
00:04:08,160 --> 00:04:10,710
工资实际上买了SUV。

65
00:04:11,040 --> 00:04:17,040
我们可以看到这里有一些绿点，对应于高于平均年龄的年龄

66
00:04:17,040 --> 00:04:18,000
平均在这里。

67
00:04:18,480 --> 00:04:22,120
但是估计薪水低于平均水平，因为这里有平均水平。

68
00:04:22,590 --> 00:04:23,280
好。

69
00:04:23,520 --> 00:04:28,170
因此，这些人这些年纪较大的人，尽管他们对购买SUV的薪水估计较低，

70
00:04:28,500 --> 00:04:32,580
可能是因为他们已经存了一些钱，或者也许他们已经还清了抵押贷款

71
00:04:32,580 --> 00:04:32,820
。

72
00:04:32,850 --> 00:04:39,800
我不知道可以肯定的是，他们无法抗拒购买这款非常酷的豪华SUV，

73
00:04:39,810 --> 00:04:41,710
低得离谱的价格。

74
00:04:42,570 --> 00:04:48,780
另一方面，我们也可以看到有些年轻人的薪水很高

75
00:04:49,050 --> 00:04:51,370
谁真正买了SUV。

76
00:04:51,540 --> 00:04:55,800
您可能知道这是因为这是一款非常酷的SUV，他们想打动自己的朋友，并带他们进入

77
00:04:55,800 --> 00:04:58,350
公路旅行，或者他们已经有家人了。

78
00:04:58,410 --> 00:04:58,730
我不知道。

79
00:04:59,510 --> 00:05:01,900
无论如何，他们买了SUV。

80
00:05:01,970 --> 00:05:06,680
实际上，有很多购买者，因此这一定是一款非常酷且便宜的SUV。

81
00:05:06,970 --> 00:05:07,360
好。

82
00:05:07,370 --> 00:05:10,570
现在分类的目标是什么。

83
00:05:10,640 --> 00:05:15,110
现在我们在谈论机器学习，为什么要进行一些分类。

84
00:05:15,320 --> 00:05:20,810
而分类器将做什么，至少我们将努力使它们为该特定业务做

85
00:05:20,810 --> 00:05:21,580
问题。

86
00:05:21,890 --> 00:05:27,320
好吧，这里的目标是将合适的用户分类为合适的类别。

87
00:05:27,500 --> 00:05:34,340
也就是说，我们正在尝试创建一个分类器，将正确的用户吸引到正确的类别中，从而

88
00:05:34,340 --> 00:05:41,060
是的，他们购买了SUV，没有，他们不购买SUV，我们代表了分类器捕捉的方式

89
00:05:41,060 --> 00:05:45,370
通过绘制所谓的预测区域来吸引用户。

90
00:05:45,410 --> 00:05:49,820
因此，预测区域是我们在该图中看到的两个区域。

91
00:05:49,970 --> 00:05:56,750
这个红色的这里和这个绿色的这里和红色的预测区域是我们的分类器所在的区域

92
00:05:56,780 --> 00:06:02,690
捕获所有昨天不咬人的用户，绿色预测区域是

93
00:06:02,690 --> 00:06:06,040
它会捕获所有购买SUV的用户。

94
00:06:06,170 --> 00:06:07,250
不过要小心。

95
00:06:07,310 --> 00:06:13,190
根据针对该红色预测区域的每个用户的分类器。

96
00:06:13,200 --> 00:06:20,300
这是我们的逻辑回归分类器，可以预测用户不会购买SUV，对于每种

97
00:06:20,300 --> 00:06:27,230
这个绿色预测区域的用户在这里是分类器，它将预测SUV的使用，甚至

98
00:06:27,230 --> 00:06:28,550
如果不是现实生活中的情况。

99
00:06:28,550 --> 00:06:33,800
那只是一个预测，但这就是我们可以分类的信念会发生的事情。

100
00:06:33,800 --> 00:06:39,970
重点是将预测与此处的真相进行比较。

101
00:06:39,980 --> 00:06:41,340
重点是事实。

102
00:06:41,480 --> 00:06:43,610
原因是预测。

103
00:06:43,880 --> 00:06:50,990
这是一个了不起的工具，因为对于社交网络的每个新用户，我们的分类器a

104
00:06:50,990 --> 00:06:56,500
Logistic回归食商将根据其年龄和估计薪水出售。

105
00:06:56,660 --> 00:07:02,930
如果此用户属于此红色预测区域，因此不购买SUV，或者

106
00:07:02,930 --> 00:07:09,020
用户属于此处的绿色预测区域，因此购买了SUV，因此该业务

107
00:07:09,020 --> 00:07:15,540
汽车公司可以通过定位社交网络来大幅优化其营销活动

108
00:07:15,560 --> 00:07:21,530
增加了绿色区域的用户，因为这些是预计将购买SUV的用户

109
00:07:21,830 --> 00:07:24,200
根据我们的分类器。

110
00:07:24,440 --> 00:07:30,830
现在要了解的另一个非常重要的事情是，这是两个分开的预测区域

111
00:07:31,040 --> 00:07:37,160
一条直线，即此处的直线，该直线称为预测边界

112
00:07:37,670 --> 00:07:41,090
因为它是两个预测​​区域之间的边界

113
00:07:41,360 --> 00:07:44,940
而且它的直线不是随机的。

114
00:07:45,080 --> 00:07:50,930
这是出于特定原因，这就是理解的重要性，因为这就是意义

115
00:07:50,930 --> 00:07:55,390
如果预测边界在此处是一条直线，则为逻辑回归。

116
00:07:55,550 --> 00:07:59,260
那是因为我们的逻辑回归分类器是线性的。

117
00:07:59,260 --> 00:08:00,750
我们的分类器。

118
00:08:01,010 --> 00:08:05,180
这意味着在这里，因为我们处于二维，所以您知道，因为我们有两个自变量

119
00:08:05,180 --> 00:08:08,130
我们在两个维度上的年龄和估计薪资。

120
00:08:08,330 --> 00:08:14,450
然后，由于逻辑回归分类器是线性分类器，因此预测边界分隔符

121
00:08:14,450 --> 00:08:17,500
这里只能是一条直线。

122
00:08:17,660 --> 00:08:23,870
如果我们在三个维度上，那么它将是一个将两个空间分隔开的直行星，但是在这里

123
00:08:23,870 --> 00:08:29,110
二维它是一条直线，如果您的分类器是线性的，它将始终是一条直线

124
00:08:29,120 --> 00:08:36,140
分类器，但是稍后我们将在构建非线性分​​类器时预测边界

125
00:08:36,140 --> 00:08:39,060
分隔符将不再是直线。

126
00:08:39,230 --> 00:08:42,670
我现在不会告诉您更多信息，我会让您等待惊喜。

127
00:08:43,010 --> 00:08:49,580
因此，在这里我们可以清楚地看到，我们的逻辑回归分类器可以捕获大多数用户

128
00:08:49,880 --> 00:08:52,510
没有在红色区域购买SUV的人

129
00:08:52,760 --> 00:08:56,960
和大多数在绿色区域购买SUV的用户一样。

130
00:08:57,050 --> 00:08:59,200
因此，它实际上做得很好。

131
00:08:59,330 --> 00:09:06,290
但是，似乎很难抓住一些绿色用户，尽管他们的薪水很低

132
00:09:06,410 --> 00:09:13,280
豪华SUV以及这里也购买了豪华SUV的其他绿色用户，因为

133
00:09:13,280 --> 00:09:20,050
可以在这里看到这些绿点，而这些在绿色区域，这是我们的分类器

134
00:09:20,060 --> 00:09:27,320
预测用户不会购买SUV，而那些错误的预测是犹太人专门针对

135
00:09:27,320 --> 00:09:34,770
我将其归类为线性分类器，这是因为我们的用户不是线性分布的。

136
00:09:34,770 --> 00:09:40,310
如果它们呈线性分布，那么我们将在此空间中拥有所有绿点以及所有

137
00:09:40,310 --> 00:09:44,960
在此空间中的红色点，然后具有直线的线性分类器可以完美地

138
00:09:45,080 --> 00:09:47,890
将所有红色点和所有绿色点分开。

139
00:09:48,310 --> 00:09:54,210
但是在这里，我们有一些叛逆的父母，他们不在线性区域，因为她的分类

140
00:09:54,210 --> 00:09:56,690
具有线性或直线分隔符。

141
00:09:56,730 --> 00:10:02,490
这就是为什么它很难抓住这里的那些用户，而您即使在这里也可以清楚地看到

142
00:10:02,490 --> 00:10:05,460
您尝试在此处旋转此直线。

143
00:10:05,670 --> 00:10:09,630
好吧，您总是会在错误的类别中出现一些绿色问题。

144
00:10:09,620 --> 00:10:14,080
例如，如果我们尝试像放下一样以这种方式旋转此处。

145
00:10:14,310 --> 00:10:18,400
好吧，我们将在这里捕捉这些绿点以及在这里正确的绿色区域。

146
00:10:18,540 --> 00:10:26,420
但是，由于我们调低了旋转速度，我们将在这里吸引更多绿色用户，因为这会增加并且更加绿色

147
00:10:26,430 --> 00:10:29,060
用户将位于红色区域。

148
00:10:29,100 --> 00:10:35,540
因此，这是最好的分隔符，逻辑回归测试很好，并且做得更好，因为

149
00:10:35,820 --> 00:10:41,480
它只能是分隔这两个区域的直线，因为要抓住这些用户，就是绿色用户

150
00:10:41,490 --> 00:10:45,800
在这里，果岭在这里是正确的类别，这是我们需要的绿色区域分类

151
00:10:45,810 --> 00:10:52,620
要在此处绘制某种曲线，以使您知道正确分类此处和此处的那些绿色用户，以及

152
00:10:52,620 --> 00:10:53,990
将它们放在绿色区域。

153
00:10:54,060 --> 00:10:59,480
这将阻止我们班级在这里做出这种错误的预测，因为这是直截了当的

154
00:10:59,490 --> 00:11:05,370
在这里用曲线画一条线，我们将捕获所有可能位于红色区域的红色用户和所有绿色的红色用户

155
00:11:05,370 --> 00:11:07,010
绿色区域的用户。

156
00:11:07,010 --> 00:11:12,690
这样就构成了一个很棒的分类器，您将看到我们的非线性分类器将如何构成一个

157
00:11:12,690 --> 00:11:14,330
做到这一点很棒。

158
00:11:14,340 --> 00:11:16,020
我等不及要向您展示。

159
00:11:16,500 --> 00:11:16,920
好。

160
00:11:16,920 --> 00:11:22,650
现在，最终要理解的最后一件事是火车。

161
00:11:22,800 --> 00:11:28,730
这是一个培训中心，这意味着我们的分类人员学习了如何根据这些信息进行分类

162
00:11:28,740 --> 00:11:29,300
这里。

163
00:11:29,340 --> 00:11:34,480
所以我会屏住呼吸几秒钟，直到我发现我们的逻辑回归分类器

164
00:11:34,500 --> 00:11:37,900
可以对新观察结果做出良好的预测。

165
00:11:38,040 --> 00:11:43,800
那就是将新用户分类为正确的区域，这些区域在这里是固定区域，因为

166
00:11:44,120 --> 00:11:49,500
这些是我们的逻辑回归分类器的学习经验所产生的区域，

167
00:11:49,500 --> 00:11:56,070
因此，如果我们查看一些新的观察结果（即新的社交网络用户）

168
00:11:56,070 --> 00:11:58,620
我们将在测试中找到什么。

169
00:11:58,620 --> 00:12:00,230
等一下

170
00:12:01,200 --> 00:12:08,070
所以我现在要做的是复制此内容，因为我们不想这样做，因为我们想提高效率

171
00:12:09,410 --> 00:12:17,740
并将其粘贴到此处，现在我将通过测试替换此处的培训。

172
00:12:17,750 --> 00:12:18,650
好吧。

173
00:12:18,960 --> 00:12:28,770
在这里，我只需要用X测试替换X火车，为什么要训练我最重的东西就可以了

174
00:12:28,770 --> 00:12:29,100
去做。

175
00:12:29,100 --> 00:12:34,040
哦，也许是标题，我将更改图形测试的标题。

176
00:12:34,460 --> 00:12:34,800
好。

177
00:12:34,800 --> 00:12:41,700
现在让我们看看我们的逻辑回归分类器如何预测测试集上的新观测值

178
00:12:41,850 --> 00:12:44,270
没有建立我们的模型。

179
00:12:44,340 --> 00:12:47,440
因此执行命令或控制百分比。

180
00:12:47,630 --> 00:12:50,280
让我们看看。

181
00:12:50,280 --> 00:12:51,280
好吧。

182
00:12:51,300 --> 00:12:51,900
不错。

183
00:12:51,890 --> 00:12:55,040
不是说我要扩大这个范围。

184
00:12:55,050 --> 00:12:56,060
开始了。

185
00:12:56,070 --> 00:12:57,930
因此，这看起来不错。

186
00:12:57,930 --> 00:12:59,500
这看起来很好。

187
00:12:59,520 --> 00:13:04,590
这些是真实的结果，红色表示实际上没有购买SUV的用户，这些

188
00:13:04,590 --> 00:13:10,440
我购买了其他客户，我们可以看到预测区域很好地预测了这些实际价值

189
00:13:10,440 --> 00:13:13,760
因为所有这些红色点都在这里和红色区域。

190
00:13:13,800 --> 00:13:15,580
这就是正确的预测。

191
00:13:15,600 --> 00:13:17,940
所有这些绿色点都在绿色区域中。

192
00:13:17,940 --> 00:13:19,770
这就是其他一些正确的预测。

193
00:13:19,860 --> 00:13:25,380
当然，由于这是线性分类器，因此逻辑回归在这里会犯一些错误，但是

194
00:13:25,380 --> 00:13:26,050
那也行。

195
00:13:26,190 --> 00:13:30,620
这实际上是我们在混淆矩阵上看到的错误预测。

196
00:13:30,620 --> 00:13:33,240
请记住，有11个错误的预测。

197
00:13:33,240 --> 00:13:34,530
我们可以在这里数。

198
00:13:34,710 --> 00:13:36,140
这个绿点应该在这里。

199
00:13:36,140 --> 00:13:46,050
所以是一二三四五五六七八，然后我们要在绿色

200
00:13:46,050 --> 00:13:46,380
区域。

201
00:13:46,380 --> 00:13:48,320
我被正确预测了。

202
00:13:48,500 --> 00:13:52,080
所以9 10和11。

203
00:13:52,130 --> 00:13:52,460
好。

204
00:13:52,470 --> 00:13:58,500
是的，那是我们在混淆矩阵中发现的11个不正确的预测。

205
00:13:58,500 --> 00:14:02,820
好的，这是我们建立的第一个分类模型。

206
00:14:02,850 --> 00:14:04,560
希望您喜欢该图。

207
00:14:05,400 --> 00:14:11,550
好的，恭喜您，您在Python和后续教程上实现了第一个分类模型

208
00:14:11,550 --> 00:14:12,880
我们将在我们上做到这一点。

209
00:14:12,890 --> 00:14:18,220
现在，对于那些有兴趣了解图形制作方式的人。

210
00:14:18,240 --> 00:14:21,450
和我在一起，我将立即解释它的工作原理。

211
00:14:21,810 --> 00:14:22,160
好。

212
00:14:22,160 --> 00:14:30,990
因此，最好的解释方法是研究这样的东西来控制我们并尝试执行，

213
00:14:31,000 --> 00:14:32,220
图。

214
00:14:32,230 --> 00:14:33,250
那是什么主意。

215
00:14:33,250 --> 00:14:37,150
我们如何绘制这些预测区域。

216
00:14:37,540 --> 00:14:45,180
好吧，这个想法实际上很酷，因为我们在这里拍摄了该帧的所有像素。

217
00:14:45,190 --> 00:14:50,400
这意味着这个大镜头看到了这么大，因此所有像素实际上都具有0.01的分辨率。

218
00:14:50,590 --> 00:14:56,350
因此，我们采用了该框架的所有像素点，并在其上应用了分类器。

219
00:14:56,350 --> 00:15:01,940
因此，您知道每个像素点都是社交网络的用户，其薪水和

220
00:15:01,940 --> 00:15:02,840
年龄。

221
00:15:02,880 --> 00:15:05,350
因此，这就像只是一个观察。

222
00:15:05,500 --> 00:15:07,670
这不是我们数据集中的观察结果。

223
00:15:07,780 --> 00:15:13,260
这是我们创建的新观察结果，我们必须将其描绘成用户和社交网络，

224
00:15:13,250 --> 00:15:15,420
估计对不起年龄。

225
00:15:15,430 --> 00:15:23,080
因此，对于这些新像素点中的每一个，我们应用逻辑回归

226
00:15:23,080 --> 00:15:31,050
模型来预测此像素观察点的值为0还是1，因此可以将您分类为漂亮

227
00:15:31,070 --> 00:15:35,520
为0，则将这个像素点着色为红色。

228
00:15:35,680 --> 00:15:40,800
如果分类器预测一个分类器，它将以绿色将像素点着色。

229
00:15:41,130 --> 00:15:49,450
因此，通过在此帧中的所有像素点上执行此操作，可以将所有像素点称为

230
00:15:49,450 --> 00:15:55,770
零预测这里有零运算，所有具有一个预测的像素点

231
00:15:55,780 --> 00:15:56,600
。

232
00:15:56,710 --> 00:16:03,640
而且由于逻辑回归是分类器，因此这两组点之间的界限是直的

233
00:16:03,630 --> 00:16:04,130
线。

234
00:16:04,210 --> 00:16:10,020
因为如前所述，逻辑回归是线性分类器，这意味着它是直线

235
00:16:10,030 --> 00:16:11,790
二维线。

236
00:16:12,070 --> 00:16:16,360
现在您已经了解了此代码。

237
00:16:17,750 --> 00:16:20,590
好的，现在让我们逐行讨论。

238
00:16:20,680 --> 00:16:26,750
我们首先导入listicle数学类，该类将帮助我们为所有数据点着色。

239
00:16:27,000 --> 00:16:32,650
然后我们创建旨在仅创建一些局部变量X set的设计，以便我们可以替换X train和

240
00:16:32,640 --> 00:16:38,110
为什么通过X测试和Y测试轻松进行培训，而不必在任何地方都进行替换，因为您知道我们

241
00:16:38,290 --> 00:16:39,920
用X说几次。

242
00:16:40,090 --> 00:16:44,940
因此，您知道这只是避免必须更换太多次的捷径。

243
00:16:44,940 --> 00:16:47,000
X测试和X训练在这里。

244
00:16:47,380 --> 00:16:48,000
好。

245
00:16:48,190 --> 00:16:54,340
在这里，使用这两行代码X1，接下来的两个等于P，即医疗补助，我们为您准备了网格

246
00:16:54,340 --> 00:16:58,060
知道我刚才谈到的所有像素点。

247
00:16:58,240 --> 00:17:05,290
因此，在这里您可以看到我们将年龄值的最小值减去1，因为我们不希望

248
00:17:05,290 --> 00:17:08,050
此处要挤压的点。

249
00:17:08,130 --> 00:17:13,860
您知道该年龄的最大值，以获得我们要包含在帧中的像素范围

250
00:17:14,700 --> 00:17:22,090
对于薪水，我们将最低薪水减去一，将最高薪水加一

251
00:17:22,090 --> 00:17:27,230
得到所有的估计薪资范围，然后减去一加一，这样就可以扣分。

252
00:17:27,370 --> 00:17:29,110
在这里，我们正在选择步骤。

253
00:17:29,260 --> 00:17:33,270
点零1表示存在0.2或一种分辨率。

254
00:17:33,280 --> 00:17:40,020
因此，举例来说，如果我选择了0.5，就不会那么密集，我们实际上会看到像素

255
00:17:40,050 --> 00:17:44,080
点，但最好采用这种分辨率，因为它们是不错的预测区域。

256
00:17:44,110 --> 00:17:46,300
就像是连续的。

257
00:17:46,750 --> 00:17:47,410
好的。

258
00:17:47,560 --> 00:17:51,540
然后，通过这行代码，整个魔术就会发生。

259
00:17:51,550 --> 00:17:57,020
因为这是我们在所有像素观察点上应用分类器的地方。

260
00:17:57,180 --> 00:18:01,900
这样，它会升高所有红色像素点和所有绿色像素点。

261
00:18:02,080 --> 00:18:08,140
然后，我们使用此轮廓函数在两个预测区域之间实际绘制轮廓。

262
00:18:08,130 --> 00:18:13,740
您可以在此处看到的红色和绿色之一用来预测分类器的功能

263
00:18:13,750 --> 00:18:19,980
逻辑回归分类器，以预测每个像素点属于0类还是0类

264
00:18:19,990 --> 00:18:20,560
1。

265
00:18:20,700 --> 00:18:25,840
然后，它描述了一个属于0类的点，它将用红色着色，如果大支撑属于

266
00:18:25,840 --> 00:18:28,510
到第1类时，它将以绿色着色。

267
00:18:28,840 --> 00:18:33,750
好的，所以在这里我们绘制X年龄的限制以及估算薪资的原因。

268
00:18:33,900 --> 00:18:38,550
然后，在此循环中，我们绘制所有数据点，这些数据点均为实数值。

269
00:18:38,700 --> 00:18:41,790
因此，这里所有红色数据点和绿色数据点。

270
00:18:41,830 --> 00:18:47,550
因此，我们正在使用此Piazzi点散点图，这是我们用于matplotlib制作散点图和

271
00:18:47,560 --> 00:18:53,860
然后非常简单地在这里我们添加标题逻辑回归训练设置表年龄White他们

272
00:18:53,950 --> 00:18:55,320
估计工资。

273
00:18:55,510 --> 00:18:59,110
我们绘制图例以指定红点对应于零。

274
00:18:59,110 --> 00:19:06,030
有一个使用没有购买的绿点对应的是用户，但该产品的

275
00:19:06,070 --> 00:19:10,670
show以显示图形并指定这是图形的结尾。

276
00:19:10,680 --> 00:19:13,210
好的，如果您还在这里，则表示祝贺。

277
00:19:13,200 --> 00:19:18,680
祝贺您有好奇心，我们想知道如何建立这样的情节。

278
00:19:18,760 --> 00:19:22,930
因此，在本节中有很多事情要学习，因为您学习了如何进行逻辑回归

279
00:19:22,920 --> 00:19:25,440
模型以及如何制作出色的图表。

280
00:19:25,470 --> 00:19:27,270
恭喜你

281
00:19:27,280 --> 00:19:32,820
在最后完成相同的操作后，下一节将变得更加令人兴奋，因为

282
00:19:32,910 --> 00:19:36,010
我们将建立更强大的分类器。

283
00:19:36,040 --> 00:19:37,900
因此，我希望向您展示这一点。

284
00:19:38,020 --> 00:19:39,850
在那之前享受机器学习

