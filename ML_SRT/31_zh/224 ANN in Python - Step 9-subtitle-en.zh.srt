1
00:00:00,420 --> 00:00:02,850
您好，欢迎来到本Python教程。

2
00:00:02,850 --> 00:00:05,220
好吧，现在有，然后进行编译。

3
00:00:05,220 --> 00:00:09,690
现在是时候进行激动人心的步骤了，该步骤是将和装入训练集中。

4
00:00:09,840 --> 00:00:15,990
因为您可能已经注意到，到目前为止，我们只是建立了末端，而未与

5
00:00:15,990 --> 00:00:20,730
训练集，所以当然现在我们需要建立这种联系，并且要建立这种联系，

6
00:00:20,730 --> 00:00:26,010
将使用适合我们年龄并适合训练的拟合方法。

7
00:00:26,010 --> 00:00:27,280
好吧，让我们开始吧。

8
00:00:27,300 --> 00:00:33,500
我们将像平常一样使用对象分类器而不是点，因为我们将使用fit方法。

9
00:00:33,690 --> 00:00:36,090
然后我们当然采用第五种方法。

10
00:00:36,090 --> 00:00:36,920
开始了。

11
00:00:37,140 --> 00:00:40,190
那是论点的一个括号。

12
00:00:40,350 --> 00:00:44,010
因此，对于我们在本课程中构建的所有其他模型。

13
00:00:44,160 --> 00:00:49,050
好吧，第一个参数是我们要在其上训练分类器的数据集。

14
00:00:49,050 --> 00:00:50,580
那是我们的训练集。

15
00:00:50,640 --> 00:00:55,320
就像在分类部分中一样，该训练集被分解为参数。

16
00:00:55,320 --> 00:01:00,320
第一个X火车，是包含火车集合观测值的特征矩阵。

17
00:01:00,480 --> 00:01:05,280
然后为什么训练包含所有观察结果的因变量的实际结果

18
00:01:05,340 --> 00:01:06,600
在我们的火车上。

19
00:01:06,600 --> 00:01:08,880
好吧，让我们首先输入这两个参数。

20
00:01:08,910 --> 00:01:13,520
如此极端，然后为什么训练。

21
00:01:13,890 --> 00:01:17,330
到目前为止，它与分类部分完全一样。

22
00:01:17,340 --> 00:01:23,150
当我们过去使用fit方法时，现在情况将变得很新，因为我们将添加两个附加参数。

23
00:01:23,280 --> 00:01:28,380
如果我们在这张幻灯片中回到Quaestor great，您可能会猜到这两个参数在哪里

24
00:01:28,440 --> 00:01:28,920
是。

25
00:01:29,160 --> 00:01:34,440
如您在第6步和第7步中看到的那样，可以得到一个很好的未监听算法。

26
00:01:34,440 --> 00:01:39,900
可以选择在每次观察到空中之后更新权重，然后或

27
00:01:39,900 --> 00:01:41,780
一批意见。

28
00:01:41,790 --> 00:01:48,180
因此，您可能会猜到，第一个附加参数将是批处理大小和批处理大小

29
00:01:48,300 --> 00:01:52,670
是要更新权重的观测值数量。

30
00:01:52,700 --> 00:01:53,110
好吧。

31
00:01:53,130 --> 00:01:56,240
现在将是第二个附加参数。

32
00:01:56,400 --> 00:02:02,130
要找到它，我们需要看一下第7步，因为在第7步中需要一本书的概念，

33
00:02:02,140 --> 00:02:07,550
书中的内容基本上是整个训练集通过CNN时的情况。

34
00:02:07,710 --> 00:02:14,350
实际上，BNN训练包括在多个时期应用步骤1到6。

35
00:02:14,490 --> 00:02:20,390
因此，我们要在这里加上的第二个论点将是Epoque的数量。

36
00:02:20,400 --> 00:02:22,180
好吧，实际上我们可以检查一下。

37
00:02:22,200 --> 00:02:26,640
我将在这里向他施压，以获取此健身功能的一些信息。

38
00:02:26,700 --> 00:02:28,020
如您所见。

39
00:02:28,180 --> 00:02:32,550
首先，我们正确输入前两个参数，即特征矩阵和从属矩阵

40
00:02:32,550 --> 00:02:39,170
变量向量，然后我们具有这两个附加参数：批处理大小和Epoque的数量。

41
00:02:39,180 --> 00:02:41,600
所以在这里我们可以看到32和10。

42
00:02:41,610 --> 00:02:43,710
这些不是我们要选择的数字。

43
00:02:43,710 --> 00:02:48,750
再次在这里，您正在深入学习艺术家的灵魂，因为再次没有规则

44
00:02:48,750 --> 00:02:49,370
拇指

45
00:02:49,410 --> 00:02:55,300
我们需要进行实验以找到一些适合此批次大小和此时期数的最佳选择。

46
00:02:55,320 --> 00:02:57,540
因此，现在我们将不进行实验。

47
00:02:57,540 --> 00:03:03,180
我们将对批次大小和时期数进行一些固定的选择，并且我们将选择批次大小

48
00:03:03,180 --> 00:03:06,430
10个，纪元100个。

49
00:03:06,660 --> 00:03:11,940
这样我们就可以看到算法的实际应用，并且可以看到准确度逐轮提高

50
00:03:12,140 --> 00:03:14,220
那是在不同的时代。

51
00:03:14,220 --> 00:03:17,970
好吧，让我们做吧，我们添加另外两个参数。

52
00:03:18,150 --> 00:03:21,400
首先是批量大小。

53
00:03:21,660 --> 00:03:29,630
所以我们说我们要10，然后Puck的B等于100。

54
00:03:29,700 --> 00:03:30,420
完善。

55
00:03:30,420 --> 00:03:35,970
所以现在是时候进行表演了，我们将从实际的意义上看到这一点，我们将

56
00:03:35,970 --> 00:03:39,320
了解在不同回合中精度如何提高。

57
00:03:39,360 --> 00:03:42,120
因此，我们不再等待，让我们开始表演。

58
00:03:42,150 --> 00:03:45,530
我将选择此行并执行。

59
00:03:45,530 --> 00:03:50,180
现在，该动作发生了，我们可以看到不同的时期正在发生。

60
00:03:50,370 --> 00:03:58,480
因此，在第二本书中，我们从79％的准确性开始，然后是82％的准确性。

61
00:03:58,490 --> 00:04:03,680
好吧，它进展很快，我们几乎达到了纪元总数的25％。

62
00:04:03,740 --> 00:04:05,750
那么我们达到了什么精度。

63
00:04:05,960 --> 00:04:14,210
好了，我们可以看到，在第24次Epoche之后，我们达到了准确的开放度84 86几乎85％

64
00:04:17,750 --> 00:04:18,240
好。

65
00:04:18,250 --> 00:04:22,870
准确度达到100分的37号书达到了85％。

66
00:04:25,140 --> 00:04:31,540
我们还可以看到有关最后一个功能的信息。

67
00:04:31,550 --> 00:04:31,970
好吧。

68
00:04:31,970 --> 00:04:37,460
我们刚刚通过了Half-Way，在这里我们可以看到第54批广告的准确性为85％

69
00:04:42,520 --> 00:04:46,960
我认为我们将转换为86％的准确性。

70
00:04:47,260 --> 00:04:48,610
那会很好。

71
00:04:48,760 --> 00:04:50,090
70号

72
00:04:50,110 --> 00:04:50,580
开始了。

73
00:04:50,590 --> 00:04:54,640
肯定是百分之八十六百分之二十七。

74
00:04:54,640 --> 00:04:56,210
它正在收敛。

75
00:04:56,220 --> 00:04:59,170
对于第81批，仍为6％。

76
00:04:59,170 --> 00:04:59,640
好吧。

77
00:04:59,650 --> 00:05:01,050
我们即将结束。

78
00:05:02,390 --> 00:05:06,750
时代数90 90占100的比例仍然是86％

79
00:05:10,600 --> 00:05:13,990
最终我们的模型已经准备就绪。

80
00:05:14,020 --> 00:05:16,550
我认为我们不准确。

81
00:05:16,660 --> 00:05:18,880
86％是肯定的。

82
00:05:18,880 --> 00:05:21,660
在这里我们可以看到百分之八十六的百分之五十。

83
00:05:21,700 --> 00:05:22,860
那是预期的。

84
00:05:22,960 --> 00:05:28,840
这就是这种训练集的随机率和算法执行得如何的好方法。

85
00:05:28,840 --> 00:05:29,470
非常令人兴奋。

86
00:05:29,470 --> 00:05:34,330
实际上这是我们第一次看到这样的东西，因为到目前为止我们所有的模型都执行它

87
00:05:34,330 --> 00:05:36,970
一秒钟甚至不到一秒钟

88
00:05:36,970 --> 00:05:42,790
所以在这里我很高兴向您介绍这种新型的机器学习模型

89
00:05:42,790 --> 00:05:43,560
网络。

90
00:05:43,870 --> 00:05:45,410
太好了，希望您喜欢它。

91
00:05:45,520 --> 00:05:50,350
现在是时候进行最后一步了，即预测测试结果。

92
00:05:50,470 --> 00:05:53,800
好了，我们已经知道我们对准确性的期望。

93
00:05:53,860 --> 00:05:56,310
我们预计准确度约为86％。

94
00:05:56,350 --> 00:05:58,140
因此，我们将对其进行检查。

95
00:05:58,180 --> 00:06:02,540
实际上这将非常容易，因为您知道一切都已经准备就绪。

96
00:06:02,530 --> 00:06:07,870
感谢我们的分类模板，因此我们无需在此行中进行任何更改即可获取

97
00:06:07,870 --> 00:06:13,440
测试客户说离开银行的预测概率与计算时的概率相同

98
00:06:13,440 --> 00:06:14,280
矩阵在这里。

99
00:06:14,290 --> 00:06:16,750
一切都已经做好了准备。

100
00:06:16,750 --> 00:06:19,840
因此，我们将在下一个也是最后一个教程中完成最后两个步骤。

101
00:06:19,900 --> 00:06:21,640
直到那时在德国学习。

