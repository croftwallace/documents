1
00:00:00,870 --> 00:00:04,770
您好，欢迎回到我们今天要讨论的教程中的机器学习课程

2
00:00:04,770 --> 00:00:07,610
K最近邻算法。

3
00:00:07,620 --> 00:00:09,430
好的，让我们开始吧。

4
00:00:09,960 --> 00:00:16,390
因此，假设我们有一个场景，在我们的数据集中已经存在两个类别

5
00:00:16,390 --> 00:00:22,950
因此，我们确定了两个类别，一个类别是左侧的运营商一，这是红色卡，第二个是绿色

6
00:00:22,950 --> 00:00:23,700
在右边。

7
00:00:23,700 --> 00:00:29,580
为了简单起见，我们将只考虑两个变量或两个列

8
00:00:29,580 --> 00:00:34,830
我们的数据集，因此所有分组工作都是基于这两列x1和x2进行的。

9
00:00:34,870 --> 00:00:38,130
现在，我们将新数据点添加到数据集中。

10
00:00:38,130 --> 00:00:42,930
问题是它应该属于红色类别还是应该属于绿色类别。

11
00:00:42,930 --> 00:00:44,340
我们如何决定。

12
00:00:44,340 --> 00:00:48,850
因此，我们如何将该新数据点归类为火灾簇。

13
00:00:48,900 --> 00:00:54,300
作为红色数据点或绿色数据点，这就是最近的邻居算法将要出现的地方

14
00:00:54,300 --> 00:00:55,300
帮助我们。

15
00:00:55,530 --> 00:01:01,400
在执行此算法的最后，我们将能够确定它是红点还是绿点

16
00:01:01,410 --> 00:01:04,050
在这种情况下，该点变成红色。

17
00:01:04,260 --> 00:01:07,870
那么K最近邻算法是如何工作的。

18
00:01:07,890 --> 00:01:08,840
它是如何做到的。

19
00:01:09,000 --> 00:01:16,290
好吧，我们将逐步建立针对K的规则指南，然后在建立K之后

20
00:01:16,290 --> 00:01:19,250
实际手动执行以查看其工作原理。

21
00:01:19,290 --> 00:01:21,840
如您所见，这是一个非常非常简单的算法。

22
00:01:21,840 --> 00:01:27,260
好吧，所以第一步是选择算法中将要拥有的邻居数k

23
00:01:27,260 --> 00:01:33,500
因此您必须确定K是否等于1 2 2 3 5或其他数字。

24
00:01:33,660 --> 00:01:40,980
k的最常见默认值之一是5，而Eckstine取k的K个最近邻居

25
00:01:40,980 --> 00:01:43,980
根据新数据点的欧几里得距离。

26
00:01:43,980 --> 00:01:49,500
现在在这里，如果您不必使用欧几里得距离，则可以使用其他距离，例如曼哈顿

27
00:01:49,500 --> 00:01:53,550
距离或您可能正在考虑的任何其他距离。

28
00:01:53,730 --> 00:01:57,750
但是在大多数情况下，欧几里德距离是，所以我们要坚持这些距离。

29
00:01:57,750 --> 00:02:03,480
因此，一旦您选择了这K个邻居中最近的邻居，就需要计算数据数量

30
00:02:03,510 --> 00:02:04,650
每个类别中的得分。

31
00:02:04,650 --> 00:02:10,080
那么有多少个数据点属于另一种运营商的一类，依此类推，如果您甚至拥有

32
00:02:10,080 --> 00:02:12,160
您的数据集中有两个以上的类别。

33
00:02:12,180 --> 00:02:17,130
因此，您只需要计算每个类别中有多少个，然后需要分配新数据即可

34
00:02:17,130 --> 00:02:20,080
指向您计数最多的邻居的类别。

35
00:02:20,280 --> 00:02:21,210
就如此容易。

36
00:02:21,210 --> 00:02:23,340
这就是为什么它被称为Kinnear的邻居。

37
00:02:23,490 --> 00:02:28,200
然后您的模型已经准备就绪，因为这是一个非常简单的算法和道德准则，它将可以

38
00:02:28,200 --> 00:02:31,320
立即进行人工锻炼，以真正巩固这一知识。

39
00:02:31,320 --> 00:02:33,210
因此，让我们继续前进。

40
00:02:33,600 --> 00:02:38,890
因此，在这里，我们已经像之前看到的那样将新的数据点添加到了散点图中。

41
00:02:38,970 --> 00:02:43,710
我们如何找到这个新数据点的最近邻居。

42
00:02:44,010 --> 00:02:49,560
好吧，让我们看一下我们将要使用的欧几里德距离，

43
00:02:49,560 --> 00:02:55,500
我们在几何中定义的一种非常基本的距离类型，它是我们在几何中使用的一种类型。

44
00:02:55,500 --> 00:03:01,260
基本上，如果您在此处有两个点一两个，则两点之间的距离

45
00:03:01,500 --> 00:03:03,630
根据该公式测量。

46
00:03:03,630 --> 00:03:10,650
所以x 2减去X x坐标之间的差，然后平方加之间的差

47
00:03:10,650 --> 00:03:15,790
y坐标平方，然后从所有平方根中取平方根。

48
00:03:16,080 --> 00:03:22,650
基本上，如果您这样看，它是一个适合您的直角三角形。

49
00:03:22,670 --> 00:03:27,810
大教堂，您在其他剧院中放平方，它正在增长，需要您添加它们

50
00:03:27,810 --> 00:03:32,610
向上，您正在扎根，这给了您高毒者的时间。

51
00:03:32,610 --> 00:03:33,610
所以我们走了。

52
00:03:33,630 --> 00:03:35,880
欧几里得距离就是这样工作的。

53
00:03:35,910 --> 00:03:40,550
同样，您可以使用任何类型的距离，但这是几何距离，这就是我们要做的

54
00:03:40,550 --> 00:03:41,410
要坚持下去。

55
00:03:41,460 --> 00:03:47,010
因此，基本上在散点图上，二维类型的多边形只需画线并查看

56
00:03:47,010 --> 00:03:48,280
靠近。

57
00:03:48,300 --> 00:03:53,040
因此，在您的数据点上，如何确定其他五个最近的邻居。

58
00:03:53,160 --> 00:03:58,740
所以基本上我们只看它们，我们在这里看到距离，所以我们可以看到那是最近的

59
00:03:59,120 --> 00:04:04,920
那可能是第二个最接近的ONE-THIRD最接近的第四个最接近的第五个最接近的所以我们概述一下

60
00:04:04,920 --> 00:04:05,520
。

61
00:04:05,520 --> 00:04:05,840
好了

62
00:04:05,840 --> 00:04:11,790
因此，现在我们要做的就是在这些科卡因邻居中的第三步计算数据点的数量

63
00:04:11,790 --> 00:04:17,240
当每个类别中有3个邻居时，每个类别中的类别都在红色的类别1中

64
00:04:17,250 --> 00:04:17,460
。

65
00:04:17,640 --> 00:04:23,190
因此，第4步将新数据点分配给您计数最多邻居的类别

66
00:04:23,190 --> 00:04:23,670
。

67
00:04:23,670 --> 00:04:27,960
这意味着我们需要像这样简单地将其分配给读取类别。

68
00:04:27,960 --> 00:04:28,590
好了

69
00:04:28,590 --> 00:04:33,150
现在我们已经对这一新点进行了分类，您的模型已经准备就绪。

70
00:04:33,180 --> 00:04:33,690
好了

71
00:04:33,680 --> 00:04:36,190
这是一个非常简单的算法。

72
00:04:36,210 --> 00:04:40,980
您可以考虑的最简单的方法之一，因此以简单的方法开始本节非常好

73
00:04:40,980 --> 00:04:41,920
这样的例子。

74
00:04:42,000 --> 00:04:48,340
而且我们还将看一些实际练习，Hudlin我们将向您展示

75
00:04:48,390 --> 00:04:48,890
蟒蛇。

76
00:04:49,050 --> 00:04:50,240
XM的雄辩歌手。

77
00:04:50,250 --> 00:04:52,350
直到那时在德国机器学习

