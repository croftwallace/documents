1
00:00:00,420 --> 00:00:06,720
您好，欢迎收看本艺术教程，我们已经进入了回归的最后一轮

2
00:00:06,720 --> 00:00:08,970
对随机Forest回归建模。

3
00:00:09,300 --> 00:00:12,660
在上一节中，我们看到了决策树回归模型。

4
00:00:12,700 --> 00:00:17,460
因此，现在决策树回归对您没有任何秘密，那么您将完全理解

5
00:00:17,520 --> 00:00:23,610
进行M-4s回归，因为随机森林只是一组决策树，每个决策树

6
00:00:23,610 --> 00:00:29,760
您的因变量的预测和随机数本身的最终预测很简单

7
00:00:29,760 --> 00:00:33,730
森林中所有不同树木的不同预测的平均值。

8
00:00:33,840 --> 00:00:36,870
实际上在上一节有关决策树的末尾。

9
00:00:36,870 --> 00:00:38,220
我问你一个谜。

10
00:00:38,250 --> 00:00:40,800
谜团知道我们得到的结果。

11
00:00:40,800 --> 00:00:48,240
如果只有一棵树，那么从可视化角度来看，如果有十棵树或100棵树或500棵树，结果将是

12
00:00:48,420 --> 00:00:49,960
和临时的预测。

13
00:00:50,190 --> 00:00:56,460
所以我希望在看完Karylle制造的玩具的直觉之后，您实际上会问自己这个问题

14
00:00:56,760 --> 00:01:01,060
并尝试通过随机第一回归来预测此处将发生的情况。

15
00:01:01,230 --> 00:01:02,750
因此，让我们了解一下。

16
00:01:02,760 --> 00:01:06,740
我们将建立一个随机的第一回归模型，看看会发生什么。

17
00:01:06,870 --> 00:01:08,040
因此，让我们开始吧。

18
00:01:08,040 --> 00:01:11,520
我们将从选择合适的父亲作为工作目录开始。

19
00:01:11,550 --> 00:01:14,100
所以这是第二部分的回归。

20
00:01:14,100 --> 00:01:16,340
这是我们正在建立的最终回归模型。

21
00:01:16,400 --> 00:01:17,590
他们进行回归。

22
00:01:17,730 --> 00:01:22,810
因此，让我们进入内部，这就是我们要使用位置服务将其设置为工作目录的步枪

23
00:01:22,920 --> 00:01:23,550
文件。

24
00:01:23,730 --> 00:01:28,270
因此，让我们单击该更多按钮并将其设置为工作目录。

25
00:01:28,290 --> 00:01:29,060
都好。

26
00:01:29,200 --> 00:01:33,250
现在，让我们使用回归模板来有效地构建此模型。

27
00:01:33,330 --> 00:01:39,420
因此，我们实际上将把所有内容从这里带到底部，但我们只会包含此代码

28
00:01:39,420 --> 00:01:44,580
部分以可视化回归模型结果，因为您了解了决策树回归

29
00:01:44,580 --> 00:01:50,310
模型是非连续回归模型，并且由于随机森林是决策树的组合

30
00:01:50,640 --> 00:01:55,320
那么它是非连续回归模型的组合，从直觉上我们可以理解。

31
00:01:55,320 --> 00:01:59,990
我们可以猜测，回归的Ranum也不会是连续的。

32
00:02:00,240 --> 00:02:06,060
因此，由于此代码不适用于非连续回归模型，因此我们将实际使用

33
00:02:06,060 --> 00:02:07,840
完美的工作。

34
00:02:07,840 --> 00:02:15,360
因此，我将在此处复制此粘贴并删除不适用于非连续的这一部分

35
00:02:15,420 --> 00:02:16,650
回归模型。

36
00:02:16,650 --> 00:02:17,400
开始了。

37
00:02:17,510 --> 00:02:19,830
现在，模板已准备就绪。

38
00:02:19,890 --> 00:02:21,420
让我们改变基础。

39
00:02:21,420 --> 00:02:28,380
让我们在这里全部用随机森林回归替换回归。

40
00:02:28,380 --> 00:02:35,500
可视化美国回归结果的运行并将随机森林回归拟合到我们的数据集。

41
00:02:35,610 --> 00:02:36,390
好，很好。

42
00:02:36,510 --> 00:02:40,080
现在，让我们构建此部分中的模型。

43
00:02:40,080 --> 00:02:42,990
因此，让我们删除它。

44
00:02:42,990 --> 00:02:50,340
和往常一样，我们将导入适合该工作的库，然后使用一个函数来构建我们的库

45
00:02:50,430 --> 00:02:51,980
随机森林回归器。

46
00:02:52,320 --> 00:02:55,940
因此，您要导入的包称为Ranum forest。

47
00:02:56,190 --> 00:03:00,810
因此，对于那些没有在此处安装软件包的用户。

48
00:03:00,990 --> 00:03:02,520
好吧，你可以检查出来。

49
00:03:02,520 --> 00:03:08,040
我已经安装了Mine，因为我以前使用过它，但是我将在此处编写此行。

50
00:03:08,040 --> 00:03:18,150
对于需要安装它的人，请安装圆括号括号并在随机引号中

51
00:03:18,180 --> 00:03:21,840
无大写字母R，但无大写字母F o r t。

52
00:03:21,870 --> 00:03:22,380
好吧。

53
00:03:22,390 --> 00:03:23,330
拉纳姆森林。

54
00:03:23,500 --> 00:03:27,460
所以我不会安装它，因为我的需求在风格上，所以我要写下评论。

55
00:03:27,570 --> 00:03:32,130
但是，如果要安装它，则只需像我一样选择此行，然后按命令控制

56
00:03:32,130 --> 00:03:33,650
按Enter执行。

57
00:03:33,810 --> 00:03:35,980
这将正确安装该软件包。

58
00:03:36,150 --> 00:03:39,750
但是在这里，我将按Command + shift Blassie进行注释。

59
00:03:39,750 --> 00:03:40,650
开始了。

60
00:03:40,790 --> 00:03:48,330
现在，我们要做的就是添加此内容，您知道图书馆随机森林实际上可以自动选择

61
00:03:48,330 --> 00:03:53,460
当我们执行整个代码或执行以下操作时，此处的框将自动导入以运行他的程序包

62
00:03:53,460 --> 00:03:54,190
部分。

63
00:03:54,510 --> 00:03:59,530
因此，这很重要，现在是构建攻击者的时候了，让我们开始吧。

64
00:03:59,580 --> 00:04:04,810
我们将像往常一样称呼侵略者回归者，以使事情简单而平等。

65
00:04:04,960 --> 00:04:11,290
现在，我们将要使用的功能也与编写的随机森林相同。

66
00:04:11,470 --> 00:04:17,450
因此，现在让我们添加一些括号，然后再按一下以查看参数。

67
00:04:17,820 --> 00:04:23,790
参数在此处，第一个参数是数据，但是如您所见，它指定它是可选的

68
00:04:23,790 --> 00:04:30,360
数据框，我们可以使用此参数构建回归变量，但我们将使用主要参数

69
00:04:30,360 --> 00:04:35,420
在一侧指定自变量，在另一侧指定因变量。

70
00:04:35,580 --> 00:04:39,600
为此，我们将使用这两个参数x和y。

71
00:04:39,720 --> 00:04:46,260
因此，X将包含作为独立变量的特征矩阵，而y将包含因变量

72
00:04:46,260 --> 00:04:47,280
可变向量。

73
00:04:47,400 --> 00:04:49,530
那是对不起的专栏。

74
00:04:49,650 --> 00:04:55,770
因此，我们首先将这两个参数输入到第一个参数是X等于，所以我们有几种方法

75
00:04:55,770 --> 00:04:58,050
采取我们的自变量。

76
00:04:58,140 --> 00:05:05,790
因此，一种方法是在此处获取我们的数据集，然后选择编写自变量的列

77
00:05:06,150 --> 00:05:11,590
并且您知道我们的数据集由两列组成，第一列由一个独立的索引

78
00:05:11,620 --> 00:05:17,380
变量列，第二列索引为2，这是我们的因变量列。

79
00:05:17,400 --> 00:05:23,790
所以在这里我们需要索引1，因为我们现在想在下一个参数

80
00:05:23,790 --> 00:05:26,730
下一个参数是为什么因变量矢量。

81
00:05:26,820 --> 00:05:31,260
现在，您可以看到为什么期望将其作为响应向量。

82
00:05:31,260 --> 00:05:34,920
它实际上是一个向量，在这里它期望有一个数据帧。

83
00:05:35,130 --> 00:05:41,670
因此，通过在此处使用该索引和两个括号，我实际上从此处导入数据以获取向量

84
00:05:41,680 --> 00:05:41,730
。

85
00:05:41,760 --> 00:05:46,830
我实际上需要使用另一个技巧，另一个技巧是使用美元符号，然后

86
00:05:46,830 --> 00:05:50,160
该列的名称当然是薪水。

87
00:05:50,700 --> 00:05:51,960
那会给我一个向量。

88
00:05:51,960 --> 00:05:59,640
因此，仅在这里重述此语法将为我提供一个数据帧，因为我们正在获取一些子数据帧

89
00:05:59,670 --> 00:06:06,110
来自数据集的原始数据，这里通过使用美元符号语法获取数据，Doris说

90
00:06:06,120 --> 00:06:06,930
不好意思

91
00:06:06,960 --> 00:06:11,640
我实际上是在获取数据集的薪水列，但这将使它成为一个向量，并且

92
00:06:11,640 --> 00:06:15,750
正是我们运行的原因，因为此处的Y参数期望一个向量。

93
00:06:16,020 --> 00:06:16,990
所以我们都很好。

94
00:06:16,990 --> 00:06:20,530
现在我们实际上需要输入第三个参数。

95
00:06:20,580 --> 00:06:21,920
你能猜得出那是什么吗？

96
00:06:21,930 --> 00:06:26,670
对于你们所有人中的Python教程嗯，您将猜测它将会是什么。

97
00:06:26,850 --> 00:06:30,510
实际上，这将是输入森林中树木的数量。

98
00:06:30,510 --> 00:06:35,370
当然，我们正在他们周围建立森林，所以如果我们选择森林的话，实际上会更好

99
00:06:35,370 --> 00:06:40,560
我们在森林中建树的数量，考虑到我们要走的事实，甚至更好

100
00:06:40,560 --> 00:06:45,720
玩不同数量的树木，那就是从10棵树木开始

101
00:06:45,720 --> 00:06:52,320
10棵树，然后您就会知道我们会尝试10棵以上的树，例如100棵树或300棵树或

102
00:06:52,350 --> 00:06:53,440
500棵树。

103
00:06:53,670 --> 00:06:59,580
这就是我们要输入的第三个参数条目，我们将从10棵树开始

104
00:06:59,580 --> 00:06:59,910
。

105
00:06:59,910 --> 00:07:05,220
好的，让我们从这开始，这就是我们需要围绕森林构建的所有参数。

106
00:07:05,250 --> 00:07:07,000
我们只需要自变量。

107
00:07:07,080 --> 00:07:13,410
因变量和树的数量已经为我们回归提供了强大的Ranum

108
00:07:13,410 --> 00:07:19,010
模型，然后通过在森林中添加更多树来使其更加健壮。

109
00:07:19,020 --> 00:07:24,660
但是在继续之前，让我们将Ranum因子设置为固定值，以便我们都得到相同的结果

110
00:07:24,660 --> 00:07:24,910
。

111
00:07:24,960 --> 00:07:28,250
因此，您知道在Python中我们使用了一个等于0的随机设置参数。

112
00:07:28,350 --> 00:07:34,100
在这里，我们可以通过或使用设置点种子函数来执行相同操作。

113
00:07:34,320 --> 00:07:39,750
然后在这个函数中，我们实际上放了一个种子，并且您知道我们可以在Bison中使用我们想要的任何东西

114
00:07:39,750 --> 00:07:47,550
通常取零42，我们喜欢做的是知道1 2 3还是1 2 3 4。

115
00:07:47,550 --> 00:07:49,850
因此，让我们使用种子来获得相同的结果。

116
00:07:50,070 --> 00:07:54,660
如果您同时进行编码，那么这会使本教程更容易理解。

117
00:07:54,690 --> 00:07:59,090
因此，现在我们都很擅长于整体代码。

118
00:07:59,100 --> 00:08:01,020
我们没有什么可替代的。

119
00:08:01,110 --> 00:08:07,260
现在唯一要做的就是知道您为我们尝试了几棵树木的几种Rudham

120
00:08:07,650 --> 00:08:13,660
并查看可视化结果并查看预测，以了解我们是否正在接近

121
00:08:13,680 --> 00:08:19,150
假设我们即将雇用的新员工的年薪为16万。

122
00:08:19,620 --> 00:08:20,750
因此，让我们开始吧。

123
00:08:20,760 --> 00:08:23,280
让我们一一执行这些部分。

124
00:08:23,280 --> 00:08:26,390
因此，让我们首先导入数据集。

125
00:08:26,400 --> 00:08:27,090
开始了。

126
00:08:27,090 --> 00:08:32,850
大卫说，很重要，我们要确保我们有两列独立变量级别和

127
00:08:32,850 --> 00:08:34,440
因变量工资。

128
00:08:34,470 --> 00:08:35,610
完善。

129
00:08:35,760 --> 00:08:39,090
现在，无需在测试集中将数据集分成20组。

130
00:08:39,120 --> 00:08:45,560
无需应用特征缩放，现在无需创建我们的第一个随机森林。

131
00:08:45,570 --> 00:08:52,330
因此，让我们执行此操作，在这里执行此代码部分，对我们来说这是随机的。

132
00:08:52,350 --> 00:08:54,260
精心打造的完美。

133
00:08:54,300 --> 00:08:55,990
所以现在是时候玩得开心了。

134
00:08:56,010 --> 00:08:59,920
您想先可视化结果还是获得预测。

135
00:09:00,150 --> 00:09:05,220
好吧，首先让我们可视化结果，因为我们要确保我们拥有正确的模型并

136
00:09:05,220 --> 00:09:08,610
我们想验证它，因为我们将尝试几种树。

137
00:09:08,700 --> 00:09:10,200
在这里，我们从几个世纪开始。

138
00:09:10,200 --> 00:09:12,600
因此，我们想看看它是否看起来像是正确的模型。

139
00:09:12,690 --> 00:09:15,110
因此，我将执行此部分。

140
00:09:15,180 --> 00:09:18,430
到这里，让我们看看会得到什么。

141
00:09:19,290 --> 00:09:21,080
好的，所以这首先看起来不错。

142
00:09:21,090 --> 00:09:23,810
我们似乎在这里没有任何问题。

143
00:09:23,820 --> 00:09:28,340
实际上，我们可以快速改善的唯一一件事就是您了解这些直线。

144
00:09:28,500 --> 00:09:32,330
应该是垂直的，以便对此有更好的表示。

145
00:09:32,430 --> 00:09:37,430
我们只需要像对决策树回归那样增加分辨率即可。

146
00:09:37,440 --> 00:09:45,760
因此，让我们添加一个就足够了，让我们重新执行此操作，现在几乎可以做得更好

147
00:09:45,760 --> 00:09:50,520
看起来有些垂直的直线比不连续的更好。

148
00:09:50,770 --> 00:09:51,780
所以现在我们能说什么。

149
00:09:51,790 --> 00:09:55,980
让我们放大此图以更好地看一下。

150
00:09:55,990 --> 00:09:57,240
现在就是Interbrand。

151
00:09:57,570 --> 00:09:58,030
好。

152
00:09:58,090 --> 00:10:02,830
因此，我在上一节中问过的谜题的答案是，我又在问你

153
00:10:02,840 --> 00:10:10,330
在本教程中，我们只是通过拥有多个决策树来简单地走上台阶

154
00:10:10,330 --> 00:10:12,150
一棵决策树。

155
00:10:12,340 --> 00:10:18,370
我们的阶梯比一棵决策树要多得多，因此我们拥有

156
00:10:18,580 --> 00:10:23,890
整个级别范围的更多分割，因此不同级别的更多间隔

157
00:10:23,890 --> 00:10:31,000
水平，因此此处的每条水平直线均被这些垂直线或一个间距

158
00:10:31,090 --> 00:10:36,340
一口气，而且我们在楼梯上走得更多，这实际上是很直观的，因为您

159
00:10:36,340 --> 00:10:42,370
知道我们是否例如在6.5级得到了这个预测那么这个预测发生了什么

160
00:10:42,370 --> 00:10:49,520
是我们有10棵树投票给6.5级职位的薪水。

161
00:10:49,750 --> 00:10:54,880
然后Ranum对我们来说是6.5薪水的所有不同预测的平均值

162
00:10:54,880 --> 00:10:57,520
森林中所有不同树木的水平。

163
00:10:57,610 --> 00:11:03,430
例如，如果我们处于第四位，则10票对应10票

164
00:11:03,430 --> 00:11:09,280
对这十棵树中的每一棵树的薪水水平进行一次预测，然后将其运行

165
00:11:09,280 --> 00:11:14,710
我们取了这10个预测的平均值，这个平均值无非是

166
00:11:14,710 --> 00:11:18,540
随机森林本身的工资水平。

167
00:11:18,700 --> 00:11:24,580
因此，我们获得了更多的步骤，因为仅将整个级别范围划分为更多的间隔，并且

168
00:11:24,820 --> 00:11:29,770
是因为随机森林正在计算其决策树预测的许多不同平均值

169
00:11:29,800 --> 00:11:31,480
在每个这些间隔中。

170
00:11:31,720 --> 00:11:34,050
因此发生的事情非常直观。

171
00:11:34,060 --> 00:11:39,580
但是，有一点需要指出的是，如果我们在随机数中添加更多树

172
00:11:39,580 --> 00:11:46,210
森林好吧，这并不意味着我们会在楼梯上走很多步，因为您添加的树越多

173
00:11:46,570 --> 00:11:51,850
树木做出的不同预测的平均值收敛到相同平均值的程度越高

174
00:11:51,850 --> 00:11:52,030
。

175
00:11:52,090 --> 00:11:56,060
您知道这是基于相同的技术熵和信息增益。

176
00:11:56,110 --> 00:12:01,660
因此，您添加树的数量越多，这些投票的平均值就会收敛到相同的最终平均值

177
00:12:02,260 --> 00:12:06,280
因此它将在此处收敛到某种形状的楼梯。

178
00:12:06,280 --> 00:12:08,630
因此，这对于可视化也很重要。

179
00:12:08,650 --> 00:12:13,290
现在，由于我们有一天可以直观地了解美国回归的运行情况。

180
00:12:13,540 --> 00:12:15,510
让我们看看预测会发生什么。

181
00:12:15,640 --> 00:12:18,160
因此，让我们看看我们得到了什么预测。

182
00:12:18,160 --> 00:12:21,940
请记住，失业者表示很遗憾是160 k。

183
00:12:22,180 --> 00:12:25,930
现在，让我们看看由10棵树组成的对我们来说是什么。

184
00:12:25,930 --> 00:12:31,720
因此，让我们看一看，上面写着一个沙利人是一百一十四万美元

185
00:12:31,730 --> 00:12:31,820
。

186
00:12:31,900 --> 00:12:38,360
这实际上是一个非常危险的预测，因为我们远低于160 K Sellery

187
00:12:38,360 --> 00:12:40,400
条目设置为以前的公司中的条目。

188
00:12:40,510 --> 00:12:45,850
因此，如果我们相信这个预测，我们实际上会认为该员工的虚张声势，但不用担心，我们会

189
00:12:45,850 --> 00:12:46,770
不止于此。

190
00:12:46,780 --> 00:12:50,860
现在，我们将首先尝试运行10棵以上的树木。

191
00:12:50,920 --> 00:12:54,130
因此，让我们选择100棵树，然后看看会得到什么。

192
00:12:54,130 --> 00:12:57,680
因此，我将重建模型。

193
00:12:57,730 --> 00:12:58,500
开始了。

194
00:12:58,630 --> 00:13:01,720
现在让我们看一下图形结果。

195
00:13:02,080 --> 00:13:08,740
正如我告诉您的那样，在该图中我们没有获得更多的步骤，也没有为我们回归提供新的随机数。

196
00:13:08,980 --> 00:13:14,140
您知道我们将树的数量乘以10，但是步数绝对不是

197
00:13:14,140 --> 00:13:14,980
乘以10。

198
00:13:15,020 --> 00:13:17,480
我们进行比较，我们可以非常快速地进行比较。

199
00:13:17,500 --> 00:13:20,360
这是前一个图，这是一个新图。

200
00:13:20,540 --> 00:13:26,710
一百棵树，我们可以看到我们可能还有更多的步骤，但绝对不是十倍

201
00:13:26,790 --> 00:13:27,790
前面的步骤。

202
00:13:27,790 --> 00:13:33,340
因此，作出这种解释的原因与我与您谈论的这种融合想法有关

203
00:13:33,340 --> 00:13:33,590
。

204
00:13:33,820 --> 00:13:39,910
因此，就地块而言，这里有100棵树的变化不是增加的步骤数

205
00:13:40,210 --> 00:13:47,110
但是更好的选择是关于我们的薪资获取途径，更好地选择台阶和楼梯的位置

206
00:13:47,110 --> 00:13:47,210
。

207
00:13:47,230 --> 00:13:53,620
这意味着也许可以更好地定位这些步骤，以便对薪金做出最终预测

208
00:13:53,980 --> 00:13:57,840
我们每个级别的从1到10的值加1。

209
00:13:58,060 --> 00:14:05,220
因此，要确认这一点，我们只需做出最终预测即可预测6.5级的薪水

210
00:14:05,230 --> 00:14:05,380
。

211
00:14:05,380 --> 00:14:12,200
因此，让我们回顾一下，雇主说大约160 k，随机森林说成100 41 k

212
00:14:12,210 --> 00:14:12,510
。

213
00:14:12,670 --> 00:14:19,740
现在，让我们看看退出100棵树的M-4周围的声音，现在它说166K。

214
00:14:19,780 --> 00:14:20,690
好多了。

215
00:14:20,710 --> 00:14:26,980
我们已经接近假定的16万实际工资，此外，我们从未真正处于良好状态

216
00:14:26,980 --> 00:14:31,630
谈判的一面，因为我们将不再认为该员工在虚张声势。

217
00:14:31,630 --> 00:14:37,010
因此，由于随着树木数量的增加，预测似乎正在改善，因此让我们实际尝试

218
00:14:37,030 --> 00:14:39,970
有500棵大森林。

219
00:14:39,970 --> 00:14:40,650
我们现在有。

220
00:14:40,660 --> 00:14:46,010
因此，让我们执行此操作以构建我们的500棵新的巨大森林。

221
00:14:46,030 --> 00:14:46,770
开始了。

222
00:14:46,770 --> 00:14:48,430
Ufer已创建。

223
00:14:48,430 --> 00:14:51,370
让我们快速查看可视化绘图结果。

224
00:14:51,520 --> 00:14:56,090
但这将是同一件事，我们可能不会再有更多的凝视。

225
00:14:56,200 --> 00:14:58,270
好吧，让我们来看看。

226
00:14:59,140 --> 00:15:00,370
好吧，绝对不是。

227
00:15:00,370 --> 00:15:03,040
我们似乎在楼梯上有相同数量的台阶。

228
00:15:03,190 --> 00:15:09,460
但是，正如我告诉您的那样，本系列中的每个步骤实际上都可以更好地定位为使每个步骤

229
00:15:09,460 --> 00:15:13,440
最终预测这里10个级别中每个级别的薪水。

230
00:15:13,450 --> 00:15:20,350
因此，检查该错误的最佳方法实际上是获得我们对6.5抱歉的最终预测

231
00:15:20,350 --> 00:15:21,340
水平。

232
00:15:21,340 --> 00:15:22,790
让我们检查一下。

233
00:15:22,840 --> 00:15:26,150
让我们看看是否比166 OK更好的预测。

234
00:15:26,550 --> 00:15:27,540
正在执行。

235
00:15:27,700 --> 00:15:34,980
就在那一刻，我们以160 458个对不起的预期击中了靶心。

236
00:15:35,080 --> 00:15:40,360
如此出色的工作让美国有500棵树死在这里，因为它预测了

237
00:15:40,360 --> 00:15:43,890
同样遗憾的是，假设工资为16万。

238
00:15:43,890 --> 00:15:49,470
争议者只是说有，而且是Breese公司，实际上到目前为止

239
00:15:49,480 --> 00:15:56,530
对我们来说，拥有500棵树的最佳模型做出了最接近于这160棵树的预测，是一个多项式

240
00:15:56,530 --> 00:16:02,110
回归模型，现在我们的Ranum回归击败了多项式回归模型，因为

241
00:16:02,110 --> 00:16:05,890
现在我们得到的预测几乎与实际值相同。

242
00:16:06,160 --> 00:16:07,480
所以当场。

243
00:16:07,570 --> 00:16:08,800
恭喜你

244
00:16:08,980 --> 00:16:15,220
实际上，我们已经建立了最终模型，现在我只想通过完成此过渡来结束本教程

245
00:16:15,220 --> 00:16:21,750
到我们未来的观点之一（实际上是第10部分），我们将构建一些必不可少的机制

246
00:16:21,790 --> 00:16:22,160
模型。

247
00:16:22,180 --> 00:16:28,540
有些模型是多种机械模型的组合，您在机械中知道这些

248
00:16:28,540 --> 00:16:30,080
实际上是最好的模型。

249
00:16:30,130 --> 00:16:35,020
您知道当您拥有多个机器模型的团队时，他们实际上可以做出出色的预测

250
00:16:35,020 --> 00:16:39,820
因为除非在机械模型的论证中有九次机器运行模型

251
00:16:39,820 --> 00:16:41,240
唯一正确的模型。

252
00:16:41,440 --> 00:16:45,880
那么，通过十种机器学习模型来预测

253
00:16:45,880 --> 00:16:48,370
不仅仅是一个模型。

254
00:16:48,550 --> 00:16:50,120
这实际上就是我们在这里所做的。

255
00:16:50,230 --> 00:16:55,490
好吧，我们有一个相同的机器学习模型团队，即决策树回归模型。

256
00:16:55,570 --> 00:16:59,710
但是将来，我们将组成一个由不同的机器专用模型组成的团队。

257
00:16:59,770 --> 00:17:01,010
因此，这将非常有趣。

258
00:17:01,030 --> 00:17:03,140
那也将非常强大。

259
00:17:03,190 --> 00:17:05,490
我期待与您同行。

260
00:17:05,710 --> 00:17:10,980
因此，现在我要告诉您，首先要祝贺您建立此非常强大的回归功能的两件事

261
00:17:10,990 --> 00:17:17,640
模型用于美国回归模型，其次用于构建我们所有的回归模型。

262
00:17:17,710 --> 00:17:23,580
我们建立了一些线性回归模型，一些非线性回归模型，一些非线性是非连续的

263
00:17:23,590 --> 00:17:28,930
回归模型和一些非线性或非连续和简单的回归模型。

264
00:17:29,080 --> 00:17:33,950
因此，恭喜您，您一定会成为机器学习方面的专家。

265
00:17:34,060 --> 00:17:36,180
但是，等待接下来发生的事情。

266
00:17:36,190 --> 00:17:40,840
因此，谈到接下来会发生什么，我期待在下一部分或下一部分中与您见面。

267
00:17:41,020 --> 00:17:42,930
在此之前，尽早享受任务。

