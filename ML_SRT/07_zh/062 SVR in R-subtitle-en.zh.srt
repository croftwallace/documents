1
00:00:00,270 --> 00:00:02,390
您好，欢迎来到这门艺术。

2
00:00:02,640 --> 00:00:06,140
因此，今天我们将实现第二个非线性回归模型。

3
00:00:06,210 --> 00:00:09,720
这将是我们回归的支持向量。

4
00:00:09,720 --> 00:00:10,640
因此，让我们开始吧。

5
00:00:10,650 --> 00:00:15,710
我们将使用回归模板，您将看到它是如此简单。

6
00:00:15,750 --> 00:00:17,290
因此，让我们从做基础开始。

7
00:00:17,310 --> 00:00:23,280
将正确的文件夹设置为工作目录，以便我们进入运行Z或2回归的机器，然后

8
00:00:23,370 --> 00:00:25,620
支持向量回归。

9
00:00:25,920 --> 00:00:26,220
对。

10
00:00:26,220 --> 00:00:28,830
抱歉，这是步枪的第三位置。

11
00:00:28,920 --> 00:00:29,630
都好。

12
00:00:29,820 --> 00:00:34,460
让我们单击“设置为工作目录”以将文件夹设置为工作目录。

13
00:00:34,460 --> 00:00:34,920
大。

14
00:00:35,040 --> 00:00:36,190
现在我们可以开始了。

15
00:00:36,420 --> 00:00:42,690
因此，我们将采用回归模板，并将所有内容从此处移至此处

16
00:00:42,690 --> 00:00:43,140
。

17
00:00:43,200 --> 00:00:47,000
将其复制并粘贴到我们的SVR模型中。

18
00:00:47,310 --> 00:00:48,080
开始了。

19
00:00:48,180 --> 00:00:50,160
现在我们只需要更改一些内容。

20
00:00:50,220 --> 00:00:53,270
因此，让我们从更改基础开始。

21
00:00:53,350 --> 00:00:56,270
我们将按原样替换回归模型。

22
00:00:56,730 --> 00:00:57,690
好的。

23
00:00:58,230 --> 00:01:02,780
和这里的结果一样。

24
00:01:03,100 --> 00:01:04,010
好的。

25
00:01:04,110 --> 00:01:05,940
和这里一样。

26
00:01:05,940 --> 00:01:06,960
好吧。

27
00:01:07,290 --> 00:01:08,470
那是简单的步骤。

28
00:01:08,580 --> 00:01:10,890
现在让我们进入有趣的步骤。

29
00:01:10,890 --> 00:01:16,230
因此，当然要创建这个有趣的步骤，因为我们是侵略者，我们正在这里创建它

30
00:01:16,250 --> 00:01:16,340
。

31
00:01:16,440 --> 00:01:18,330
所以我要删除它。

32
00:01:18,500 --> 00:01:20,580
现在让我们创建这个回归器。

33
00:01:21,150 --> 00:01:23,490
照常需要三到四行。

34
00:01:23,490 --> 00:01:29,030
这将非常简单，我们将非常简单地使用一个函数，即SVM函数，因为

35
00:01:29,150 --> 00:01:34,770
正如我们所知，这是一种支持向量机算法，但是为了回归，这就是为什么我们称其为

36
00:01:34,770 --> 00:01:35,460
你是。

37
00:01:35,760 --> 00:01:41,030
因此，我们只是从SBM功能中获取它，您将完全理解为什么。

38
00:01:41,490 --> 00:01:47,610
因此，首先让我们导入所需的包，因为此函数包含在

39
00:01:47,610 --> 00:01:49,160
Intent 71软件包。

40
00:01:49,160 --> 00:01:53,870
因此，让我们在这里转到我们的软件包，并检查是否有它。

41
00:01:54,300 --> 00:01:57,860
我之所以拥有它，是因为我当然曾经使用过它，但是您可能没有。

42
00:01:57,850 --> 00:02:05,550
因此，如果您没有它，我将在此处键入此行，您需要执行安装

43
00:02:05,640 --> 00:02:06,550
这个包。

44
00:02:06,630 --> 00:02:12,540
因此，您可以在此处安装该软件包，然后在括号中安装，然后在引号中键入名称

45
00:02:12,540 --> 00:02:16,010
包装是10 71。

46
00:02:16,110 --> 00:02:16,560
好吧。

47
00:02:16,560 --> 00:02:19,480
然后，您只需选择此行并执行即可。

48
00:02:19,710 --> 00:02:21,230
这将安装软件包。

49
00:02:21,330 --> 00:02:26,730
不会这样做，因为我的已经安装了，因此我将在评论中

50
00:02:26,940 --> 00:02:29,580
刚按下命令移位加座位。

51
00:02:29,820 --> 00:02:30,620
好吧。

52
00:02:30,740 --> 00:02:39,720
现在，我们实际上还要添加此行库，并在括号中的Eatons 71中不要加引号。

53
00:02:39,960 --> 00:02:46,440
这将自动选择密集的软件包，因为这并不总是

54
00:02:46,440 --> 00:02:47,100
已选择。

55
00:02:47,310 --> 00:02:49,980
但是通过将其包含在脚本中就可以了。

56
00:02:49,980 --> 00:02:51,520
将始终选择此项。

57
00:02:51,720 --> 00:02:52,290
好。

58
00:02:52,500 --> 00:02:56,360
现在让我们开始创建我们的SVR侵略者。

59
00:02:56,430 --> 00:03:04,140
因此，像往常一样，我们将从定义我们的侵略者回归开始，然后等于

60
00:03:04,170 --> 00:03:09,170
正如我之前提到的，我们将使用实际上是SVM的功能。

61
00:03:09,330 --> 00:03:10,320
然后放在括号中。

62
00:03:10,330 --> 00:03:17,080
现在让我们按一下这里以查看参数并了解我们需要输入的内容。

63
00:03:17,100 --> 00:03:19,040
因此，第一个参数是公式。

64
00:03:19,170 --> 00:03:21,110
因此，您开始完全了解它是什么。

65
00:03:21,110 --> 00:03:30,170
当然，公式是我们的因变量，它是记住薪水然后说出来的。

66
00:03:30,300 --> 00:03:36,480
我刚刚按下，然后在这里执行，这表明我们正在采取所有独立

67
00:03:36,480 --> 00:03:39,530
我们数据集的变量。

68
00:03:39,810 --> 00:03:43,570
实际上，我们有一个自变量，即级别自变量。

69
00:03:43,620 --> 00:03:48,990
所以我们也可以在此处输入水平，但是大多数时候我们使用点是因为我们当然有很多

70
00:03:48,990 --> 00:03:50,910
多个独立的可行性。

71
00:03:51,300 --> 00:03:56,310
但提醒一下，我在这里使用了一个变量，以便我们可以清楚地看到视觉图形

72
00:03:56,310 --> 00:04:00,170
我们正在建立的不同非线性模型的结果。

73
00:04:00,560 --> 00:04:03,160
好的，现在让我们添加第二个参数。

74
00:04:03,420 --> 00:04:06,600
因此，我在此处添加逗号，然后再添加下一个参数。

75
00:04:06,600 --> 00:04:08,810
因此，下一个参数是数据。

76
00:04:09,070 --> 00:04:13,530
好的，我想您知道此数据参数将是什么。

77
00:04:13,530 --> 00:04:20,940
这当然将是我们的数据集数据集，因为我们没有创建任何训练集或测试

78
00:04:20,940 --> 00:04:23,880
在使用训练集之前，您会知道一些集合。

79
00:04:23,880 --> 00:04:24,900
这是数据。

80
00:04:25,080 --> 00:04:29,550
但是这里我们没有任何训练集，所以我们当然要采用整个数据集，因为

81
00:04:29,550 --> 00:04:31,640
我们想做出非常准确的预测。

82
00:04:31,860 --> 00:04:32,320
好。

83
00:04:32,490 --> 00:04:35,080
现在最后是最重要的论点。

84
00:04:35,100 --> 00:04:41,310
好吧，所有论点都很重要，但实际上与本节最相关的是

85
00:04:41,310 --> 00:04:43,490
接下来的争论是关于输入的。

86
00:04:43,530 --> 00:04:48,440
因此，此参数实际上不是X或Y，它们是可选参数。

87
00:04:48,450 --> 00:04:55,860
我刚才谈到的最重要的参数是此类型，因为此参数类型

88
00:04:55,860 --> 00:05:02,570
会实际指定您是否正在制作用于分类的ass VM模型，或者像我们一样

89
00:05:02,580 --> 00:05:04,960
用于回归的模型。

90
00:05:04,980 --> 00:05:11,250
所以在这里，因为我们正在建立一个非线性回归模型，所以我们将选择EPA的回归类型

91
00:05:11,990 --> 00:05:16,610
我们可以使用实际回归或新回归，因为您可以看到您想采用最常见的回归

92
00:05:16,610 --> 00:05:16,700
。

93
00:05:16,760 --> 00:05:18,170
EPA有回归。

94
00:05:18,320 --> 00:05:24,950
如果我们将其作为分类模型，那么我们将在这里选择C分类

95
00:05:24,950 --> 00:05:29,250
如您所见，复杂度是分类的默认类型。

96
00:05:29,540 --> 00:05:34,820
简而言之，如果要进行回归，则选择时间等于回归。

97
00:05:34,990 --> 00:05:39,860
如果要进行分类，请选择类型，然后进行C分类，然后

98
00:05:39,860 --> 00:05:43,180
关于分类的下一部分将创建一个SVM模型。

99
00:05:43,220 --> 00:05:47,290
对于此特定模型，我们将选择C分类类型。

100
00:05:47,840 --> 00:05:51,540
好的，但是我们在进行回归，因此我们选择回归类型。

101
00:05:51,540 --> 00:05:59,150
因此，我们将其放入类型中，类型等于EPEAT作为回归。

102
00:05:59,450 --> 00:05:59,700
对。

103
00:05:59,720 --> 00:06:01,410
您需要将其用引号引起来。

104
00:06:01,460 --> 00:06:07,910
实际上，不要忘记引号，以防止再次发生任何错误。

105
00:06:07,910 --> 00:06:13,820
实际上，这是最后一个参数，如果需要的话，我们可以在此处添加内核参数只是为了指定

106
00:06:13,820 --> 00:06:19,490
我们想要一个高斯内核，因为在这里我们使用的是Galchen内核，但这是选择的内核

107
00:06:19,490 --> 00:06:25,820
默认情况下，因此我们实际上不需要放置它，而请记住我们在这里使用

108
00:06:26,060 --> 00:06:28,290
Gulshan内核就我们而言是模型。

109
00:06:28,580 --> 00:06:33,520
好的，但是我们都很好，实际上可以创建模型了。

110
00:06:33,770 --> 00:06:40,880
所以实际上这就是我们需要在回归模板中进行的所有更改，现在我们可以执行了

111
00:06:40,880 --> 00:06:46,430
一章一节地创建我们的模型，并找出最终结果和最终结论

112
00:06:46,820 --> 00:06:48,500
无论是真理还是虚张声势。

113
00:06:48,530 --> 00:06:50,470
因此，让我们开始吧。

114
00:06:50,780 --> 00:06:53,780
我将首先导入数据集。

115
00:06:53,810 --> 00:06:54,680
好吧，我们去。

116
00:06:54,820 --> 00:06:56,470
报道不错，我们可以看看。

117
00:06:56,480 --> 00:07:01,520
所以这些日子里，水平作为自变量，工资作为因变量

118
00:07:01,520 --> 00:07:08,710
变量变大，无需将赤字分成训练集，并表示无需将来

119
00:07:08,740 --> 00:07:13,490
进行扫描，因为我们正在使用包含它的任何一个库中非常流行的Eaton。

120
00:07:13,550 --> 00:07:15,670
现在让我们创建模型。

121
00:07:15,710 --> 00:07:22,160
因此，我将在这里为我们的指挥控制中心选择整个部分，以表示遗憾

122
00:07:22,160 --> 00:07:23,900
被创造伟大。

123
00:07:24,080 --> 00:07:28,610
现在，让我们分解一下您的结果，您想从视觉上看到我们是结果吗？

124
00:07:28,640 --> 00:07:34,610
首先或很好地预测新结果，让我们实际预测结果，因为这是最令人兴奋的

125
00:07:34,610 --> 00:07:35,160
步。

126
00:07:35,300 --> 00:07:36,830
让我们保持最好的状态。

127
00:07:37,130 --> 00:07:41,780
但是，这一步骤实际上也非常令人兴奋，因为我们正在获得最终的预测

128
00:07:41,780 --> 00:07:43,540
最终的预计工资。

129
00:07:43,550 --> 00:07:48,110
所以您知道，如果您实际上是在我之前自己编写此代码，则不会。

130
00:07:48,110 --> 00:07:50,030
这实际上是一个很好的练习。

131
00:07:50,060 --> 00:07:51,800
我真的鼓励您这样做。

132
00:07:51,830 --> 00:07:55,570
无论如何，首先选择要执行的任务。

133
00:07:55,580 --> 00:07:57,490
您现在无需更改任何其他内容。

134
00:07:57,620 --> 00:08:00,020
所以我现在要执行该操作。

135
00:08:00,380 --> 00:08:06,180
实际上，我们获得的预测薪水为十七万七千美元。

136
00:08:06,230 --> 00:08:07,010
大。

137
00:08:07,310 --> 00:08:12,650
因此，请记住这位正在谈判未来薪资的员工说，这是相当不错的薪水

138
00:08:12,650 --> 00:08:14,130
是160好。

139
00:08:14,330 --> 00:08:19,200
并且我们的模型预测，这是一笔可观的薪水，有一百七十七。

140
00:08:19,190 --> 00:08:19,580
好。

141
00:08:19,790 --> 00:08:23,490
因此，首先，这实际上与该员工所说的相近。

142
00:08:23,570 --> 00:08:26,410
此外，它在谈判的有利方面。

143
00:08:26,480 --> 00:08:27,850
因此，这实际上非常好。

144
00:08:27,950 --> 00:08:31,570
然后我们可以对这个结果和我们的模型感到满意。

145
00:08:31,580 --> 00:08:38,060
但是要真正满意，让我们看看图形结果发生了什么，所以我要执行

146
00:08:38,060 --> 00:08:44,990
在本节中，让我们看一下SVR模型。

147
00:08:45,230 --> 00:08:47,990
我将放大它，并且更好。

148
00:08:48,140 --> 00:08:48,810
好的。

149
00:08:49,040 --> 00:08:51,750
因此，此模型首先非常适合。

150
00:08:51,770 --> 00:08:57,380
大多数数据点提醒我们，真实的观察点此处还有其他红色点，以及所有

151
00:08:57,380 --> 00:09:02,670
点在此蓝色曲线上，这就是您的模型本身的预测点。

152
00:09:02,660 --> 00:09:08,600
因此，例如，如果我们在此处采用这个红色观察点，则预测是完美的，因为

153
00:09:08,660 --> 00:09:12,530
预测点是该红色点在蓝色曲线上的投影。

154
00:09:12,650 --> 00:09:17,690
所以它实际上是重新指向自身，因为红色点位于蓝色曲线上，因此非常适合

155
00:09:17,690 --> 00:09:22,790
预测，但是在此，例如，如果我们进行的预测不太准确，但仍然是非常好的预测

156
00:09:22,790 --> 00:09:28,580
我们将真实的观察点作为投影在蓝色曲线上的红色点，即

157
00:09:28,580 --> 00:09:33,150
实际薪水和预计的对不起之间的差是在这里。

158
00:09:33,160 --> 00:09:38,780
如果将其投影回包含薪水的y轴上，但您可以看到所有这些

159
00:09:38,780 --> 00:09:44,750
从这一点到实际上这一点，蓝色曲线实际上已经非常接近真实

160
00:09:44,750 --> 00:09:46,780
观察点为红色点。

161
00:09:46,820 --> 00:09:53,390
因此，预测非常接近实际结果，但这是针对数据集的所有这些点的

162
00:09:53,510 --> 00:09:55,330
除了这里的那个。

163
00:09:55,370 --> 00:09:59,400
顺便看一下，这是一个单独的地方。

164
00:09:59,420 --> 00:10:05,690
因此，我为首席执行官感到抱歉，但是发生这种情况的原因是，这实际上是一个离群值

165
00:10:05,920 --> 00:10:11,990
今年不要说不是骗子，但这是一个离群值，因为正如您所看到的，这实际上是

166
00:10:11,990 --> 00:10:15,380
在薪金方面与其他观点相去甚远。

167
00:10:15,410 --> 00:10:19,810
首席执行官的薪水比以前的职位高得多。

168
00:10:19,820 --> 00:10:24,040
因此，作为您的模型，这是一个离群值，因此他实际上没有考虑。

169
00:10:24,050 --> 00:10:30,440
就像在这一点上，它不排除任何道德，就是不去看它，并根据这些做出预测。

170
00:10:30,440 --> 00:10:31,250
点在这里。

171
00:10:31,550 --> 00:10:37,340
因此，具体取决于您的算法本身，但是有很多参数，您可以

172
00:10:37,340 --> 00:10:43,200
实际使用参数来改变模型感知异常值的方式。

173
00:10:43,310 --> 00:10:49,070
因此，例如，这些参数是惩罚参数，正则化参数是大多数

174
00:10:49,070 --> 00:10:54,780
说明书中充分描述的时间，当然，伊顿71库也包括这样的技术。

175
00:10:55,340 --> 00:11:00,710
但是我们不会在本教程中进行此操作，因为我们实际上不需要获得良好的预测

176
00:11:00,710 --> 00:11:02,200
首席执行官的薪水

177
00:11:02,210 --> 00:11:06,740
记住，我们实际需要的是对我们之前这名员工以前的工资的良好预测

178
00:11:06,730 --> 00:11:10,440
正在谈判中，此员工的级别为6.5。

179
00:11:10,610 --> 00:11:15,830
在这一点上，我们可以看到该模型非常适合我们的数据集，我们实际上得到了一个

180
00:11:15,830 --> 00:11:23,510
177 K的预测非常接近该员工的实际工资或提及的工资，即160

181
00:11:23,510 --> 00:11:23,930
k。

182
00:11:24,200 --> 00:11:25,400
因此，这实际上非常好。

183
00:11:25,460 --> 00:11:32,520
因此，根据我们的模型，虚张声势的真实性判断是相当真实的。

184
00:11:32,750 --> 00:11:35,890
好的，还不错，因为您在这里做得很好。

185
00:11:35,900 --> 00:11:40,610
现在，让我们看一下决策树回归并为我们运行回归的过程，我们将在

186
00:11:40,610 --> 00:11:41,600
下一节。

187
00:11:41,690 --> 00:11:42,520
所以我在那里见。

188
00:11:42,560 --> 00:11:44,210
在那之前享受机器学习

