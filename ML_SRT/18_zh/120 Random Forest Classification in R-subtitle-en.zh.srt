1
00:00:00,180 --> 00:00:05,700
您好，欢迎来到我们的教程，我们终于可以进入分类冒险的最后一轮了

2
00:00:05,700 --> 00:00:11,080
在我们的机器学习过程中，因为今天我们将最后一个分类器设为随机森林

3
00:00:11,100 --> 00:00:12,000
分类器。

4
00:00:12,270 --> 00:00:17,640
因此，该分类器基本上为您提供了上一类的父亲决策树分类器，因为

5
00:00:17,730 --> 00:00:22,520
非常简单，随机森林分类器是一组决策树。

6
00:00:22,650 --> 00:00:27,840
因此，您将看到我们将选择一些树来组成我们的随机森林，然后在

7
00:00:27,840 --> 00:00:33,720
时间做出预测，那么随机森林中的每棵树都将做出预测

8
00:00:33,900 --> 00:00:39,150
他们是否认为用户会购买是或否的SUV，然后随机森林就会出现

9
00:00:39,150 --> 00:00:44,610
在它的树的每个表决中，然后我们将计算每个具有

10
00:00:44,610 --> 00:00:50,460
关于SUV使用的是的票数，他们使用或不购买的否的票数。

11
00:00:50,460 --> 00:00:56,160
SUV并仅根据多数投票为我们运行它们，您将选择一个已获得

12
00:00:56,430 --> 00:01:02,300
从树上投票最多的多数票使其成为最终预测。

13
00:01:02,310 --> 00:01:04,480
这就是为我们跑步的想法。

14
00:01:04,650 --> 00:01:09,390
因此，如果您正确理解了决策树，那么您将毫无疑问地了解

15
00:01:09,490 --> 00:01:10,570
为我们跑步。

16
00:01:10,590 --> 00:01:10,890
好。

17
00:01:10,890 --> 00:01:15,590
因此，让我们现在为您提供最后的机会，让我们了解结果。

18
00:01:15,690 --> 00:01:20,370
因此，让我们从基础开始吧，您将在文件夹中找到合适的其余部分

19
00:01:20,370 --> 00:01:24,520
工作目录，所以这支步枪和男孩3分类。

20
00:01:24,630 --> 00:01:27,260
这是运行分类时的部分。

21
00:01:27,270 --> 00:01:28,810
那是正确的文件夹。

22
00:01:29,040 --> 00:01:34,800
正如我告诉您的那样，我们将进入第三部分分类的结尾，因为下一部分

23
00:01:34,800 --> 00:01:40,670
将致力于评估分类模型的性能，以改进模型。

24
00:01:40,800 --> 00:01:42,830
因此，这是我们最后的气化炉。

25
00:01:43,020 --> 00:01:44,250
因此，让我们转到该文件夹​​。

26
00:01:44,370 --> 00:01:48,060
那就是我们要设置为工作目录的文件夹，确保您拥有社交网络广告

27
00:01:48,140 --> 00:01:49,170
当您归档时。

28
00:01:49,230 --> 00:01:53,900
如果是这种情况，请单击此处的更多按钮，然后将其设置为工作目录。

29
00:01:54,180 --> 00:01:59,970
一切都很好，现在让我们进入分类模板为我们分类器围绕它们构建

30
00:02:00,240 --> 00:02:01,770
以最好的效率。

31
00:02:01,770 --> 00:02:10,710
因此，我们将所有内容从这里复制到底部副本，然后将其粘贴到此处。

32
00:02:11,010 --> 00:02:14,630
好的，我只想简单提醒一下此模板的功能。

33
00:02:14,640 --> 00:02:16,790
因此，第一步是导入数据集。

34
00:02:16,860 --> 00:02:22,830
我们正在投放包含文件的社交网络广告，其中包含有关社交网络用户的一些数据

35
00:02:23,220 --> 00:02:26,750
以及他们的信息，例如年龄和估算工资。

36
00:02:26,910 --> 00:02:32,760
因此，这家汽车公司刚刚以荒谬的价格推出了全新的SUV，将广告投放到社交网站上

37
00:02:32,760 --> 00:02:37,060
网络和他认为告诉我们的此社交网络广告的最后一栏。

38
00:02:37,100 --> 00:02:38,210
如果是或否。

39
00:02:38,220 --> 00:02:41,120
社交网络的一些用户购买了SUV。

40
00:02:41,190 --> 00:02:47,970
所以如果没有，则为零，如果是，则在这里编码目标特征因子，因为有时我们需要

41
00:02:47,970 --> 00:02:50,340
为我们建立的班级费耶斯做。

42
00:02:50,360 --> 00:02:55,740
我们只是在执行此操作以指定解密他们最后一次购买的电话是类别变量

43
00:02:55,740 --> 00:02:58,380
因子级别0和1。

44
00:02:58,590 --> 00:03:03,570
所以我们不需要对所有的分类器都这样做，但是我们确实需要像海军基地那样在太阳下进行

45
00:03:03,570 --> 00:03:04,860
就像我们看到的那样

46
00:03:05,040 --> 00:03:09,840
因此，最好将此代码部分保留在模板中，然后将数据集拆分为训练

47
00:03:09,840 --> 00:03:11,220
集和测试集。

48
00:03:11,220 --> 00:03:16,780
提醒一下，训练集就是我们为美国人为变相而运行的机器学习模型的地方

49
00:03:16,830 --> 00:03:20,920
该模型将了解年龄与估计工资之间的相关性。

50
00:03:21,120 --> 00:03:25,890
以及用户是否会购买SUV的问题，然后根据这些信息

51
00:03:25,890 --> 00:03:28,990
机器学习模型学习如何做出一些未来的预测。

52
00:03:29,220 --> 00:03:34,810
因此，我们在此处构建此测试集，以根据预测测试模型的性能。

53
00:03:34,950 --> 00:03:39,570
然后在预处理阶段的最后一部分中，应用fut。 获取数据，我们

54
00:03:39,570 --> 00:03:45,360
之所以这样做，是因为在此模板的最后，我们针对这两种趋势制作了非常酷的图形

55
00:03:45,360 --> 00:03:50,300
得出测试结果，将绘制预测区域和预测边界。

56
00:03:50,520 --> 00:03:54,820
好的，现在我们需要在此模板中进行一些更改，但需要进行一些更改。

57
00:03:54,930 --> 00:04:02,310
首先，请不要忘记更改情节的标题，此处将替换为随机森林分类

58
00:04:02,930 --> 00:04:04,500
分类。

59
00:04:04,890 --> 00:04:08,790
我们将复制它，因为我们将在测试结果中执行相同的操作。

60
00:04:08,790 --> 00:04:09,570
这里是。

61
00:04:09,630 --> 00:04:10,560
完善。

62
00:04:11,000 --> 00:04:11,500
好。

63
00:04:11,490 --> 00:04:17,700
现在，我们只需要在此处创建分类器，便可以准备就绪。

64
00:04:17,700 --> 00:04:20,120
所以我将在此处粘贴相同的内容。

65
00:04:20,150 --> 00:04:22,340
运行它们为我们气化到火车上。

66
00:04:22,620 --> 00:04:25,270
现在，让我们创建分类器。

67
00:04:25,290 --> 00:04:26,520
好吧，让我们这样做。

68
00:04:26,520 --> 00:04:27,960
因此，这非常简单。

69
00:04:27,960 --> 00:04:31,470
我们将使用一个称为随机森林的库。

70
00:04:31,620 --> 00:04:37,260
因此，让我们执行此操作，首先使用安装该软件包的命令来安装该软件包。

71
00:04:37,590 --> 00:04:43,410
因此，这是针对那些第一次使用此软件包的人，那么您将不会安装它

72
00:04:43,500 --> 00:04:45,040
在你背上就在这里。

73
00:04:45,420 --> 00:04:49,330
如您所见，我已经在这里了，因为我使用了几次。

74
00:04:49,360 --> 00:04:51,490
那里是森林。

75
00:04:51,630 --> 00:04:55,900
因此，如果您不是这种情况，则需要在此处安装软件包。

76
00:04:56,070 --> 00:05:02,430
因此，在此安装包功能中，您只需要在引号中输入库的名称

77
00:05:02,440 --> 00:05:02,560
。

78
00:05:02,760 --> 00:05:09,670
因此，Forest随机选择此处的大写F而不是此处的大写。

79
00:05:09,670 --> 00:05:13,540
好的，这就是您需要传递的内容，它将安装软件包。

80
00:05:13,560 --> 00:05:18,610
我不会这样做，因为我已经安装了我的，而您只需要选择此选项即可

81
00:05:18,810 --> 00:05:21,340
然后按Command和Control加Enter键执行。

82
00:05:21,340 --> 00:05:24,570
这样就可以毫无问题地安装软件包。

83
00:05:24,570 --> 00:05:29,550
好的，所以在这里，我仅按Plessey的班次按Command作为注释即可。

84
00:05:29,560 --> 00:05:36,330
但是然后我需要做的是在这里的库中添加命令，然后输入Ranum的名称

85
00:05:36,330 --> 00:05:39,190
美国图书馆，因为您在这里可以看到它未被选中。

86
00:05:39,310 --> 00:05:45,040
因此，我需要添加这个库，并为我们提供命令以自动选择它，尤其是在我想

87
00:05:45,040 --> 00:05:48,160
在将来制作一些自动化脚本。

88
00:05:48,340 --> 00:05:50,970
所以要做的事情是非常实际的。

89
00:05:51,220 --> 00:05:54,390
现在我们都很好，让我们创建分类器。

90
00:05:54,690 --> 00:06:00,200
好的，所以像往常一样，我们将从创建Voivode分类器开始，该分类器将围绕我们

91
00:06:00,210 --> 00:06:01,300
本身。

92
00:06:01,300 --> 00:06:05,350
现在，我们将使用随机森林函数来构建分类器。

93
00:06:05,350 --> 00:06:11,110
因此，在这里，我将采用随机森林函数，现在让我们看看我们需要输入哪些参数

94
00:06:11,110 --> 00:06:11,410
。

95
00:06:11,410 --> 00:06:17,860
因此，我们只需要按一下即可获得有关这些功能的一些信息，或者我们需要在此处单击

96
00:06:18,100 --> 00:06:23,940
这里和这里是有关随机森林库和函数的一些信息。

97
00:06:23,940 --> 00:06:27,150
因此，让我们看一下我们感兴趣的参数。

98
00:06:27,510 --> 00:06:27,780
好。

99
00:06:27,790 --> 00:06:32,270
因此，第一个参数是数据，我们将需要它，因为您可以看到它是一个国家数据框架。

100
00:06:32,410 --> 00:06:36,640
因此，我们不需要围绕他为他的分类器建立论据。

101
00:06:36,680 --> 00:06:37,550
子集相同。

102
00:06:37,560 --> 00:06:42,210
他们可以采取行动，实际上我们不需要为我们构建的第三个参数。

103
00:06:42,220 --> 00:06:49,980
但是，我们当然需要这里的x和y参数，您可以猜测它们将是特征矩阵

104
00:06:50,130 --> 00:06:52,340
以及因变量向量。

105
00:06:52,440 --> 00:06:56,770
正如您所看到的，X确实是数据帧或预测变量矩阵。

106
00:06:56,800 --> 00:06:58,000
这很清楚。

107
00:06:58,030 --> 00:07:04,270
X是特征矩阵，是预测变量矩阵，这是我们的自变量年龄估计

108
00:07:04,260 --> 00:07:05,070
薪水。

109
00:07:05,290 --> 00:07:07,930
然后为什么要成为响应向量。

110
00:07:07,940 --> 00:07:12,950
因此，为什么要选择作为列的因变量向量呢？

111
00:07:13,400 --> 00:07:14,350
好的，完美。

112
00:07:14,350 --> 00:07:19,690
然后需要为我们分类器建立的最后一个参数当然是数字

113
00:07:19,690 --> 00:07:26,350
森林中我们想拥有的树木数量，此数目由此处的进入参数给出

114
00:07:26,710 --> 00:07:30,110
如您所见，这是要生长的树木数量。

115
00:07:30,340 --> 00:07:36,040
因此，增长是告诉树木从数据集中学习如何进行预测的好方法

116
00:07:36,050 --> 00:07:36,240
。

117
00:07:36,490 --> 00:07:39,400
基本上，此参数是树木的数量。

118
00:07:39,460 --> 00:07:42,390
因此，请记住我们选择哨兵的方式。

119
00:07:42,460 --> 00:07:43,880
好吧，我们在这里做同样的事情。

120
00:07:43,890 --> 00:07:44,590
让我们选择。

121
00:07:44,620 --> 00:07:45,940
条目等于10。

122
00:07:46,300 --> 00:07:52,620
实际上，这是我们需要围绕他构建的所有东西，我们只能将您分类为X的矩阵

123
00:07:52,690 --> 00:07:55,620
自变量y的特征主义矩阵。

124
00:07:55,750 --> 00:08:00,720
因变量矢量的响应矢量和部队人数。

125
00:08:00,730 --> 00:08:02,930
好的，让我们这样做吧，让我们以参数结尾。

126
00:08:03,120 --> 00:08:04,270
让我们回到我们的。

127
00:08:04,480 --> 00:08:05,250
我们到了。

128
00:08:05,380 --> 00:08:05,650
好。

129
00:08:05,640 --> 00:08:10,840
让我们以参数结尾，因为您记得第一个参数是矩阵A具有矩阵

130
00:08:10,840 --> 00:08:12,220
自变量。

131
00:08:12,390 --> 00:08:20,320
那就是训练集，不包括索引为3的最后一列，因为您在训练中记得

132
00:08:20,320 --> 00:08:26,590
设置我们有前两列，它们是自变量的估计年龄，因此

133
00:08:26,760 --> 00:08:28,200
索引1和2。

134
00:08:28,360 --> 00:08:33,660
第三列由三索引，这是购买的因变量向量。

135
00:08:33,730 --> 00:08:35,150
所以这里减去三。

136
00:08:35,320 --> 00:08:39,720
那么下一个参数是什么，下一个参数是为什么因变量向量。

137
00:08:39,930 --> 00:08:46,820
然后这里将使用trainset，让我们以这种方式选择它以在bin不变式中指定的名称

138
00:08:46,840 --> 00:08:49,930
2美元在这里购买。

139
00:08:49,920 --> 00:08:53,250
已购买是我们的因变量列的名称。

140
00:08:53,250 --> 00:08:55,620
好的，所以我们几乎拥有了所需的一切。

141
00:08:55,620 --> 00:09:02,990
我们现在需要的最后一件事当然是树木的数量，即入口等于10。

142
00:09:03,000 --> 00:09:08,080
您可以使用输入参数进行操作，还可以在将要观察的森林中选择更多树木

143
00:09:08,080 --> 00:09:09,300
一些有趣的结果。

144
00:09:09,350 --> 00:09:15,840
有趣的是，看到不同的树木小组可以做什么来预测用户的响应

145
00:09:15,930 --> 00:09:19,160
在社交网络中，无论他们是否购买SUV。

146
00:09:19,390 --> 00:09:24,900
但是，如果要这样做，请务必注意要避免的过度拟合。

147
00:09:24,900 --> 00:09:27,550
您不想过度训练他们来上课。

148
00:09:27,560 --> 00:09:28,770
训练说的很对。

149
00:09:28,890 --> 00:09:33,490
因为如果执行此操作，则可能会对新的集合做出一些错误的预测。

150
00:09:33,490 --> 00:09:39,660
您可以通过测试实际检查出来，但是他会选择10棵树，我们将看看会发生什么。

151
00:09:39,660 --> 00:09:40,020
好吧。

152
00:09:40,010 --> 00:09:42,510
所以实际上我们已经完成了模板。

153
00:09:42,510 --> 00:09:49,000
我们更改了我们必须更改的所有内容，现在我们可以知道选择所有内容并执行

154
00:09:49,330 --> 00:09:50,550
准备好一切。

155
00:09:50,560 --> 00:09:56,280
实际上，您可以喝点咖啡或茶，然后选择所有内容并执行观看

156
00:09:56,290 --> 00:09:57,110
结果。

157
00:09:57,410 --> 00:10:04,060
但是，让我们宁愿一步一步地做，我们将在这里一次完成第一步预处理步骤，所以我

158
00:10:04,060 --> 00:10:09,730
刚刚选择了预处理阶段，现在我将按Command Control按Enter执行所有

159
00:10:09,730 --> 00:10:14,890
好的，我们有我们的数据集，训练集和测试集。

160
00:10:15,000 --> 00:10:21,990
所以一切看起来都很好，我们总共有300个观测值进入了训练集

161
00:10:22,280 --> 00:10:29,020
我进入了测试集中的100个观察值中，您可以看到训练集和测试集已缩放

162
00:10:29,380 --> 00:10:33,960
因为最后我们绘制了一些分辨率为0 0 1的图形结果。

163
00:10:33,970 --> 00:10:40,540
因此，为了使我们的代码更快地执行而又不破坏我们的代码，我们需要应用功能

164
00:10:40,550 --> 00:10:43,250
只是得到我们的训练和测试集。

165
00:10:43,360 --> 00:10:48,780
否则，我们将不需要这样做，因为美国分类的依据不是基于欧几里得

166
00:10:48,780 --> 00:10:53,550
距离，但它基于您知道自变量的条件。

167
00:10:53,740 --> 00:10:59,880
但是由于这里的代码需要大量计算，因此我们需要应用特征缩放

168
00:10:59,880 --> 00:11:01,100
执行得很好。

169
00:11:01,440 --> 00:11:04,290
好吧，让我们这样做，让我们观察结果。

170
00:11:04,290 --> 00:11:08,810
我们只需要通过执行该部分来在此处创建分类器。

171
00:11:08,820 --> 00:11:11,980
所以我会做的很好。

172
00:11:12,000 --> 00:11:18,220
现在再次让我们预测测试结果，然后有了混淆矩阵，它将在手电筒中告诉我们

173
00:11:18,340 --> 00:11:20,270
我们有多少不正确的预测。

174
00:11:20,400 --> 00:11:22,370
因此，让我们直接直接进行操作。

175
00:11:22,440 --> 00:11:27,360
更快地了解我们的Ranum如何根据预测对其进行分类。

176
00:11:27,450 --> 00:11:29,160
因此，让我们执行一下。

177
00:11:29,640 --> 00:11:35,500
现在让我们在理事会按Enter的位置输入CME。

178
00:11:35,860 --> 00:11:38,130
在这里，我们有了混淆矩阵。

179
00:11:38,250 --> 00:11:42,620
好，我们有七个加10等于17个错误的预测。

180
00:11:42,960 --> 00:11:44,210
嗯，还算不错。

181
00:11:44,250 --> 00:11:52,560
只是为了好玩，让我们只选择另一棵树，例如，让我们选择500棵树500

182
00:11:52,560 --> 00:11:53,240
树木很多。

183
00:11:53,250 --> 00:11:57,220
这是一个很大的树木大军，需要做出一些预测。

184
00:11:57,450 --> 00:11:59,940
现在只是为了好玩，让我们来看看。

185
00:11:59,980 --> 00:12:05,020
我不需要这样做，因为我的库是从上一次执行此操作中选择的

186
00:12:05,010 --> 00:12:05,760
代码部分。

187
00:12:05,760 --> 00:12:10,110
因此，让我们用500棵树重建一个新的分类器。

188
00:12:10,130 --> 00:12:13,210
现在让我们看一下混淆矩阵。

189
00:12:13,370 --> 00:12:18,630
但是在建立预测向量之前，因为现在预测的Y保护器是

190
00:12:18,630 --> 00:12:21,130
奔跑给我们的一棵，有十棵树。

191
00:12:21,450 --> 00:12:23,120
因此，让我们真正执行一下。

192
00:12:23,130 --> 00:12:30,120
现在，我们有y扩散，这是Ranum为我们预测的500棵树的预测向量

193
00:12:30,120 --> 00:12:30,660
。

194
00:12:30,660 --> 00:12:32,620
现在让我们看一下预测矩阵。

195
00:12:32,620 --> 00:12:36,320
记住，对于Gentry，我们有17个错误的预测。

196
00:12:36,340 --> 00:12:37,390
现在让我们看看。

197
00:12:37,470 --> 00:12:41,130
选择执行C并输入。

198
00:12:41,160 --> 00:12:44,470
现在我们有15个错误的预测。

199
00:12:44,490 --> 00:12:45,000
大。

200
00:12:45,000 --> 00:12:48,880
我们投资了490多棵树，以赢得正确的预测。

201
00:12:49,090 --> 00:12:53,420
因此，这绝对意味着团队中有很多有用的树。

202
00:12:53,610 --> 00:13:01,930
好的，所以如果您想让我们回到这里的几个世纪，因为显然500棵树不是很有用

203
00:13:01,920 --> 00:13:02,660
。

204
00:13:02,670 --> 00:13:05,700
好吧，我再再讲一次。

205
00:13:05,930 --> 00:13:06,860
那也一样。

206
00:13:06,880 --> 00:13:09,370
还有。

207
00:13:09,370 --> 00:13:10,090
好吧。

208
00:13:10,260 --> 00:13:12,610
现在，让我们看一下训练搜索结果。

209
00:13:12,630 --> 00:13:17,520
因此，这里一切都很好，我们在这里使用了随机的第一分类更改了标题。

210
00:13:17,520 --> 00:13:18,810
所以这一切都很好。

211
00:13:18,810 --> 00:13:21,520
我们准备看一下图形结果。

212
00:13:21,690 --> 00:13:26,350
顺便说一下，您现在可以使视频困惑，并尝试猜测您将要看到的内容。

213
00:13:26,520 --> 00:13:30,810
尝试猜测预测Regence和预测边界的形状。

214
00:13:30,810 --> 00:13:35,550
如果您正确地理解了决策树，那么您将毫无疑问地猜测将要做什么

215
00:13:35,550 --> 00:13:36,390
发生。

216
00:13:36,390 --> 00:13:39,240
好吧，我现在就执行。

217
00:13:39,250 --> 00:13:47,090
指挥官控制呈现执行和Showtime。

218
00:13:47,110 --> 00:13:47,720
好吧。

219
00:13:47,740 --> 00:13:49,700
哇，这真是太好了。

220
00:13:49,950 --> 00:13:50,220
好。

221
00:13:50,220 --> 00:13:53,700
因此，首先简短简短地提醒您这是什么。

222
00:13:53,700 --> 00:13:57,100
所以这里的点是真实的观察点。

223
00:13:57,120 --> 00:14:03,250
有社交网络的真实用户，红点是未购买SUV和

224
00:14:03,250 --> 00:14:05,790
绿点表示购买了SUV的其他用户。

225
00:14:06,100 --> 00:14:10,080
然后我们在这里有红色区域和绿色区域作为预测区域

226
00:14:10,100 --> 00:14:10,280
。

227
00:14:10,440 --> 00:14:15,660
因此，红色区域是我为我们进行分类的区域，预示着美国不会购买

228
00:14:15,660 --> 00:14:20,690
SUV和我们周围的绿色区域Kaspar预测用户会购买SUV。

229
00:14:20,860 --> 00:14:25,380
好的，总之，要点是事实，而区域是预测。

230
00:14:25,530 --> 00:14:26,250
现在让我们看看。

231
00:14:26,250 --> 00:14:26,530
好。

232
00:14:26,550 --> 00:14:32,950
因此，Ranum for us分类器肯定会抓住大多数未在SUV中购买SUV的用户

233
00:14:32,940 --> 00:14:33,640
正确的类别。

234
00:14:33,630 --> 00:14:34,500
那是红色区域。

235
00:14:34,500 --> 00:14:35,860
所以这意味着它是分类的。

236
00:14:35,860 --> 00:14:40,770
那么，大多数不购买SUV的用户与其他用户的绿色用户相同。

237
00:14:40,780 --> 00:14:48,210
但是，是的，我们现实中是，因为正如我们所看到的那样，大多数人都在正确的绿色区域中，而且它拼命

238
00:14:48,210 --> 00:14:51,450
试图捕捉一些离群值。

239
00:14:51,450 --> 00:14:52,550
我们可以这样称呼他们。

240
00:14:52,550 --> 00:14:58,500
例如，这里的那个人实际上并没有购买SUV，因为这是一个红点，

241
00:14:58,500 --> 00:15:03,780
这是进入绿色区域的方式，我们可以看到，但是随机的头等舱票价设法使

242
00:15:03,780 --> 00:15:08,820
这个红色区域的小矩形部分可以抓住这一点。

243
00:15:08,830 --> 00:15:11,770
使用它，我没有购买SUV并对其进行很好的分类。

244
00:15:12,030 --> 00:15:13,620
但这是明智的做法吗？

245
00:15:13,620 --> 00:15:19,290
因为这将告诉您，对于一些新观察，我们将使您认识一些没有

246
00:15:19,290 --> 00:15:22,350
在这里购买这个红色矩形中的SUV。

247
00:15:22,380 --> 00:15:27,330
这看起来像是过度填充，因为它在这里制作了这个红色矩形，因为我们确实有这个用户

248
00:15:27,340 --> 00:15:33,460
谁没有购买SUV，但没有什么可以告诉我们，对于一些新观察，我们将有一些用户

249
00:15:33,450 --> 00:15:36,520
没有在这里用这个红色矩形购买SUV。

250
00:15:36,720 --> 00:15:38,680
因此，我们应该对此谨慎。

251
00:15:38,830 --> 00:15:44,320
您在该用户处看到的与此用户相同的是，这里没有某种不规则的红色区域

252
00:15:44,620 --> 00:15:50,450
但是幸运的是，对于我们来说分类并没有太着迷于使所有的预测正确。

253
00:15:50,460 --> 00:15:53,890
因为我们可以看到这个红色用户在绿色区域。

254
00:15:53,970 --> 00:15:57,670
因此，这意味着仍要注意或安装它，但不要过多。

255
00:15:57,660 --> 00:15:59,440
我们对此应格外小心。

256
00:15:59,430 --> 00:16:05,140
所以说到过度捕捞，让我们现在检查一下，让我们看看测试结果，看看

257
00:16:05,400 --> 00:16:08,820
这里的区域如何变化，因为您知道区域不会改变。

258
00:16:08,830 --> 00:16:11,100
这些是我们的模型构建的区域。

259
00:16:11,110 --> 00:16:16,980
因此，当我们查看测试结果时，我们将在此处具有相同的红色区域，并在此矩形

260
00:16:16,980 --> 00:16:18,180
这里是绿色区域。

261
00:16:18,420 --> 00:16:22,890
但是将改变的是测试集观察点，即所有红色点和绿色点

262
00:16:22,890 --> 00:16:23,230
点。

263
00:16:23,230 --> 00:16:28,920
这将改变，我们将看到在此矩形中是否存在一些红点，实际上

264
00:16:28,920 --> 00:16:34,710
可能不是因为这看起来像过度拟合，因为我们的课程太适合了

265
00:16:34,840 --> 00:16:37,680
到火车上，让我们现在就了解一下。

266
00:16:37,680 --> 00:16:43,560
让我们选择专用于可视化测试结果的部分。

267
00:16:43,600 --> 00:16:53,230
因此，我将选择所有内容，然后按命令控制并按Enter键执行。

268
00:16:53,220 --> 00:16:53,580
好吧。

269
00:16:53,590 --> 00:16:55,910
那么，您在这里看到的第一件事是什么。

270
00:16:56,130 --> 00:17:02,690
好吧，的确，这里的红色矩形对于某些观察完全有用。

271
00:17:02,700 --> 00:17:09,040
所以这显然是一个红色矩形区域，用于捕捉火车的某些用途，因为我们的课程是

272
00:17:09,030 --> 00:17:14,970
太适合火车组了，这个红色矩形实际上在这里没有任何意义，因为

273
00:17:14,970 --> 00:17:18,830
实际上，我们在此矩形区域中没有红色用户。

274
00:17:18,850 --> 00:17:23,130
嗯，不是说它没有任何意义，而是在这里完全没有用。

275
00:17:23,490 --> 00:17:28,890
此外，您知道我们这里有这个绿点，而这个绿点可能就在这个地区

276
00:17:28,890 --> 00:17:31,030
在这里，它将做出错误的预测。

277
00:17:31,030 --> 00:17:35,850
我们很幸运能做到这一点，因为这些是新发现，

278
00:17:35,860 --> 00:17:41,190
对我们来说是随机的分类机器学习模型没有从这个新观察中学到任何东西

279
00:17:41,190 --> 00:17:41,610
点。

280
00:17:41,730 --> 00:17:46,870
所以这个家伙本来可以很幸运的落到这里。

281
00:17:46,920 --> 00:17:50,740
顺便说一句，对于此区域，我们这里没有红色用户。

282
00:17:50,760 --> 00:17:53,380
那是一些没有在这个红色区域购买SUV的用户。

283
00:17:53,380 --> 00:17:56,400
因此，这个红色区域也完全有用。

284
00:17:56,880 --> 00:18:01,780
好的，这是个主意，但是最重要的是，它做得很好，因为当然有很多红色

285
00:18:01,780 --> 00:18:07,200
年龄低，估算工资低的用户，因此昨天没有购买的用户

286
00:18:07,190 --> 00:18:07,360
。

287
00:18:07,650 --> 00:18:13,500
而且大多数绿色用户（他们的全部都拥有较高的估计薪水）购买了这款出色的产品

288
00:18:13,680 --> 00:18:16,280
像您一样便宜的奢侈品。

289
00:18:16,420 --> 00:18:18,090
现在，这一切的结论是什么。

290
00:18:18,100 --> 00:18:21,580
因为我们到达了分类冒险的终点。

291
00:18:21,610 --> 00:18:27,780
我们构建了所有分类器，因此根据您的需求，什么是该特定业务的最佳气化器

292
00:18:27,780 --> 00:18:28,450
问题。

293
00:18:28,440 --> 00:18:29,770
什么是最好的。

294
00:18:29,880 --> 00:18:32,520
应该是正确分类的分类。

295
00:18:32,530 --> 00:18:39,420
未购买SUV的用户和购买SUV的用户同时防止了过量填充

296
00:18:39,660 --> 00:18:44,730
在训练集中能够对一些新的观察结果做出一些好的新的预测。

297
00:18:44,740 --> 00:18:51,450
因此，在我看来，最好的类别是将内核作为VM，就百分比之间的平衡而言

298
00:18:51,510 --> 00:18:55,210
错误的预测以及我们要防止过拟合的事实。

299
00:18:55,440 --> 00:19:00,940
好吧，如果我再看一下它们，那么我认为最好的分类就是内核。

300
00:19:00,930 --> 00:19:02,990
好的，这就是本教程的结尾。

301
00:19:03,010 --> 00:19:09,840
现在我要说的是祝贺，因为您从简单的分类器构建了很多分类器

302
00:19:09,850 --> 00:19:17,220
逻辑回归到更复杂，更复杂的分类器，例如内核SVM或Ranum

303
00:19:17,240 --> 00:19:18,700
森林分类器。

304
00:19:18,970 --> 00:19:24,220
但这还不是下一节旅程的终点​​，我们将讨论如何评估

305
00:19:24,220 --> 00:19:28,110
模型的性能以及如何改进它们。

306
00:19:28,240 --> 00:19:33,850
最终，我们将在现实生活的数据集上进行作业，将我们学到的知识结合起来

307
00:19:33,850 --> 00:19:38,790
这是关于如何建立一些分类器和所有接下来的概念，我们将学习评估

308
00:19:38,800 --> 00:19:44,160
性能模型，以便为此现实业务问题数据集找到最佳模型，

309
00:19:44,160 --> 00:19:49,540
您将得到帮助，我们将以数据科学家或机器或任何科学家的身份完成工作

310
00:19:49,620 --> 00:19:50,500
事实上。

311
00:19:50,670 --> 00:19:52,240
再次恭喜您。

312
00:19:52,240 --> 00:19:54,210
我期待在下一部分见到您。

313
00:19:54,240 --> 00:19:56,180
在此之前，请享受机器学习。

