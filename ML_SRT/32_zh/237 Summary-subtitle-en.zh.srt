1
00:00:00,390 --> 00:00:03,060
您好，欢迎回到深度学习课程。

2
00:00:03,120 --> 00:00:06,010
因此，我们在本节课程中学到了很多东西。

3
00:00:06,030 --> 00:00:08,390
让我们总结一下我们所讨论的内容。

4
00:00:08,580 --> 00:00:09,920
好吧，我们开始吧。

5
00:00:10,110 --> 00:00:16,230
我们从一个输入图像开始，对它应用了多个不同的特征检测器，也称为

6
00:00:16,230 --> 00:00:19,100
过滤器以创建这些特征图。

7
00:00:19,140 --> 00:00:21,530
这包括我们的卷积巢穴。

8
00:00:21,630 --> 00:00:28,910
然后在关键的Lehre顶部，我们应用reglue或整流线性单元以消除任何清晰度

9
00:00:28,980 --> 00:00:32,050
或增加我们图像中的非线性。

10
00:00:32,060 --> 00:00:36,970
然后，我们将卷积巢穴应用于卷积巢穴。

11
00:00:36,990 --> 00:00:44,910
因此，从每个单个要素地图中，我们都创建了一个混合要素地图，基本上，拉雷尔

12
00:00:44,910 --> 00:00:45,840
很多优点。

13
00:00:45,840 --> 00:00:54,150
拉巢穴的主要目的是确保我们在我们的空间中具有特殊的空间不变性

14
00:00:54,330 --> 00:00:54,690
图片。

15
00:00:54,690 --> 00:01:01,890
所以基本上，如果某些东西倾斜或扭曲或与理想情况有些不同，那么我们仍然可以

16
00:01:01,890 --> 00:01:07,210
选择该功能再加上拉动会大大减小图像的大小。

17
00:01:07,260 --> 00:01:15,360
池化还有助于避免我们的数据或整体模型对数据的任何过度拟合，因为

18
00:01:15,360 --> 00:01:18,220
它只是简单地摆脱了很多数据。

19
00:01:18,450 --> 00:01:24,300
但是同时池保留了我们所追求的主要功能，只是因为方式指令

20
00:01:24,330 --> 00:01:26,720
而使用的池是最大池。

21
00:01:26,970 --> 00:01:35,760
然后，我们将所有合并的图像展平为所有这些值的一个长向量或一列，

22
00:01:35,760 --> 00:01:40,140
我们将其放入人工神经网络中，然后逐步展平。

23
00:01:40,140 --> 00:01:46,770
第四步是一个完全连接的人工神经网络，其中所有这些特征都经过处理

24
00:01:46,920 --> 00:01:53,700
通过网络，然后我们在最后的Lehre最后的完全连接层中进行投票

25
00:01:53,910 --> 00:02:00,630
面向我们所要学习的课程，然后通过向前传播对所有这些课程进行培训，

26
00:02:00,720 --> 00:02:02,550
反向传播过程。

27
00:02:02,580 --> 00:02:09,730
很多迭代，在公园，最后我们有了一个定义明确的神经网络。

28
00:02:09,920 --> 00:02:10,470
和。

29
00:02:10,730 --> 00:02:14,850
另一个重要的事情是，不仅在人工神经元工作部分训练了砝码，而且

30
00:02:15,180 --> 00:02:22,590
功能检测器在相同的配料处理过程中经过培训和调整，可以

31
00:02:22,590 --> 00:02:23,930
我们提出了最好的功能图。

32
00:02:23,940 --> 00:02:31,110
最后，我们得到了训练有素的卷积神经网络，该网络可以识别图像并进行分类

33
00:02:31,110 --> 00:02:31,700
他们。

34
00:02:31,770 --> 00:02:32,360
所以我们去了。

35
00:02:32,370 --> 00:02:35,480
这就是卷积神经网络的工作方式。

36
00:02:35,730 --> 00:02:42,220
现在，您应该完全熟悉这个概念，并准备进行实际应用。

37
00:02:42,330 --> 00:02:51,370
如果您想做更多的阅读，那么L.D有一个很棒的博客。 从2016年解散。

38
00:02:51,450 --> 00:02:53,400
您可以在底部看到链接。

39
00:02:53,400 --> 00:02:58,360
因此，该博客称为“九篇深度学习论文”，您需要了解了解CNN的这一部分

40
00:02:58,440 --> 00:02:59,180
三。

41
00:02:59,310 --> 00:03:04,860
这个博客实际上为您提供了由创建的九种不同CNN的简短概述

42
00:03:04,860 --> 00:03:10,590
像您这样的人和licken以及其他您可以继续研究的人。

43
00:03:10,590 --> 00:03:18,000
因此，会有很多新事物对您来说是全新的，您将必须获得

44
00:03:18,000 --> 00:03:23,880
走开，但只要记住此博客，就牢记这九篇论文，即使您尚未准备好

45
00:03:23,880 --> 00:03:29,220
立即进行阅读，也许是在实际教程之后，或者在您做了一些额外的练习之后

46
00:03:29,490 --> 00:03:36,180
慢慢地在深度学习领域进行培训，然后您可以参考这些作品，理想情况下，我认为

47
00:03:36,180 --> 00:03:41,360
通过查看其他人的神经网络及其结构，您将获得很多价值。

48
00:03:41,550 --> 00:03:46,620
可能会有虚幻的网络，它将帮助您了解什么是最佳实践以及人们为什么

49
00:03:46,620 --> 00:03:51,870
以某种方式做了某些事情，这将对您的神经网络架构有所帮助

50
00:03:51,870 --> 00:03:57,900
因为神经网络和卷积神经网络也不例外。

51
00:03:58,020 --> 00:04:05,670
它们就像是架构挑战，您必须提出一个想法，然后进行结构化，然后

52
00:04:05,670 --> 00:04:11,780
对其进行调整和调整，以获得最佳设计，并获得最佳和最佳性能。

53
00:04:11,790 --> 00:04:12,490
所以我们去了。

54
00:04:12,510 --> 00:04:13,430
今天就是我们了。

55
00:04:13,420 --> 00:04:17,720
希望您喜欢今天的教程和整个部分，并希望下次见到您。

56
00:04:17,730 --> 00:04:19,440
在此之前，请享受深度学习。

