1
00:00:00,270 --> 00:00:02,640
您好，欢迎来到本Python教程。

2
00:00:02,730 --> 00:00:07,580
因此，在上一个教程中，我们学习了一种评估模型性能的非常有效的方法。

3
00:00:07,590 --> 00:00:10,800
因此，这是关于评估模型性能。

4
00:00:10,800 --> 00:00:15,960
在今天的Statoil中，我们将学习一种有关改进模型的技术

5
00:00:15,960 --> 00:00:17,160
性能。

6
00:00:17,160 --> 00:00:21,450
因此，我们已经建立了非常强大的模型，但是我们仍然可以对其进行改进。

7
00:00:21,450 --> 00:00:27,480
我们如何通过找到超参数的最佳值来做到这一点，因为实际上

8
00:00:27,480 --> 00:00:30,680
机器早期模型由两种类型的参数组成。

9
00:00:30,720 --> 00:00:35,530
第一类参数是通过机器学习算法学习的参数

10
00:00:35,760 --> 00:00:39,150
第二种参数是我们选择的参数。

11
00:00:39,180 --> 00:00:45,720
例如，例如SVM模型中的内核，惩罚参数甚至某些正则化参数

12
00:00:45,720 --> 00:00:47,550
倒退或更少。

13
00:00:47,680 --> 00:00:52,320
基本上，在任何机器学习模型中，我们都有很多未学习的参数。

14
00:00:52,470 --> 00:00:57,570
到目前为止，我们在本课程中所做的只是为这些参数选择一个值。

15
00:00:57,600 --> 00:01:02,650
我们从未真正体验过这些超级参数，也从未尝试过使用它们的多个值。

16
00:01:02,880 --> 00:01:07,560
因此，这仍然给我们很大的改进空间，因为也许有更好的选择

17
00:01:07,560 --> 00:01:09,570
这些超级参数的值。

18
00:01:09,570 --> 00:01:12,720
您知道比我们选择的价值更好的选择。

19
00:01:12,780 --> 00:01:17,970
因此，这种称为“网格搜索”的技术将回答您多次提出的问题之一

20
00:01:17,970 --> 00:01:23,360
在本课程中，这是我如何知道在建立机器学习模型时应该选择哪个参数的方法

21
00:01:23,370 --> 00:01:28,710
这些超参数的最佳值是多少，网格搜索将给出答案，因为

22
00:01:28,980 --> 00:01:32,180
它将找到这些参数的最佳值。

23
00:01:32,190 --> 00:01:34,840
说到本课程中提出的问题。

24
00:01:34,920 --> 00:01:40,320
好吧，还有一个非常相关的问题被问了很多遍：我怎么知道哪种模型

25
00:01:40,320 --> 00:01:43,010
选择适合我的机器学习问题。

26
00:01:43,050 --> 00:01:47,350
您知道我有一个特定数据集附带的机器学习问题。

27
00:01:47,400 --> 00:01:51,320
我如何知道选择哪种模型来解决我的业务问题。

28
00:01:51,360 --> 00:01:52,980
哪种模式是最好的。

29
00:01:53,190 --> 00:01:58,590
当然首先要回答这个问题，您需要做的是知道您的问题是否是回归

30
00:01:58,590 --> 00:02:01,920
问题或分类问题或聚类问题。

31
00:02:01,920 --> 00:02:04,600
这样很容易，您只需要查看您的因变量即可。

32
00:02:04,680 --> 00:02:07,580
如果您没有因变量，那就是聚类问题。

33
00:02:07,650 --> 00:02:12,720
如果您有因变量，则可以看到它是连续结果还是绝对结果，如果

34
00:02:12,720 --> 00:02:15,810
这是一个连续的结果，那么您的问题就是一个回归问题。

35
00:02:15,870 --> 00:02:20,130
如果这是分类结果，那么您的问题就是分类问题。

36
00:02:20,160 --> 00:02:23,990
因此，这是找出哪种模型选择问题所在的第一步。

37
00:02:24,090 --> 00:02:29,570
然后第二步是问自己是我的问题是线性问题还是非线性问题。

38
00:02:29,700 --> 00:02:34,320
这不是一个显而易见的问题，尤其是当您拥有大量数据集时，您无法弄清楚

39
00:02:34,500 --> 00:02:39,610
如果数据是线性可分离的，或者您宁愿选择线性模型（例如SVM）。

40
00:02:39,660 --> 00:02:45,930
如果您正在分类或使用非线性模型（例如内核作为VM），则可以回答此问题

41
00:02:45,930 --> 00:02:47,760
通过我们今天要学习的技术。

42
00:02:47,880 --> 00:02:51,550
网格搜索，因为您将看到针对特定问题的信息。

43
00:02:51,670 --> 00:02:56,910
网格搜索会告诉我们是否应该选择线性模型，例如YEM或非线性模型

44
00:02:56,910 --> 00:02:58,610
像内核一样的模型。

45
00:02:58,680 --> 00:03:00,180
因此，让我们看看它将如何做到这一点。

46
00:03:00,180 --> 00:03:02,430
让我们实现一个网格搜索。

47
00:03:02,430 --> 00:03:06,110
因此，我们将处理与前两个工具相同的问题。

48
00:03:06,180 --> 00:03:11,030
也就是说，您知道这个分类问题，我们需要在社交网络中对用户进行分类

49
00:03:11,030 --> 00:03:14,670
并预测他们是否会在广告上点击“是”或“否”以购买SUV。

50
00:03:14,910 --> 00:03:19,510
因此，我们正在使用此数据集社交网络广告，这是一个不错的选择。

51
00:03:19,520 --> 00:03:24,900
请说明网格搜索，因为网格搜索会告诉我们是否应该选择SVM模型或

52
00:03:24,900 --> 00:03:26,240
我们建模的内核。

53
00:03:26,340 --> 00:03:31,380
除此之外，这是一个很好的例子，因为内核作为VM模型具有许多参数。

54
00:03:31,380 --> 00:03:33,460
您知道它具有此惩罚参数。

55
00:03:33,460 --> 00:03:38,840
这个伽玛参数，有些人问我应该为这些参数选择哪些值。

56
00:03:39,030 --> 00:03:41,750
因此，网格搜索将准确地告诉我们这一点。

57
00:03:41,760 --> 00:03:43,350
因此，让我们开始吧。

58
00:03:43,380 --> 00:03:48,660
我们正在使用与上一个教程相同的文件夹作为模型选择，以确保

59
00:03:48,660 --> 00:03:50,990
发现您拥有这个社交网络。

60
00:03:51,120 --> 00:03:52,750
如果是这样的话，您就准备好了。

61
00:03:53,070 --> 00:03:54,580
所以很好地探索。

62
00:03:54,630 --> 00:03:57,630
现在让我们开始实现网格搜索。

63
00:03:57,630 --> 00:04:04,020
因此，基本上可以在将模型拟合到训练集之后应用网格搜索，因为其中之一

64
00:04:04,020 --> 00:04:07,650
网格搜索的输入将是此处的分类器。

65
00:04:07,650 --> 00:04:13,860
因此，必须在本节之后对其进行编码，但是由于这三个节在此处对应于评估

66
00:04:13,860 --> 00:04:18,190
模型性能，现在我们正在努力改善模型性能。

67
00:04:18,210 --> 00:04:25,260
因此，让我们将网格搜索部分放在经过仔细的交叉验证之后就可以了，您知道我们首先评估

68
00:04:25,260 --> 00:04:28,080
他们所有的性能，然后我们改进它。

69
00:04:28,180 --> 00:04:28,670
好吧。

70
00:04:28,670 --> 00:04:42,750
这里的新部分应用了网格搜索，并且说说找到最佳模型和最佳参数

71
00:04:43,950 --> 00:04:46,740
现在完美，它实现了网格搜索。

72
00:04:46,910 --> 00:04:47,180
好。

73
00:04:47,190 --> 00:04:53,280
因此，首先让我们为作业导入正确的包和正确的功能，然后将该包称为

74
00:04:53,550 --> 00:05:03,680
网格搜索CV，我们从该模型选择的Kaylor导入此包，因为网格搜索是

75
00:05:03,680 --> 00:05:05,130
一种模型选择技术。

76
00:05:05,250 --> 00:05:12,860
因此它在模型选择模块和导入网格搜索中。

77
00:05:12,910 --> 00:05:14,490
请参阅全部。

78
00:05:14,550 --> 00:05:16,360
完美的包装很重要。

79
00:05:16,380 --> 00:05:22,740
现在让我们继续进行下一行，这将是关于指定不同的参数

80
00:05:22,920 --> 00:05:25,790
我们希望找到其中的最佳值。

81
00:05:25,830 --> 00:05:33,150
因此，我将创建此参数变量，这将是词典列表。

82
00:05:33,150 --> 00:05:39,390
因此，基本上，Python中的字典实际上是键标识符的列表，每个键标识符

83
00:05:39,600 --> 00:05:41,190
它具有特定的值。

84
00:05:41,370 --> 00:05:46,560
因此，该词典中的关键标识符将成为我们要优化的参数

85
00:05:46,560 --> 00:05:51,930
值，对于每个键标识符，我们将为其提供几个值

86
00:05:51,930 --> 00:05:55,340
是将由网格搜索模型测试的值。

87
00:05:55,470 --> 00:05:59,160
在这些值中，网格搜索模型将找到最佳值。

88
00:05:59,430 --> 00:06:01,370
因此，您将看到它会更加清晰。

89
00:06:01,500 --> 00:06:03,960
一旦建立，此参数就可行。

90
00:06:04,170 --> 00:06:07,390
因此，正如我刚刚告诉您的，这是词典列表。

91
00:06:07,500 --> 00:06:11,770
因此，由于这是一个列表，因此我们将在此处引入一些方括号。

92
00:06:12,030 --> 00:06:12,990
对。

93
00:06:13,080 --> 00:06:20,070
然后在这些括号内，我们将输入两个字典，以便在Python中放置一个字典

94
00:06:20,160 --> 00:06:22,680
在这样的括号中。

95
00:06:22,680 --> 00:06:28,170
在这些括号内，我们需要首先输入标识符以及什么是标识符。

96
00:06:28,170 --> 00:06:30,740
这是我们要优化的参数。

97
00:06:30,960 --> 00:06:37,310
因此，我们现在要做的实际上是选择从前面的代码部分到顶部的所有内容。

98
00:06:37,310 --> 00:06:38,910
我们将运行此。

99
00:06:38,940 --> 00:06:39,930
开始了。

100
00:06:40,060 --> 00:06:48,650
所有操作均已正确执行，现在已在此内核中运行，众所周知，我们将按Command或Control键

101
00:06:48,660 --> 00:06:53,890
我来看看不同的参数，然后选择我们要优化的参数。

102
00:06:53,940 --> 00:06:57,990
因此，让我们看一下这是类的参数。

103
00:06:58,050 --> 00:07:03,240
因此，基本上，当我们构建内核时，如果我们不道德，我们当然会选择明显的价值。

104
00:07:03,240 --> 00:07:08,010
内核参数，然后我们选择一个零的随机状态值。

105
00:07:08,070 --> 00:07:08,690
但是，仅此而已。

106
00:07:08,730 --> 00:07:12,440
我们没有为其他参数选择任何其他值。

107
00:07:12,450 --> 00:07:16,740
因此，例如存在误差项的惩罚参数。

108
00:07:16,740 --> 00:07:22,420
因此，这是用于正则化的参数，以防止默认值过大。

109
00:07:22,440 --> 00:07:27,070
这意味着当我们建立自己的核心时，我们的道德财富就等于一。

110
00:07:27,240 --> 00:07:32,640
也许c有更好的价值，这就是很棒的搜索会告诉我们的。

111
00:07:32,700 --> 00:07:34,680
然后我们有这个内核参数。

112
00:07:34,770 --> 00:07:37,340
因此，我们也将其包含在字典中。

113
00:07:37,440 --> 00:07:43,350
这将回答以下问题：线性之间最适合我的问题的模型是什么

114
00:07:43,350 --> 00:07:45,390
模型和非线性模型。

115
00:07:45,390 --> 00:07:50,700
如果网格搜索告诉我们内核应该是线性的，则意味着我们应该采用线性模型

116
00:07:51,150 --> 00:07:56,080
如果网格搜索告诉我们内核应该是非线性的，例如RB。

117
00:07:56,160 --> 00:07:58,920
嗯，这意味着我们应该建立一个非线性模型。

118
00:07:59,160 --> 00:08:00,520
所以我们已经知道答案了。

119
00:08:00,510 --> 00:08:06,090
但是我们在这里可以做的是，可以解决您的问题和数据集，因此这将非常

120
00:08:06,090 --> 00:08:11,280
有助于您决定采用线性模型还是非线性模型。

121
00:08:11,280 --> 00:08:12,840
然后我们有一个学位。

122
00:08:13,050 --> 00:08:18,780
因此，我们不会将其包含在字典中，因为我们不会测试是否应采用多项式

123
00:08:18,780 --> 00:08:24,810
内核，因为该度数是多项式内核函数，我们将尝试在

124
00:08:25,010 --> 00:08:30,860
线性调用和核函数，因此我们将不会尝试优化此度数参数。

125
00:08:31,110 --> 00:08:38,470
但是，我们有了伽玛，它是非线性波洛斯（例如B-F Poley或S型）的参数。

126
00:08:38,520 --> 00:08:43,630
因此，由于我们的模型选择方法的不同选项，因此存在明显的内核。

127
00:08:43,740 --> 00:08:47,870
好吧，我们将尝试优化此伽玛参数并找到最佳值。

128
00:08:48,090 --> 00:08:50,530
这样可以进一步改善我们的模型。

129
00:08:50,580 --> 00:08:57,810
我们不仅会通过找到最佳的惩罚参数来防止过度拟合来改善它，而且我们

130
00:08:57,810 --> 00:09:01,940
将优化此伽玛值以找到最佳内核。

131
00:09:01,980 --> 00:09:08,580
因此，让我们来做吧，我们来构建实际上将成为不同选择的字典

132
00:09:08,580 --> 00:09:10,250
网格搜索将进行调查。

133
00:09:10,380 --> 00:09:14,140
在这些选项中，出色的搜索将找到最好的一种。

134
00:09:14,160 --> 00:09:21,100
因此，第一个选择是线性模型，对于线性模型，我们还有一个惩罚参数。

135
00:09:21,150 --> 00:09:24,630
因此，我们将尝试使用此惩罚参数的不同值。

136
00:09:24,840 --> 00:09:31,560
因此，我们在这里输入的第一件事就是C惩罚参数的密钥标识符，我们需要

137
00:09:31,560 --> 00:09:33,800
用这种方式用引号引起来。

138
00:09:33,830 --> 00:09:42,740
先看再看Kallen，然后我们指定c的不同值，所以我们在

139
00:09:42,740 --> 00:09:44,100
方括号。

140
00:09:44,150 --> 00:09:46,100
因此，默认值为1。

141
00:09:46,190 --> 00:09:51,400
而且，增加此惩罚参数C越多，它将防止过度拟合。

142
00:09:51,470 --> 00:09:56,510
但是要小心，不要将其增加太多，否则会遇到新的问题

143
00:09:56,510 --> 00:09:57,890
将在50岁以下。

144
00:09:58,220 --> 00:10:03,200
那是一个瘫痪的模型，以致它不再适合数据集。

145
00:10:03,230 --> 00:10:10,890
因此，我们将尝试几个值，例如一个是默认值，然后是10，然后也是100。

146
00:10:11,090 --> 00:10:18,440
然后我们也可以尝试1000，但不能尝试更多，因为例如10000太多了。

147
00:10:18,440 --> 00:10:23,870
我一直处于职位上，我怀疑您会得到1000，但是我们仍然可以尝试。

148
00:10:23,870 --> 00:10:24,230
好吧。

149
00:10:24,240 --> 00:10:26,450
就是第一个密钥标识符。

150
00:10:26,450 --> 00:10:28,160
那是第一个参数。

151
00:10:28,160 --> 00:10:31,570
现在来介绍第二个参数。

152
00:10:31,650 --> 00:10:34,660
因此，现在我们正在测试线性选项。

153
00:10:34,760 --> 00:10:39,800
因此，我们将在此处指定线性核，以便指定首先需要引入一个

154
00:10:39,800 --> 00:10:49,890
关键标识符，即参数，它是内核，然后相同的调用然后放在方括号中

155
00:10:50,190 --> 00:10:58,310
我们输入引号几乎没有问题，这是针对第一个选项的，即第一个选项

156
00:10:58,310 --> 00:11:04,470
网格搜索将研究的是线性模型，这是经典的线性内核。

157
00:11:04,730 --> 00:11:09,850
对于此模型，它将尝试查看惩罚参数的最佳值，请参见。

158
00:11:10,160 --> 00:11:16,460
好的，现在我们将尝试第二种选择，即非线性选择和非线性

159
00:11:16,460 --> 00:11:19,040
选项当然是非线性模型。

160
00:11:19,040 --> 00:11:20,870
那就是非线性核。

161
00:11:21,200 --> 00:11:27,520
因此，让我们做同样的事情，我们以此方式在括号中引入第二个选项。

162
00:11:27,610 --> 00:11:32,850
所以说我们将为此席位惩罚参数尝试不同的值。

163
00:11:33,020 --> 00:11:41,330
所以我将其复制到此处并粘贴到此处，然后我们获取内核的第二个标识符

164
00:11:41,330 --> 00:11:43,810
复制它，我们可以将其粘贴到此处。

165
00:11:43,820 --> 00:11:49,470
但是这一次，我们将输入内核的RB，以便对非线性Karlo进行输入。

166
00:11:49,670 --> 00:11:51,130
我们还说了什么。

167
00:11:51,230 --> 00:11:58,250
我们说过，我们还想为优化gamma参数所需的色域尝试几个值。

168
00:11:58,250 --> 00:12:05,190
我们将找到此非线性内核的gamma参数的最佳值作为VM选项。

169
00:12:05,260 --> 00:12:16,130
因此，让我们将其放在此处并加引号gamma，然后是Cullin，然后尝试其他值。

170
00:12:16,180 --> 00:12:19,670
那么我们应该为该gamma参数尝试哪些值。

171
00:12:19,810 --> 00:12:28,120
就像您看到的那样，默认值是auto，并且如果gamma值也超过1并且功能将

172
00:12:28,120 --> 00:12:29,060
代替。

173
00:12:29,290 --> 00:12:34,690
这样就已经使我们对值范围进行了了解，应该尝试使用此gamma参数，因为

174
00:12:34,690 --> 00:12:37,190
我们有多少功能，我们有两个功能。

175
00:12:37,300 --> 00:12:40,830
因此，我们默认使用的值为0.5。

176
00:12:41,200 --> 00:12:44,650
但这可能不是最佳值，因此我们将尝试其他值。

177
00:12:44,650 --> 00:12:46,630
因此，让我们在这里尝试一些较小的。

178
00:12:46,690 --> 00:12:57,340
因此，让我们成为第一个0.5，然后上升，我们也尝试0.1，然后打开1，然后下降

179
00:12:57,340 --> 00:13:00,020
指出1。

180
00:13:00,220 --> 00:13:05,470
如果您将此代码应用于数据集，则完全可以这样做，因为它完全相同

181
00:13:05,470 --> 00:13:06,130
事情。

182
00:13:06,340 --> 00:13:11,710
好吧，因为您可能会有更多功能和两个功能，例如100个功能，

183
00:13:11,710 --> 00:13:17,180
甚至可以为gamma参数尝试较小的数字，例如点0 0 1。

184
00:13:17,200 --> 00:13:22,240
因此，我只是为您的数据集提供此值，以防您需要更小的值

185
00:13:22,240 --> 00:13:23,800
伽玛参数。

186
00:13:23,810 --> 00:13:29,970
因此，这实际上是网格搜索将调查的第二个选项。

187
00:13:29,980 --> 00:13:34,990
这意味着它将通过将内核视为

188
00:13:34,990 --> 00:13:37,100
我们的V.F.中的道德 核心。

189
00:13:37,240 --> 00:13:42,910
对于这个相同的选项，我们将研究几种您知道不同的选项

190
00:13:42,910 --> 00:13:47,190
惩罚参数C的值和不同的伽玛值。

191
00:13:47,410 --> 00:13:52,660
因此，最终我们将获得所有这些的单一组合。

192
00:13:52,690 --> 00:13:59,050
这意味着首先我们将知道我们是否应该采用R B F核，从而获得非线性模型

193
00:13:59,440 --> 00:14:05,920
或线性或核，进而是线性模型，这样就可以告诉我们我们的问题是

194
00:14:05,920 --> 00:14:12,010
线性或非线性，因此已经对您的问题有很大帮助。

195
00:14:12,010 --> 00:14:13,080
我应该选择。

196
00:14:13,210 --> 00:14:19,270
即使您不想将SVM或内核构建为模型，也可以应用此技术

197
00:14:19,270 --> 00:14:25,450
使用VM的不同内核来识别您是要处理线性问题还是非线性问题

198
00:14:25,450 --> 00:14:26,290
问题。

199
00:14:26,740 --> 00:14:31,860
然后根据结果，网格搜索还将告诉您惩罚参数的最佳值

200
00:14:31,870 --> 00:14:34,760
c和伽玛参数的最佳值。

201
00:14:34,960 --> 00:14:41,560
如果选择了RBA，则当然是如果发现您的问题的最佳选择是非线性

202
00:14:41,560 --> 00:14:42,510
模型。

203
00:14:42,520 --> 00:14:43,000
好吧。

204
00:14:43,000 --> 00:14:45,820
网格搜索的第一步就是这样。

205
00:14:45,820 --> 00:14:50,060
第一步是为参数选择这些选项。

206
00:14:50,230 --> 00:14:56,760
现在，第二步，我们将实现网格搜索，这些参数选项将

207
00:14:56,760 --> 00:15:01,180
作为我们刚刚导入的网格搜索功能的输入。

208
00:15:01,240 --> 00:15:06,670
因此，在下一个教程中，我们将使用此函数并获得最佳参数的结果。

209
00:15:06,670 --> 00:15:07,360
第2步。

210
00:15:07,630 --> 00:15:09,220
在那之前在德国学习。

