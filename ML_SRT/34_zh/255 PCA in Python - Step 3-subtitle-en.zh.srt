1
00:00:00,330 --> 00:00:02,480
您好，欢迎来到本Python教程。

2
00:00:02,520 --> 00:00:08,610
因此，我们仅将PCA应用于由训练集和测试集组成的数据集，并提取了

3
00:00:08,640 --> 00:00:13,830
两个主要组成部分解释最多变体的前两个主要组成部分。

4
00:00:13,860 --> 00:00:19,620
所以现在基本上我们只有两个自变量，并且我们已经准备好进行逻辑回归

5
00:00:19,620 --> 00:00:24,670
模型以对新的行进行分类，并确定它们属于哪个客户群。

6
00:00:24,840 --> 00:00:30,450
当然，与此同时，我们将预测测试结果以评估模型性能

7
00:00:30,450 --> 00:00:32,190
混淆矩阵。

8
00:00:32,190 --> 00:00:35,840
因此，好消息是，现在我们还有很多事情要做。

9
00:00:35,880 --> 00:00:40,010
例如，在本节中，将逻辑回归模型填充到训练集中。

10
00:00:40,230 --> 00:00:45,270
就像您看到的那样，我们没有任何事情要做，因为您知道我们正在导入逻辑回归

11
00:00:45,270 --> 00:00:50,040
类，我们创建了这个气化器对象，然后将这个气化器对象填充到

12
00:00:50,040 --> 00:00:50,880
训练集。

13
00:00:50,880 --> 00:00:58,740
所以基本上我们已经准备好选择部分并执行以建立我们的逻辑回归

14
00:00:58,740 --> 00:01:01,200
建模并使其适合训练集。

15
00:01:01,290 --> 00:01:05,940
这样就完成了，您将看到其余部分将保持不变。

16
00:01:06,090 --> 00:01:11,460
在本节中，我们只需要更改您将尝试猜测的两件事，但基本上

17
00:01:11,460 --> 00:01:18,150
休息已经准备好了，因为现在我们确实可以预测测试结果，因为我们的下一位客人已经准备好了

18
00:01:18,210 --> 00:01:21,660
并且还包含两个主要组成部分。

19
00:01:21,690 --> 00:01:22,680
可以看看。

20
00:01:22,680 --> 00:01:26,670
那就是我们通过PCA提取的两个主要成分。

21
00:01:26,700 --> 00:01:31,950
因此，我们都可以选择此生产线并预测测试结果。

22
00:01:31,960 --> 00:01:35,320
并不是我们对白面包测试的全部预测。

23
00:01:35,430 --> 00:01:39,930
因此，例如，第一个被预测属于客户，说我们是第一名。

24
00:01:40,050 --> 00:01:44,940
预计第二个属于客户，说第三号，第三个预计

25
00:01:44,940 --> 00:01:46,730
属于客户群编号2。

26
00:01:46,830 --> 00:01:52,960
太好了，我们有了预测，现在可以制作混淆矩阵来评估模型。

27
00:01:53,070 --> 00:01:59,460
这将是非常有趣的代码部分，因为我们将看到准确性

28
00:01:59,670 --> 00:02:03,960
我们的分类模型，并提取了两个主成分。

29
00:02:03,960 --> 00:02:10,290
由于选择了这些主要成分来解释最多的变体，实际上我们知道

30
00:02:10,290 --> 00:02:16,230
他们解释了大约60％的方差，因此我们应该获得良好的准确性，因为我们的

31
00:02:16,230 --> 00:02:22,120
实际上，两个主要成分是我们数据集中最大方差的方向。

32
00:02:22,170 --> 00:02:23,490
因此，我确实进行了检查。

33
00:02:23,490 --> 00:02:25,170
我现在要执行。

34
00:02:25,350 --> 00:02:27,750
因此，现在创建了混淆矩阵。

35
00:02:27,750 --> 00:02:28,560
我们来看一下。

36
00:02:28,650 --> 00:02:32,480
顺便说一句，您将在此过程中第一次看到有趣的事情。

37
00:02:32,520 --> 00:02:38,670
它是一个包含三类的混淆矩阵，这意味着我们不会有真假肯定

38
00:02:38,750 --> 00:02:40,130
和真假假。

39
00:02:40,260 --> 00:02:45,570
我们将有3个类，所以它不会是2乘2的令人困惑的矩阵，但是由于我们现在有了3个

40
00:02:45,570 --> 00:02:52,200
好吧，这将是一个三乘三与三个真实类1 2和3的混淆矩阵

41
00:02:52,520 --> 00:02:55,060
以及三个受保护的类别1 2和3。

42
00:02:55,080 --> 00:02:56,480
让我们来看一下。

43
00:02:56,550 --> 00:02:58,040
那就是计算矩阵。

44
00:02:58,200 --> 00:03:05,550
如您所见，我们获得了出色的结果，因为在此对角线中，单元格包含正确的

45
00:03:05,600 --> 00:03:06,120
预测。

46
00:03:06,130 --> 00:03:12,970
因此，例如，这笔财富在这里意味着14个零类的正确预测。

47
00:03:13,050 --> 00:03:15,610
基本上，这是细分市场第一的客户。

48
00:03:15,630 --> 00:03:22,380
这里的15表示对第二个客户群的15个正确预测，而这里的6表示

49
00:03:22,470 --> 00:03:25,850
客户说出第三条的六个正确预测。

50
00:03:26,100 --> 00:03:32,790
其余的例如为零这里表示零结果为实数

51
00:03:32,790 --> 00:03:38,740
观察结果为1的是类型1，即客户的第一号。

52
00:03:38,880 --> 00:03:42,590
预测是类型2或客户群2。

53
00:03:42,900 --> 00:03:49,410
因此，我们可以看到这里几乎没有错误的预测，只有一个对应于

54
00:03:49,410 --> 00:03:55,440
实际结果是第一个客户群，而预测是第二个客户的情况

55
00:03:55,440 --> 00:03:55,990
分割。

56
00:03:56,130 --> 00:03:57,990
因此，这实际上非常好。

57
00:03:57,990 --> 00:04:04,110
正是由于主成分分析，因为我们提取了独立变量

58
00:04:04,290 --> 00:04:09,460
可以解释最多的差异，因此可以使我们的两个主要成分成为很好的预测指标。

59
00:04:09,660 --> 00:04:12,440
这就是为什么我们在这里获得非常好的准确性的原因。

60
00:04:12,450 --> 00:04:13,850
我们实际上可以计算出来。

61
00:04:14,070 --> 00:04:18,980
好吧，让我们看看我们有14加15 29加6 3 5。

62
00:04:19,170 --> 00:04:20,960
这就是正确预测的数量。

63
00:04:21,090 --> 00:04:25,360
我们需要将其除以测试中的观察总数。

64
00:04:25,380 --> 00:04:26,990
那就是预测的总数。

65
00:04:27,240 --> 00:04:33,700
实际上，如果我们在这里看一下，测试集将包含36个观察值。

66
00:04:33,810 --> 00:04:42,170
所以我们需要将35除以36，这实际上是非常好的精度，因为我们得到35除以36。

67
00:04:42,240 --> 00:04:45,440
我们的准确性为97％。

68
00:04:45,570 --> 00:04:46,650
这真的很好。

69
00:04:46,860 --> 00:04:51,510
实际上，对于这种特定的分割，如果我们无法获得最佳的精度，那是我们可以做的最好的

70
00:04:51,510 --> 00:04:53,000
100％。

71
00:04:53,250 --> 00:05:00,760
真的很好，我们将看看其他降维技术LDA是否可以

72
00:05:00,980 --> 00:05:04,970
可以使我们获得100％的精度。

73
00:05:04,970 --> 00:05:07,720
好的，所以我们完成了混淆矩阵。

74
00:05:07,730 --> 00:05:09,110
我们取得了很好的结果。

75
00:05:09,110 --> 00:05:14,750
由于我们取得了良好的结果，因此通过可视化的培训，我们也将获得出色的结果

76
00:05:14,750 --> 00:05:20,250
结果，因为我们将了解与英国完全分开的不同预测区域

77
00:05:20,330 --> 00:05:21,260
边界。

78
00:05:21,260 --> 00:05:23,870
因此，让我们看一下，但不要在这里过快。

79
00:05:23,870 --> 00:05:27,010
我们需要在本节中更改一件事。

80
00:05:27,170 --> 00:05:31,400
好吧，这是一项必填项，然后是表单的另一项可选项。

81
00:05:31,490 --> 00:05:33,520
实际上，让我们从表单开始。

82
00:05:33,560 --> 00:05:40,730
我们只需要用PC代替这里的age，因为您知道age是第一个的名字，并且已经

83
00:05:40,730 --> 00:05:42,760
在第3部分的示例中非常宝贵

84
00:05:42,790 --> 00:05:48,620
社交网络广告和相同的估算工资是我们需要的第二个独立角色

85
00:05:48,620 --> 00:05:55,240
在这里也要替换掉，因为现在有两个独立变量实际上是一个。

86
00:05:55,560 --> 00:06:03,890
实际上，我们在这里也要这样做，我们用PC 1代替年龄，用PC 2代替估计工资。

87
00:06:04,270 --> 00:06:04,720
好的。

88
00:06:04,730 --> 00:06:07,450
现在我们也需要改变。

89
00:06:07,520 --> 00:06:09,670
我将扩大这个。

90
00:06:09,680 --> 00:06:13,250
我们还需要更改另一件事，这是强制性的。

91
00:06:13,340 --> 00:06:17,470
您能猜到是什么吗？您可以在视频中停顿一下，然后我现在要告诉您。

92
00:06:17,570 --> 00:06:23,570
嗯，这与以下事实有关：我们现在有三个类，而不是两个，因此我们需要

93
00:06:23,570 --> 00:06:29,150
预测区域和观察点的三种颜色，因为记住我们需要区分

94
00:06:29,500 --> 00:06:31,170
颜色的预测区域。

95
00:06:31,310 --> 00:06:34,400
并且由于每个预测区域对应于每个类别。

96
00:06:34,490 --> 00:06:37,890
好吧，我们将获得3个预测区域，因此会有3个调用者。

97
00:06:38,060 --> 00:06:43,790
因此，我将在此处添加新颜色，所以我们选择蓝色。

98
00:06:44,050 --> 00:06:47,010
好的，这里也一样。

99
00:06:47,840 --> 00:06:55,590
蓝色完美，在这里对于蓝色最终设置相同。

100
00:06:55,770 --> 00:06:56,730
这里也一样。

101
00:06:58,140 --> 00:06:58,810
大。

102
00:06:58,830 --> 00:07:04,320
因此，我在问答中注意到，有些人问我，如果我们有更多的东西，我们该如何处理呢？

103
00:07:04,320 --> 00:07:05,400
比两个班。

104
00:07:05,400 --> 00:07:06,710
好了，现在您知道了答案。

105
00:07:06,870 --> 00:07:08,980
您只需要再添加一种颜色。

106
00:07:09,180 --> 00:07:13,930
现在，我们实际上已经准备好可视化培训结果和测试结果。

107
00:07:14,100 --> 00:07:19,410
因此，鉴于我们的97％的准确性，让我们从训练集结果开始。

108
00:07:19,440 --> 00:07:24,810
我们知道，我们将得到完美区分的预测区域，这些预测区域几乎可以被

109
00:07:24,810 --> 00:07:26,160
预测边界。

110
00:07:26,160 --> 00:07:30,650
所以我要选择它，然后开始吧。

111
00:07:30,900 --> 00:07:32,810
这是美丽的结果。

112
00:07:32,820 --> 00:07:37,740
所以首先我们可以清楚地看到三个不同的预测区域对应于三个眼镜

113
00:07:38,190 --> 00:07:43,530
对应于第一客户群的红色对应第二客户的绿色

114
00:07:43,540 --> 00:07:47,360
细分，第三个细分对应于第三个客户细分。

115
00:07:47,370 --> 00:07:52,950
提醒您，实际上是我们的模型预测哪个客户细分的区域

116
00:07:52,950 --> 00:07:53,750
属于。

117
00:07:53,970 --> 00:07:59,010
然后，我们在这里有了所有与真实观察相对应的点。

118
00:07:59,070 --> 00:08:02,240
这是我们在训练中得到的真实观察结果。

119
00:08:02,760 --> 00:08:06,730
因此，我们可以清楚地看到所有红点都在正确的类别中。

120
00:08:06,750 --> 00:08:10,020
那是这里正确的预测区域。

121
00:08:10,200 --> 00:08:14,970
然后，与第二个客户群相对应的所有绿点都在正确的预测中

122
00:08:14,970 --> 00:08:17,290
除了这两个区域。

123
00:08:17,310 --> 00:08:22,470
最后，所有与该细分市场的客户相对应的蓝点和三个

124
00:08:22,500 --> 00:08:24,040
在正确的预测区域。

125
00:08:24,180 --> 00:08:26,420
实际上，所有这些都是如此。

126
00:08:26,520 --> 00:08:29,240
因此，这里的类很好地分开了。

127
00:08:29,310 --> 00:08:36,240
这是因为这两个自变量1和2实际上是最大方向

128
00:08:36,330 --> 00:08:37,290
方差。

129
00:08:37,290 --> 00:08:42,270
好的，那是针对训练集的，然后我们可以看一下测试结果。

130
00:08:42,270 --> 00:08:49,820
我将选择执行的部分，然后在这些测试结果中，客户再次陷入

131
00:08:49,820 --> 00:08:52,580
正确的区域（一位顾客除外）。

132
00:08:52,580 --> 00:08:57,920
这里就是这一点，它恰好对应于我们在我们的报告中看到的错误预测

133
00:08:57,920 --> 00:09:03,140
混淆矩阵，因为该客户确实属于第二个客户群，因为它是一个

134
00:09:03,140 --> 00:09:08,840
绿点，因为它是绿点，并且落在红色区域中，对客户群的响应

135
00:09:09,200 --> 00:09:09,990
第一。

136
00:09:10,160 --> 00:09:12,920
因此，这是错误的预测，也是错误的预测。

137
00:09:12,920 --> 00:09:17,270
我们在混淆矩阵中看到了，但是所有其他信息都可以正确预测。

138
00:09:17,420 --> 00:09:23,030
这使我们之前获得了97％的准确性。

139
00:09:23,360 --> 00:09:24,370
好的，完美。

140
00:09:24,380 --> 00:09:29,750
我们已经完成了有关PCa的第一部分，现在我们要看的有趣的事情是

141
00:09:29,870 --> 00:09:35,810
我们将要实现的下一个降维技术将在此数据集上进行。

142
00:09:35,840 --> 00:09:40,760
下一个降维技术是LDH线性判别分析。

143
00:09:40,850 --> 00:09:43,810
因此，问题是它将击败PCA。

144
00:09:43,970 --> 00:09:46,120
因此，我们将在下一部分中找到有关此内容的信息。

145
00:09:46,220 --> 00:09:47,960
直到那时机器学习。

